# Basic tidymodels


```{r}
library(tidymodels)
```

::: {.callout-note}
### 在继续之前，你应该

-   会使用 R 语言中的管道命令 `%>%` 或者 `|>`
-   用过这几个软件包：`dplyr`, `tidyr`, `ggplot2`
-   了解基本的统计学概念
-   现在不懂，但是想学习模型或者机器学习
:::

基础的 tidymodels 知识包括下面几点：

- 数据预处理
- 模型的结构
- 模型的评价
- 模型的调优

::: {#fig-tidymodels-workflow}
```{mermaid}
flowchart LR
 A(全部数据) --> B1(训练数据集)
 A --> B2(测试数据集)
 B1 --> F(最佳模型)
 B1 --> C(重采样)
 C --> D1(logistics 回归)
 C --> D2[决策树]
 C --> D3[随机森林]
 D1 --> E{选择模型}
 D2 --> E
 D3 --> E
 E --> F[最佳模型]
 F --> G[验证模型性能]
 B2 --> G
```
建模流程图
:::

## 安装需要的软件包

安装下面的这些软件包，以便完成上面列举的任务。

```{r}
#| eval: false
# Install the packages for the workshop
pkgs <- 
  c("bonsai", "doParallel", "embed", "finetune", "lightgbm", "lme4",
    "plumber", "probably", "ranger", "rpart", "rpart.plot", "rules",
    "splines2", "stacks", "text2vec", "textrecipes", "tidymodels", 
    "vetiver", "remotes")

pak::pak(pkgs)
```

## 数据预处理


`modeldata` 包提供了一些示例数据集，用于在 `tidymodels` 中进行模型建设和演示。其中 "taxi" 数据集是一个简化的示例数据集，描述了芝加哥出租车司机获得小费的情况。

其详细信息可以使用以下代码查看：

```{r}
library(modeldata)
taxi
```

包含的变量有：

- `tip`：乘客是否留下小费。 "yes" 或 "no"。
- `distance`：行程距离，以英里为单位。
- `company`：出租车公司。出现次数较少的公司被分为 "other"。
- `local`：行程是否在同一社区区域开始和结束。
- `dow`：行程开始的星期几。
- `month`：行程开始的月份。
- `hour`：行程开始的小时。

这个数据一共有 10000 行。

### 拆分数据

在机器学习中，数据集主要分为以下几种类型：

1. **训练集（Training Set）：**
   - **定义：** 用于训练模型的数据集。
   - **作用：** 模型通过训练集学习特征和模式，调整参数以最小化预测错误。

2. **验证集（Validation Set）：**
   - **定义：** 用于调整模型超参数、选择模型或防止过拟合的数据集。
   - **作用：** 通过在验证集上评估模型性能，进行超参数调整和模型选择。

3. **测试集（Test Set）：**
   - **定义：** 用于评估模型在未见过的数据上的性能的数据集。
   - **作用：** 测试集提供了模型在真实场景中的泛化能力的估计。


使用 `initial_split()` 将数据拆分成训练集和测试集。

```{r taxi-split}
set.seed(123)
library(rsample)

# random split
(taxi_split <- initial_split(taxi))


# access to split data
(taxi_train <- training(taxi_split))
(taxi_test <- testing(taxi_split))
```

使用 `initial_validation_split()` 将数据拆分成训练集、验证集和测试集。

```{r}
set.seed(123)
(taxi_split_2 = initial_validation_split(taxi, prop = c(0.6, 0.2)))

training(taxi_split_2)
testing(taxi_split_2)
validation(taxi_split_2)
```

使用函数的 `strata`、`prop` 参数，以及 `initial_time_split()`、`group_initial_split()` 等函数，可以实现更科学的随机分组。

## 模型的结构


在 R 中使用 `tidymodels` 进行建模的基本步骤如下：

1. **选择模型：**
   - 选择适合任务的模型，例如线性回归、决策树、随机森林等。

2. **指定引擎：**
   - 指定模型使用的引擎，如 "lm" 或 "glmnet"。

3. **设置模型模式：**
   - 设置模型的模式，是用于分类还是回归。


::: {.callout-note}
**Models** have default engines.

**Some** models have a default mode.
:::

```{r}
# 使用默认引擎的逻辑回归模型
logistic_reg()

# 使用 glmnet 引擎的逻辑回归模型
logistic_reg() %>%
  set_engine("glmnet")

# 使用 stan 引擎的逻辑回归模型
logistic_reg() %>%
  set_engine("stan")

# 未指定模式的决策树
decision_tree()

# 指定分类模式的决策树
decision_tree() %>% 
  set_mode("classification")
```

::: {.callout-tip}
All available models are listed at <https://www.tidymodels.org/find/parsnip/> 
:::


## 开始建模

使用 2 种模型对 `taxi` 数据进行建模。

* Logistic regression
* Decision trees

```{r sim-model-viz}
#| echo: false

set.seed(1)
dat <- sim_logistic(500, ~ .1 + 2 * A)
dat$bin <- cut(dat$A, breaks = c(seq(-3, 3, by = 1/2)), include.lowest = TRUE)
bin_midpoints <- data.frame(A = seq(-3, 3, by = 1/2) + 0.25)

rates <- 
  dat %>% 
  nest(.by = bin) %>% 
  mutate(
    probs = map(data, ~ binom.test(sum(.x$class == "one"), nrow(.x))),
    probs = map(probs, ~ tidy(.x))
  ) %>% 
  select(-data) %>% 
  unnest(cols = probs) %>% 
  arrange(bin) %>% 
  mutate(A = seq(-3, 3, by = 1/2) + 0.25) 

plot_rates <- left_join(rates, bin_midpoints, by = join_by(A)) %>% 
  filter(-2.5 < A, A < 3) %>% 
  ggplot() + 
  geom_point(aes(A, estimate)) +
  geom_errorbar(aes(A, estimate, ymin = conf.low, ymax = conf.high), width = .25)  +
  xlim(c(-3, 3.5)) +
  theme_bw(base_size = 18)
```

### 逻辑回归模型

逻辑回归模型将事件概率的对数几率（logit）建模为预测变量的线性组合：

$$
 \log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 \cdot A 
$$

在这里：

- $p$ 是事件发生的概率，
- $\beta_0$ 是截距，
- $\beta_1$ 是与预测变量 $A$ 相关的系数。



### 决策树

使用决策树建模。

- 基于预测变量的一系列划分或 if/then 语句：

- 首先，树会在满足某些条件之前（如达到最大深度或没有更多数据时）不断地“生长”（grow）。

- 然后，为了降低树的复杂性，树会被“修剪”（pruned）。

```{r}
tree_fit <- decision_tree(mode = "classification") %>% 
  fit(class ~ A, data = mutate(dat, class = forcats::fct_rev(class)))

tree_preds <- augment(tree_fit, new_data = bin_midpoints)

library(rpart.plot)
tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE)
```

建模的效果如下：

::: {.callout-caution}
All models are wrong, but some are useful!
:::

```{r}
#| echo: false
#| label: fig-model-comparison
#| fig-cap: 逻辑回归模型与决策树的预测结果示意。（A）通过逻辑函数（S形函数），找到一条分隔两个类别的曲线。当 $p$ 大于 0.5 时，预测的类别为 1；否则，为 0。 S 形曲线的形状实现了两个类别之间的平滑过渡。（B）使用决策树建模。

logistic_preds <- logistic_reg() %>% 
  fit(class ~ A, data = dat) %>% 
  augment(new_data = bin_midpoints) 

logistic_model_plot = plot_rates +
  geom_line(aes(A, .pred_one), color = "blue", linewidth = 2, alpha = 0.8, data = logistic_preds)

tree_model_plot = plot_rates +
  geom_step(aes(A, .pred_one), color = "green", linewidth = 2, alpha = 0.8, data = tree_preds)

aplot::plot_list(logistic_model_plot, tree_model_plot, ncol = 2, labels = c("A","B"))
```


### 将模型整合为 workflow

使用 `workflow()` 有一些明显的优势（@fig-workflow）。

- Workflow 在处理新数据方面比基本的 R 工具更加灵活，尤其是在涉及新的因子水平时：这在处理分类变量时尤为重要。

- 可以使用更多的数据预处理器来提取特征（在高级 tidymodels 中更多关于特征提取的内容！）

- 便于同时处理多个模型。

- 最重要的是，Workflow 涵盖了整个建模过程：`fit()` 和 `predict()` 不仅适用于模型拟合，还适用于预处理步骤。

::: {.callout-note}
### Workflow 如何更好地处理因子水平

- 强制执行不允许在预测时出现新因子水平的规定（可以关闭）
- 恢复在拟合时存在但在预测时缺失的因子水平
:::

![Workflows bind preprocessors and models](https://vnote-1251564393.cos.ap-chengdu.myqcloud.com/picgo/202312301710141.png){#fig-workflow}

**经典方法**

```{r tree-spec}
tree_spec <-
  decision_tree(cost_complexity = 0.002) %>% 
  set_mode("classification")

tree_spec %>% 
  fit(tip ~ ., data = taxi_train) 
```

**workflow方法**

```{r tree-wflow}
tree_spec <-
  decision_tree(cost_complexity = 0.002) %>% 
  set_mode("classification")

# 建立一个 workflow，同时保存模型参数，表达式和数据
workflow() %>%
  add_formula(tip ~ .) %>%
  add_model(tree_spec) %>%
  fit(data = taxi_train) 

# 或者写在一起
workflow(tip ~ ., tree_spec) %>% 
  fit(data = taxi_train) 
```

*Edit this code to make a workflow with your own model of choice.*

*Extension/Challenge: Other than formulas, what kinds of preprocessors are supported?*

### 使用模型预测

推荐使用 `augment()` 方法进行预测，与传统的 `predict()` 相比的差异如下。

```{r}
tree_fit <-
  workflow(tip ~ ., tree_spec) %>% 
  fit(data = taxi_train) 

predict(tree_fit, new_data = taxi_test)

augment(tree_fit, new_data = taxi_test)
```

::: {.callout-note}
- 预测结果在一个 tibble 中；
- 列名和数据类型更加清晰和易于理解；
- 行数和输出结果的行数是相同的，确保了数据的对应关系。
:::

### 解释模型

使用 `extract_*()` 函数提取模型 workflow 对象的组件。如 @fig-plot-tree-fit 展示了上面决策树模型的分类过程。

```{r}
#| label: fig-plot-tree-fit
#| fig-cap: 决策树的决策过程
library(rpart.plot)
tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE)
```


You can use your fitted workflow for model and/or prediction explanations:

-   overall variable importance, such as with the [vip](https://koalaverse.github.io/vip/) package

-   flexible model explainers, such as with the [DALEXtra](https://dalex.drwhy.ai/) package


## 模型的评价

### 模型

```{r setup-previous}
#| echo: false
library(tidymodels)

set.seed(123)
taxi_split <- initial_split(taxi, prop = 0.8, strata = tip)
taxi_train <- training(taxi_split)
taxi_test <- testing(taxi_split)

tree_spec <- decision_tree(cost_complexity = 0.0001, mode = "classification")
taxi_wflow <- workflow(tip ~ ., tree_spec)
taxi_fit <- fit(taxi_wflow, taxi_train)
```

### 混淆矩阵

混淆矩阵将真实值和预测值以热图的形成呈现出来。

```{r conf-mat-plot}
#| label: fig-conf-mat-plot
#| fig-asp: 0.5
#| fig-cap: 混淆矩阵
library(ggplot2)
library(forcats)
p1 = augment(taxi_fit, new_data = taxi_train) %>%
  conf_mat(truth = tip, estimate = .pred_class) %>%
  autoplot(type = "heatmap") +
  coord_equal()

# 阳性与阴性
df = tibble(Truth = as_factor(c("yes","yes","no","no")),
Prediction = as_factor(c("no","yes","no","yes")),
label = c("FN","TP","TN","FP"))
p2 = ggplot(df, aes(Truth, Prediction, label = label)) +
geom_tile(fill = "grey90", color = "grey", linewidth = 1) +
geom_text() +
coord_equal() +
theme_minimal()

aplot::plot_list(p1, p2, labels = c("A","B"))
```

```{r}
#| echo: false
TP = 7341
FP = 536
FN = 43
TN = 80
```

### 准确性

根据 @eq-predict-accuracy 可以计算准确性为 `r (TP+TN)/(TP+TN+FP+FN)`。

$$
accuracy = \frac{TP + TN}{TP+FP+TN+FN}
$$ {#eq-predict-accuracy}

```{r acc}
augment(taxi_fit, new_data = taxi_train) %>%
  accuracy(truth = tip, estimate = .pred_class)
```

### 敏感性

根据 @eq-predict-sensitivity 可以计算其数值为 `r (TP)/(TP+FN)`。


$$
sensitivity = \frac{TP}{TP+FP}
$$ {#eq-predict-sensitivity}


```{r sens}
augment(taxi_fit, new_data = taxi_train) %>%
  sensitivity(truth = tip, estimate = .pred_class)
```

### 特异性

根据 @eq-predict-specificity 可以计算其数值为 `r (TN)/(TN+FP)`。


$$
sensitivity = \frac{TP}{TP+FP}
$$ {#eq-predict-specificity}


```{r spec}
augment(taxi_fit, new_data = taxi_train) %>%
  specificity(truth = tip, estimate = .pred_class)
```

::: {.callout-note}

- **敏感性**告诉我们，测试有多大程度上能够捕捉到真正的阳性实例，即对于实际为阳性的样本，测试有多大可能性能够正确地识别出它们。
- **特异性**告诉我们，测试有多大程度上能够正确地排除实际为阴性的样本，即对于实际为阴性的样本，测试有多大可能性能够正确地将它们识别为阴性。
- **准确率**是一个综合性指标，衡量了分类模型对于所有样本的整体预测准确性。具体而言，它表示模型正确预测的样本在所有样本中的比例。

:::

使用 `metric_set()` 可以一次获取多个指标（另见 @fig-thresholds）。

```{r taxi-metrics}
taxi_metrics <- metric_set(accuracy, specificity, sensitivity)

augment(taxi_fit, new_data = taxi_train) %>%
  taxi_metrics(truth = tip, estimate = .pred_class)
```



```{r}
#| label: fig-thresholds
#| echo: false
#| fig-cap: 敏感性和特异性通常是一对矛盾的指标，即提高敏感性可能会降低特异性，反之亦然。在实际应用中，选择哪个指标更重要取决于具体的问题和应用背景。

augment(taxi_fit, new_data = taxi_train) %>% 
  roc_curve(truth = tip, .pred_yes) %>% 
  filter(is.finite(.threshold)) %>% 
  pivot_longer(c(specificity, sensitivity), names_to = "statistic", values_to = "value") %>% 
  rename(`event threshold` = .threshold) %>% 
  ggplot(aes(x = `event threshold`, y = value, col = statistic, group = statistic)) + 
  geom_line() +
  scale_color_brewer(palette = "Dark2") +
  labs(y = NULL) +
  coord_equal() +
  theme_bw() +
  theme(legend.position = "top")
```

### ROC 曲线

ROC（Receiver Operating Characteristic）曲线是一种用于评估二分类模型性能的图形工具。以下是关于ROC曲线的定义和解释：

1. **定义**：

   - ROC曲线是一种以假正例率（False Positive Rate，FPR）为横轴、真正例率（True Positive Rate，TPR或敏感性）为纵轴的图形。它显示了在不同阈值下，模型的真正例率和假正例率之间的权衡关系。

2. **绘制方式**：

   - 在ROC曲线中，横轴表示FPR，纵轴表示TPR。模型的输出概率或分数被用作不同阈值，从而生成一系列的TPR和FPR值。

3. **解释**：

   - ROC曲线能够展示在不同分类阈值下，模型在识别正例（阳性类别）和负例（阴性类别）方面的性能。理想情况下，ROC曲线越靠近左上角，模型性能越好，因为在那里，TPR较高而FPR较低。

4. **AUC值**：

   - ROC曲线下的面积（Area Under the Curve，AUC）也是一个常用的性能度量。AUC值越接近1，表示模型性能越好。AUC值为0.5时，表示模型的性能等同于随机猜测。

5. **示例**：

   - 一个理想的ROC曲线会沿着左上角的边缘，最终达到（0, 1）点。一般情况下，ROC曲线在图形上是向左上凸起的。

在实际应用中，ROC曲线和AUC值是评估分类模型性能的重要工具，尤其在处理不同类别分布和不同阈值的情况下。

given that sensitivity is the true positive rate, and specificity is the true negative rate. Hence `1 - specificity` is the false positive rate.

We can use the area under the ROC curve as a classification metric: 

- ROC AUC = 1 💯 
- ROC AUC = 1/2 😢

```{r roc-auc}
# Assumes _first_ factor level is event; there are options to change that
augment(taxi_fit, new_data = taxi_train) %>% 
  roc_curve(truth = tip, .pred_yes) %>%
  slice(1, 20, 50)

augment(taxi_fit, new_data = taxi_train) %>% 
  roc_auc(truth = tip, .pred_yes)
```

@fig-taxi-fit-roc-curve 显示了上面这个模型的 ROC 曲线。

```{r fig-taxi-fit-roc-curve}
#| label: fig-taxi-fit-roc-curve
#| fig-cap: 这个模型的 ROC AUC 值为 0.691。
augment(taxi_fit, new_data = taxi_train) %>% 
  roc_curve(truth = tip, .pred_yes) %>%
  autoplot()
```


### 过拟合

将训练得到的模型分别用于训练数据集和测试数据集，比较二者预测的准确率，可以发现预测训练数据集的结果优于测试数据集。这就是模型的过拟合现象（@fig-over-fitting）。

![过拟合](https://raw.githubusercontent.com/topepo/2022-nyr-workshop/main/images/tuning-overfitting-test-1.svg){#fig-over-fitting}

首先，比较一下模型的准确性指标。

```{r}
# 模型预测训练数据集
taxi_fit %>%
  augment(taxi_train) %>%
  accuracy(tip, .pred_class)

# 模型预测测试数据集
taxi_fit %>%
  augment(taxi_test) %>%
  accuracy(tip, .pred_class)
```

其次，比较一下 Brier 分数。

```{r brier-class}
taxi_fit %>%
  augment(taxi_train) %>%
  brier_class(tip, .pred_yes)

taxi_fit %>%
  augment(taxi_test) %>%
  brier_class(tip, .pred_yes)
```

Brier分数（Brier Score）是一种用于评估分类模型性能的指标。对于二分类问题，Brier分数的计算公式如下：

$$
Brier\ Score = \frac{1}{N} \sum_{i=1}^{N} (f_i - o_i)^2
$$

其中：
- $N$ 是样本数；
- $f_i$ 是模型对事件发生的概率的预测值；
- $o_i$ 是实际观测到的二分类结果，取值为0或1（例如，事件未发生为0，事件发生为1）。

Brier分数的取值范围在0到1之间，0表示完美预测，1表示最差的预测。较低的Brier分数表示模型对观测结果的概率预测更准确。所以，仍然可以发现模型过拟合的现象。

### 交叉验证

在不使用测试数据集的前提下，能不能比较模型的参数？这就要用到交叉验证。`vfold_cv()` 函数默认将训练数据集中的十分之一（`v = 10`）取出来，用于计算、比较模型的性能参数。

```{r taxi-folds}
set.seed(123)
taxi_folds <- vfold_cv(taxi_train, v = 10, strata = tip)
taxi_folds
```

使用 `fit_resamples()` 函数来对多次取样的数据进行拟合，使用 `collect_mertics()` 评价模型的性能。

```{r fit-resamples}
taxi_res <- fit_resamples(taxi_wflow, taxi_folds)
taxi_res
```

```{r collect-metrics}
taxi_res %>%
  collect_metrics()
```

::: {.callout-note}
`collect_metrics()` is one of a suite of `collect_*()` functions that can be used to work with columns of tuning results. Most columns in a tuning result prefixed with `.` have a corresponding `collect_*()` function with options for common summaries.
:::

交叉验证通过重采样和性能比较，使得我们可以在仅使用训练集就可以可靠地比较模型的性能。

::: {.callout-warning}
记住：

- 训练集会给出过于乐观的指标
- 测试集非常宝贵
:::


```{r save-predictions}
# Save the assessment set results
ctrl_taxi <- control_resamples(save_pred = TRUE)
taxi_res <- fit_resamples(taxi_wflow, taxi_folds, control = ctrl_taxi)

taxi_res

# Save the assessment set results
taxi_preds <- collect_predictions(taxi_res)
taxi_preds

# Evaluating model performance
taxi_preds %>% 
  group_by(id) %>%
  taxi_metrics(truth = tip, estimate = .pred_class)

taxi_res
```

交叉验证的蒙特卡洛方法，以及创建验证数据集。

```{r mc-cv}
set.seed(322)
# use the Monte Carlo Cross-Validation
mc_cv(taxi_train, times = 10)

# create validation set
taxi_val_split <- initial_validation_split(taxi, strata = tip)
validation_set(taxi_val_split)
```


## 模型的调优