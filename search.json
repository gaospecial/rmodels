[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Models",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#ç¯å¢ƒé…ç½®",
    "href": "index.html#ç¯å¢ƒé…ç½®",
    "title": "R Models",
    "section": "ç¯å¢ƒé…ç½®",
    "text": "ç¯å¢ƒé…ç½®\n\nVS Code\n\nå®‰è£… VS Code\nå®‰è£… VS Code æ’ä»¶\n\nR æ‰©å±• - æä¾› R è¯­è¨€æ”¯æŒ\nQuarto æ‰©å±• - æä¾› Quarto åŠŸèƒ½\nMarkdown æ‰©å±• - æä¾› Markdown æ ¼å¼åŒ–å¿«æ·æ–¹å¼\n\n\n\n\nQuarto\nMarkdown is an easy to read and write text format:\n\nItâ€™s plain text so works well with version control\nIt can be rendered into HTML, PDF, and more\nLearn more at: https://quarto.org/docs/authoring/\n\n\n\né…ç½® Python\nè®¾ç½® reticulate è¿è¡Œçš„ Python ç¯å¢ƒ\næ ¹æ® quarto æ‰©å±•çš„é»˜è®¤è®¾ç½®ï¼ŒPython ä»£ç å°†é€šè¿‡ reticulate æ¥è¿è¡Œã€‚å¦‚æœæ²¡æœ‰å®‰è£…çš„è¯éœ€è¦è¿è¡Œ install.packages(\"reticulate\") å®‰è£…å®ƒã€‚ç„¶åä½¿ç”¨ use_condaenv() æ¥æŒ‡å®šéœ€è¦çš„ Conda ç¯å¢ƒã€‚\n\nreticulate::use_condaenv(\"rmodels\")"
  },
  {
    "objectID": "index.html#ç¯å¢ƒæµ‹è¯•",
    "href": "index.html#ç¯å¢ƒæµ‹è¯•",
    "title": "R Models",
    "section": "ç¯å¢ƒæµ‹è¯•",
    "text": "ç¯å¢ƒæµ‹è¯•\n\nCode Cell\nHere is a Python code cell:\n\nimport os\nos.cpu_count()\n\n12\n\n\nHere is a R code chunk:\n\nplot(cars)\n\n\n\n\n\n\nEquation\nUse LaTeX to write equations:\n\n\\chi' = \\sum_{i=1}^n k_i s_i^2"
  },
  {
    "objectID": "index.html#é¡¹ç›®ç®€ä»‹",
    "href": "index.html#é¡¹ç›®ç®€ä»‹",
    "title": "R Models",
    "section": "é¡¹ç›®ç®€ä»‹",
    "text": "é¡¹ç›®ç®€ä»‹\nä½¿ç”¨ R/Python è¿›è¡Œæ¨¡å‹æ„å»ºçš„å­¦ä¹ ç¬”è®°ã€‚\n\ntidymodels è½¯ä»¶åŒ…çš„ä½¿ç”¨ https://workshops.tidymodels.org\nã€Šæ•°æ®æŒ–æ˜å®æˆ˜ã€‹è¯»ä¹¦ç¬”è®° (å¼  2021)\næ›´å¤šå­¦ä¹ ææ–™(TidymodelsHuanYing?; M. K. and J. Silge 2022; E. H. and J. Silge 2023; Robinson 2023; McConville 2022)\n\n\n\n\n\nMcConville, Chester Ismay and Albert Y. Kim Foreword by Kelly S. 2022. Statistical Inference via Data Science.\n\n\nRobinson, Julia Silge and David. 2023. Welcome to Text Mining with R  Text Mining with R.\n\n\nSilge, Emil Hvitfeldt and Julia. 2023. Supervised Machine Learning for Text Analysis in R.\n\n\nSilge, Max Kuhn and Julia. 2022. Tidy Modeling with R.\n\n\nå¼ ä¿Šå¦®. 2021. æ•°æ®æŒ–æ˜ï¼šåŸºäºRè¯­è¨€çš„å®æˆ˜. äººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾."
  },
  {
    "objectID": "10.tidymodels-intro.html#ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
    "href": "10.tidymodels-intro.html#ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
    "title": "Machine Learning with Tidymodels",
    "section": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
    "text": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ \ntidymodels æ˜¯ä¸€ä¸ªç”¨äºæœºå™¨å­¦ä¹ çš„è½¯ä»¶åŒ…ã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ å‘¢ï¼ˆFigureÂ 1ï¼‰ï¼Ÿ\n\n\n\n\n\nFigureÂ 1: ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ \n\n\n\n\næœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼Œç®€ç§°MLï¼‰æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰çš„åˆ†æ”¯é¢†åŸŸï¼Œè‡´åŠ›äºç ”ç©¶å¦‚ä½•è®©è®¡ç®—æœºç³»ç»Ÿé€šè¿‡ç»éªŒå­¦ä¹ æ”¹å–„æ€§èƒ½ã€‚æœºå™¨å­¦ä¹ çš„ç›®æ ‡æ˜¯è®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè‡ªåŠ¨è¯†åˆ«æ¨¡å¼ã€è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä¸æ–­åœ°æé«˜è‡ªèº«çš„æ€§èƒ½ã€‚\nåœ¨ä¼ ç»Ÿçš„ç¼–ç¨‹ä¸­ï¼Œç¨‹åºå‘˜ç¼–å†™è§„åˆ™å’Œç®—æ³•æ¥æŒ‡å¯¼è®¡ç®—æœºæ‰§è¡Œç‰¹å®šçš„ä»»åŠ¡ã€‚è€Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬æä¾›å¤§é‡çš„æ•°æ®å’Œç›¸åº”çš„ç»“æœï¼ˆæ ‡ç­¾ï¼‰ï¼Œè®©è®¡ç®—æœºè‡ªå·±å­¦ä¹ ä»æ•°æ®ä¸­æå–æ¨¡å¼å’Œè§„å¾‹ï¼Œè€Œä¸æ˜¯æ˜¾å¼åœ°ç¼–å†™è¯¦å°½çš„è§„åˆ™ã€‚\næœºå™¨å­¦ä¹ ä»»åŠ¡é€šå¸¸å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š\n\nç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰ï¼šåœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œç®—æ³•æ¥æ”¶å¸¦æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ®ï¼Œå­¦ä¹ è¾“å…¥ä¸è¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚ç›®æ ‡æ˜¯ä½¿ç®—æ³•èƒ½å¤Ÿå¯¹æ–°çš„ã€æœªæ ‡è®°çš„æ•°æ®è¿›è¡Œå‡†ç¡®çš„é¢„æµ‹æˆ–åˆ†ç±»ã€‚\n\nåˆ†ç±»ï¼ˆClassificationï¼‰ï¼šé¢„æµ‹è¾“å…¥å±äºå“ªä¸ªç±»åˆ«ï¼Œä¾‹å¦‚åƒåœ¾é‚®ä»¶æ£€æµ‹ã€æ‰‹å†™æ•°å­—è¯†åˆ«ç­‰ã€‚\nå›å½’ï¼ˆRegressionï¼‰ï¼šé¢„æµ‹ä¸€ä¸ªè¿ç»­å€¼ï¼Œä¾‹å¦‚æˆ¿ä»·é¢„æµ‹ã€è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç­‰ã€‚\n\næ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervised Learningï¼‰ï¼šåœ¨æ— ç›‘ç£å­¦ä¹ ä¸­ï¼Œç®—æ³•æ¥æ”¶æœªæ ‡è®°çš„è®­ç»ƒæ•°æ®ï¼Œç›®æ ‡æ˜¯å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼ã€ç»“æ„æˆ–å…³ç³»ã€‚\n\nèšç±»ï¼ˆClusteringï¼‰ï¼šå°†æ•°æ®åˆ’åˆ†ä¸ºä¸åŒçš„ç»„ï¼Œä½¿ç»„å†…çš„æ•°æ®ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œç»„é—´ç›¸ä¼¼åº¦è¾ƒä½ã€‚\né™ç»´ï¼ˆDimensionality Reductionï¼‰ï¼šå‡å°‘æ•°æ®çš„ç»´åº¦ï¼Œä¿ç•™é‡è¦çš„ç‰¹å¾ï¼Œä¾‹å¦‚ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã€‚\n\nå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰ï¼šåœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç®—æ³•é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’å­¦ä¹ ï¼Œé€šè¿‡å°è¯•æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±æ¥å†³å®šæœ€ä½³çš„è¡Œä¸ºç­–ç•¥ã€‚è¿™ç§å­¦ä¹ æ–¹å¼é€šå¸¸æ¶‰åŠåˆ°ä»£ç†ï¼ˆAgentï¼‰å’Œç¯å¢ƒä¹‹é—´çš„äº¤äº’ã€‚\n\nä»£è¡¨æ€§åº”ç”¨ï¼šæ¸¸æˆç©å®¶ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€‚\n\n\næœºå™¨å­¦ä¹ ä½¿ç”¨å¤šç§æŠ€æœ¯å’Œç®—æ³•ï¼ŒåŒ…æ‹¬å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œã€æœ´ç´ è´å¶æ–¯ã€Kè¿‘é‚»ç­‰ã€‚è¿™äº›æ–¹æ³•åœ¨ä¸åŒçš„é—®é¢˜å’Œæ•°æ®æƒ…å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œé€‰æ‹©åˆé€‚çš„ç®—æ³•å–å†³äºå…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®ç‰¹å¾ã€‚æœºå™¨å­¦ä¹ åœ¨è®¸å¤šé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆå°±ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€åŒ»å­¦è¯Šæ–­ç­‰ã€‚"
  },
  {
    "objectID": "10.tidymodels-intro.html#ä»€ä¹ˆæ˜¯-tidymodels",
    "href": "10.tidymodels-intro.html#ä»€ä¹ˆæ˜¯-tidymodels",
    "title": "Machine Learning with Tidymodels",
    "section": "ä»€ä¹ˆæ˜¯ tidymodelsï¼Ÿ",
    "text": "ä»€ä¹ˆæ˜¯ tidymodelsï¼Ÿ\ntidymodels æ˜¯ä¸€ä¸ª R è¯­è¨€çš„æœºå™¨å­¦ä¹ å·¥å…·é›†åˆï¼ŒåŒ…å«äº†ä¸€ç³»åˆ—ç”¨äºç»Ÿè®¡å»ºæ¨¡å’Œæœºå™¨å­¦ä¹ çš„è½¯ä»¶åŒ…ã€‚\nå®ƒæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å»ºæ¨¡æ¡†æ¶ï¼Œä¸º R ç”¨æˆ·æä¾›äº†ä¸€ç§è¿›è¡Œé¢„å¤„ç†ï¼Œå»ºæ¨¡ï¼Œè¯„ä¼°å’Œè°ƒæ•´çš„æœ‰åºæ–¹æ³•ã€‚å…¶ç›®æ ‡æ˜¯ç®€åŒ–æ•°æ®åˆ†æè¿‡ç¨‹ã€‚è¿™ä¸ªæ¡†æ¶é›†æˆäº†å¾ˆå¤šç°æœ‰ä¸”è¢«å¹¿æ³›ä½¿ç”¨çš„RåŒ…ï¼Œä½¿å¾—å…¶å…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚\nTidymodelsåŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦çš„ç»„ä»¶ï¼š\n\nRecipes: è¿™æ˜¯ä¸€ç§ç”¨äºæ•°æ®é¢„å¤„ç†æ­¥éª¤çš„æ ·æ¿æ–‡ä»¶/è“å›¾ã€‚ä¾‹å¦‚ï¼Œç¼©æ”¾æˆ–ä¸­å¿ƒåŒ–è¿ç»­å˜é‡ï¼Œç¼–ç åˆ†ç±»å˜é‡ç­‰ã€‚\nrsample: ç”¨äºé‡å¤æŠ½æ ·ï¼Œä¾‹å¦‚äº¤å‰éªŒè¯æˆ–bootstrapã€‚\nparnsip: ç”¨äºè®¾ç½®æ¨¡å‹è§„èŒƒå’Œå¼•æ“ã€‚\ntune: ç”¨äºæ¨¡å‹è°ƒä¼˜ã€‚\nworkflows: å…è®¸å°†é¢„å¤„ç†æ­¥éª¤ï¼ˆå³é…æ–¹ï¼‰å’Œæ¨¡å‹è§„èŒƒåˆå¹¶ä¸ºå•ä¸€å¯¹è±¡ï¼Œä»¥ä¾¿åœ¨æ•´ä¸ªå·¥ä½œæµç¨‹ä¸­ä¿æŒä¸€è‡´æ€§ã€‚\nyardstick: ç”¨äºè®¡ç®—æ¨¡å‹çš„è¡¨ç°å’Œæ•ˆæœã€‚\n\nä»¥ä¸‹æ˜¯ tidymodels ä¸»è¦ç»„æˆéƒ¨åˆ†åŠå…¶åŠŸèƒ½çš„ç®€è¦ä»‹ç» (FigureÂ 2)ï¼š\n\n\n\nFigureÂ 2: tidymodels ç›¸å…³åŒ…\n\n\n\nlibrary(\"tidymodels\")\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” recipes      1.0.9\nâœ” dials        1.2.0     âœ” rsample      1.2.0\nâœ” dplyr        1.1.4     âœ” tibble       3.2.1\nâœ” ggplot2      3.4.4     âœ” tidyr        1.3.0\nâœ” infer        1.0.5     âœ” tune         1.1.2\nâœ” modeldata    1.2.0     âœ” workflows    1.1.3\nâœ” parsnip      1.1.1     âœ” workflowsets 1.0.1\nâœ” purrr        1.0.2     âœ” yardstick    1.2.0\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– purrr::discard() masks scales::discard()\nâœ– dplyr::filter()  masks stats::filter()\nâœ– dplyr::lag()     masks stats::lag()\nâœ– recipes::step()  masks stats::step()\nâ€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\n\n\næ¨¡å‹è§„èŒƒï¼ˆModel Specificationï¼‰ï¼š\n\nparsnip åŒ…æä¾›äº†ä¸€ä¸ªä¸€è‡´çš„ APIï¼Œç”¨äºå®šä¹‰ã€ä¼°è®¡å’Œè°ƒæ•´å„ç§ç»Ÿè®¡æ¨¡å‹ã€‚å®ƒæ”¯æŒå¤šç§æ¨¡å‹ç±»å‹ï¼ŒåŒ…æ‹¬å›å½’ã€åˆ†ç±»ã€èšç±»ç­‰ã€‚\n\nlibrary(parsnip)\n\n# åˆ›å»ºä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹è§„èŒƒ\nlinear_spec &lt;- linear_reg() %&gt;% set_engine(\"lm\")\né¢„å¤„ç†ï¼ˆPreprocessingï¼‰ï¼š\n\nrsample å’Œ recipes åŒ…ç”¨äºåˆ›å»ºå’Œæ‰§è¡Œæ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼Œä¾‹å¦‚ç¼ºå¤±å€¼å¤„ç†ã€å˜é‡å˜æ¢ã€ç‰¹å¾å·¥ç¨‹ç­‰ã€‚é¢„å¤„ç†æ­¥éª¤å¯ä»¥ä¸æ¨¡å‹è§„èŒƒæ— ç¼é›†æˆã€‚\n\nlibrary(recipes)\n\n# åˆ›å»ºä¸€ä¸ªæ•°æ®é¢„å¤„ç†é…æ–¹\npreprocess_recipe &lt;- recipe(target ~ ., data = training_data) %&gt;%\n  step_scale(all_predictors()) %&gt;%\n  step_center(all_predictors())\næ¨¡å‹è°ƒå‚ï¼ˆModel Tuningï¼‰ï¼š\n\ntune åŒ…ç”¨äºæ‰§è¡Œæ¨¡å‹å‚æ•°è°ƒä¼˜ï¼ˆtuningï¼‰ã€‚å®ƒæä¾›äº†ä¸€ä¸ªä¸€è‡´çš„æ¡†æ¶ï¼Œå¯ä»¥å¯¹æ¨¡å‹è¿›è¡Œç½‘æ ¼æœç´¢æˆ–å…¶ä»–ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æ‰¾åˆ°æœ€ä½³çš„è¶…å‚æ•°ç»„åˆã€‚\n\nlibrary(tune)\n\n# åˆ›å»ºä¸€ä¸ªå‚æ•°è°ƒä¼˜ç½‘æ ¼\ngrid &lt;- expand.grid(neighbors = c(1, 3, 5))\n\n# è¿›è¡Œå‚æ•°è°ƒä¼˜\ntune_result &lt;- tune_grid(\n  linear_spec,\n  resamples = training_data,\n  grid = grid\n)\næ¨¡å‹è¯„ä¼°ï¼ˆModel Evaluationï¼‰ï¼š\n\nyardstick åŒ…æä¾›äº†ç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„å·¥å…·ï¼ŒåŒ…æ‹¬å„ç§æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ã€AUCã€RMSE ç­‰ï¼‰å’Œå›¾å½¢åŒ–æ–¹æ³•ã€‚\n\nlibrary(yardstick)\n\n# è¯„ä¼°çº¿æ€§å›å½’æ¨¡å‹çš„æ€§èƒ½\nlinear_metrics &lt;- linear_spec %&gt;%\n  fit(training_data) %&gt;%\n  predict(new_data = testing_data) %&gt;%\n  yardstick::metrics(truth = testing_data$target, estimate = .pred)\nç®¡é“ï¼ˆWorkflowsï¼‰ï¼š\n\n\nworkflows åŒ…æä¾›äº†ä¸€ç§ç»„ç»‡æ¨¡å‹è®­ç»ƒã€é¢„å¤„ç†å’Œè¯„ä¼°çš„æ¡†æ¶ã€‚å®ƒå…è®¸ä½ å®šä¹‰æ•´ä¸ªå»ºæ¨¡è¿‡ç¨‹ï¼Œå¹¶ä½¿æ•´ä¸ªå·¥ä½œæµç¨‹å¯é‡å¤å’Œå¯æ‰©å±•ã€‚\n\nlibrary(workflows)\n\n# åˆ›å»ºä¸€ä¸ªåŒ…å«é¢„å¤„ç†å’Œæ¨¡å‹çš„å·¥ä½œæµ\nwf &lt;- workflow() %&gt;%\n  add_recipe(preprocess_recipe) %&gt;%\n  add_model(linear_spec)\n\n# è®­ç»ƒå’Œè¯„ä¼°å·¥ä½œæµ\nwf_fit &lt;- wf %&gt;%\n  fit(training_data) %&gt;%\n  predict(new_data = testing_data)\næ€»ä½“è€Œè¨€ï¼Œtidymodels æä¾›äº†ä¸€ä¸ªä¸€è‡´çš„æ¡†æ¶ï¼Œä½¿æ•°æ®ç§‘å­¦å®¶å’Œåˆ†æå¸ˆèƒ½å¤Ÿæ›´è½»æ¾åœ°è¿›è¡Œæ¨¡å‹å¼€å‘ã€è¯„ä¼°å’Œè°ƒä¼˜ã€‚å®ƒä¸ tidyverse çš„å…¶ä»–éƒ¨åˆ†æ— ç¼é›†æˆï¼Œæ”¯æŒæ•´æ´çš„æ•°æ®å¤„ç†å’Œå¯è¯»æ€§å¼ºçš„ä»£ç ã€‚"
  },
  {
    "objectID": "10.tidymodels-intro.html#æ¨¡å‹çš„ä¾èµ–åŒ…",
    "href": "10.tidymodels-intro.html#æ¨¡å‹çš„ä¾èµ–åŒ…",
    "title": "Machine Learning with Tidymodels",
    "section": "æ¨¡å‹çš„ä¾èµ–åŒ…",
    "text": "æ¨¡å‹çš„ä¾èµ–åŒ…\nä¸‹é¢æ˜¯ä¸º tidymodels æä¾›æ¨¡å‹çš„ R åŒ…ï¼š\n\nlmï¼ˆLinear Modelï¼‰ï¼š\n\næè¿°ï¼š ç”¨äºæ‹Ÿåˆçº¿æ€§å›å½’æ¨¡å‹ï¼Œé€‚ç”¨äºè¿ç»­å‹ç›®æ ‡å˜é‡ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nmodel &lt;- lm(y ~ x1 + x2, data = my_data)\n\nglmï¼ˆGeneralized Linear Modelï¼‰ï¼š\n\næè¿°ï¼š ç”¨äºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼Œé€‚ç”¨äºå…·æœ‰ä¸åŒåˆ†å¸ƒçš„ç›®æ ‡å˜é‡ï¼Œå¦‚äºŒé¡¹åˆ†å¸ƒï¼ˆé€»è¾‘å›å½’ï¼‰ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nmodel &lt;- glm(y ~ x1 + x2, family = binomial, data = my_data)\n\nglmnetï¼ˆRegularized Regressionï¼‰ï¼š\n\næè¿°ï¼š ç”¨äº L1 å’Œ L2 æ­£åˆ™åŒ–çš„çº¿æ€§å’Œå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼Œé€‚ç”¨äºå¤„ç†é«˜ç»´æ•°æ®é›†ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nlibrary(glmnet)\nmodel &lt;- cv.glmnet(x, y, family = \"gaussian\")\n\nkerasï¼ˆRegression using TensorFlowï¼‰ï¼š\n\næè¿°ï¼š æä¾›äº†ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶ TensorFlow è¿›è¡Œå›å½’çš„åŠŸèƒ½ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nlibrary(keras)\nmodel &lt;- keras_model_sequential() %&gt;%\n  layer_dense(units = 1, input_shape = c(n_features))\n\nstanï¼ˆBayesian Regressionï¼‰ï¼š\n\næè¿°ï¼š ä½¿ç”¨æ¦‚ç‡ç¼–ç¨‹è¯­è¨€ Stan è¿›è¡Œè´å¶æ–¯çº¿æ€§å›å½’ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nlibrary(rstan)\nmodel &lt;- stan_model(\"linear_regression.stan\")\n\nsparkï¼ˆLarge Data Setsï¼‰ï¼š\n\næè¿°ï¼š æä¾›äº†ä½¿ç”¨ Apache Spark å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬åˆ†å¸ƒå¼å›å½’ã€‚\nç¤ºä¾‹ä»£ç ï¼š\nlibrary(sparklyr)\nsc &lt;- spark_connect(master = \"local\")\nmodel &lt;- spark_lm(sc, mpg ~ wt + hp, data = mtcars)\n\n\nè¿™äº›åŒ…æ¶µç›–äº†ä¸åŒç±»å‹å›å½’ä»»åŠ¡çš„éœ€æ±‚ï¼Œä»ä¼ ç»Ÿçš„çº¿æ€§å›å½’åˆ°æ·±åº¦å­¦ä¹ å’Œè´å¶æ–¯å›å½’ã€‚"
  },
  {
    "objectID": "11.tidymodels-basic.html#å®‰è£…éœ€è¦çš„è½¯ä»¶åŒ…",
    "href": "11.tidymodels-basic.html#å®‰è£…éœ€è¦çš„è½¯ä»¶åŒ…",
    "title": "1Â  Basic tidymodels",
    "section": "1.1 å®‰è£…éœ€è¦çš„è½¯ä»¶åŒ…",
    "text": "1.1 å®‰è£…éœ€è¦çš„è½¯ä»¶åŒ…\nå®‰è£…ä¸‹é¢çš„è¿™äº›è½¯ä»¶åŒ…ï¼Œä»¥ä¾¿å®Œæˆä¸Šé¢åˆ—ä¸¾çš„ä»»åŠ¡ã€‚\n\n# Install the packages for the workshop\npkgs &lt;- \n  c(\"bonsai\", \"doParallel\", \"embed\", \"finetune\", \"lightgbm\", \"lme4\",\n    \"plumber\", \"probably\", \"ranger\", \"rpart\", \"rpart.plot\", \"rules\",\n    \"splines2\", \"stacks\", \"text2vec\", \"textrecipes\", \"tidymodels\", \n    \"vetiver\", \"remotes\")\n\npak::pak(pkgs)"
  },
  {
    "objectID": "11.tidymodels-basic.html#æ•°æ®é¢„å¤„ç†",
    "href": "11.tidymodels-basic.html#æ•°æ®é¢„å¤„ç†",
    "title": "1Â  Basic tidymodels",
    "section": "1.2 æ•°æ®é¢„å¤„ç†",
    "text": "1.2 æ•°æ®é¢„å¤„ç†\nmodeldata åŒ…æä¾›äº†ä¸€äº›ç¤ºä¾‹æ•°æ®é›†ï¼Œç”¨äºåœ¨ tidymodels ä¸­è¿›è¡Œæ¨¡å‹å»ºè®¾å’Œæ¼”ç¤ºã€‚å…¶ä¸­ â€œtaxiâ€ æ•°æ®é›†æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹æ•°æ®é›†ï¼Œæè¿°äº†èŠåŠ å“¥å‡ºç§Ÿè½¦å¸æœºè·å¾—å°è´¹çš„æƒ…å†µã€‚\nå…¶è¯¦ç»†ä¿¡æ¯å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç æŸ¥çœ‹ï¼š\n\nlibrary(modeldata)\ntaxi\n\n# A tibble: 10,000 Ã— 7\n   tip   distance company                      local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3 yes      18.1  other                        no    Mon   Feb      18\n 4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8 yes      17.7  other                        no    Sun   Jan       6\n 9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10 yes       1.47 City Service                 no    Tue   Mar      14\n# â„¹ 9,990 more rows\n\n\nåŒ…å«çš„å˜é‡æœ‰ï¼š\n\ntipï¼šä¹˜å®¢æ˜¯å¦ç•™ä¸‹å°è´¹ã€‚ â€œyesâ€ æˆ– â€œnoâ€ã€‚\ndistanceï¼šè¡Œç¨‹è·ç¦»ï¼Œä»¥è‹±é‡Œä¸ºå•ä½ã€‚\ncompanyï¼šå‡ºç§Ÿè½¦å…¬å¸ã€‚å‡ºç°æ¬¡æ•°è¾ƒå°‘çš„å…¬å¸è¢«åˆ†ä¸º â€œotherâ€ã€‚\nlocalï¼šè¡Œç¨‹æ˜¯å¦åœ¨åŒä¸€ç¤¾åŒºåŒºåŸŸå¼€å§‹å’Œç»“æŸã€‚\ndowï¼šè¡Œç¨‹å¼€å§‹çš„æ˜ŸæœŸå‡ ã€‚\nmonthï¼šè¡Œç¨‹å¼€å§‹çš„æœˆä»½ã€‚\nhourï¼šè¡Œç¨‹å¼€å§‹çš„å°æ—¶ã€‚\n\nè¿™ä¸ªæ•°æ®ä¸€å…±æœ‰ 10000 è¡Œã€‚\n\n1.2.1 æ‹†åˆ†æ•°æ®\nåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ•°æ®é›†ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ç§ç±»å‹ï¼š\n\nè®­ç»ƒé›†ï¼ˆTraining Setï¼‰ï¼š\n\nå®šä¹‰ï¼š ç”¨äºè®­ç»ƒæ¨¡å‹çš„æ•°æ®é›†ã€‚\nä½œç”¨ï¼š æ¨¡å‹é€šè¿‡è®­ç»ƒé›†å­¦ä¹ ç‰¹å¾å’Œæ¨¡å¼ï¼Œè°ƒæ•´å‚æ•°ä»¥æœ€å°åŒ–é¢„æµ‹é”™è¯¯ã€‚\n\néªŒè¯é›†ï¼ˆValidation Setï¼‰ï¼š\n\nå®šä¹‰ï¼š ç”¨äºè°ƒæ•´æ¨¡å‹è¶…å‚æ•°ã€é€‰æ‹©æ¨¡å‹æˆ–é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ•°æ®é›†ã€‚\nä½œç”¨ï¼š é€šè¿‡åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè¿›è¡Œè¶…å‚æ•°è°ƒæ•´å’Œæ¨¡å‹é€‰æ‹©ã€‚\n\næµ‹è¯•é›†ï¼ˆTest Setï¼‰ï¼š\n\nå®šä¹‰ï¼š ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ€§èƒ½çš„æ•°æ®é›†ã€‚\nä½œç”¨ï¼š æµ‹è¯•é›†æä¾›äº†æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›çš„ä¼°è®¡ã€‚\n\n\nä½¿ç”¨ initial_split() å°†æ•°æ®æ‹†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚\n\nset.seed(123)\nlibrary(rsample)\n\n# random split\n(taxi_split &lt;- initial_split(taxi))\n\n&lt;Training/Testing/Total&gt;\n&lt;7500/2500/10000&gt;\n\n# access to split data\n(taxi_train &lt;- training(taxi_split))\n\n# A tibble: 7,500 Ã— 7\n   tip   distance company                   local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes       0.7  Taxi Affiliation Services yes   Tue   Mar      18\n 2 yes       0.99 Sun Taxi                  yes   Tue   Jan       8\n 3 yes       1.78 other                     no    Sat   Mar      22\n 4 yes       0    Taxi Affiliation Services yes   Wed   Apr      15\n 5 yes       0    Taxi Affiliation Services no    Sun   Jan      21\n 6 yes       2.3  other                     no    Sat   Apr      21\n 7 yes       6.35 Sun Taxi                  no    Wed   Mar      16\n 8 yes       2.79 other                     no    Sun   Feb      14\n 9 yes      16.6  other                     no    Sun   Apr      18\n10 yes       0.02 Chicago Independents      yes   Sun   Apr      15\n# â„¹ 7,490 more rows\n\n(taxi_test &lt;- testing(taxi_split))\n\n# A tibble: 2,500 Ã— 7\n   tip   distance company                      local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 2 yes       1    Taxi Affiliation Services    no    Mon   Feb      18\n 3 yes       1.91 Flash Cab                    no    Wed   Apr      15\n 4 yes       1.1  Chicago Independents         no    Sat   Mar      10\n 5 yes      11.7  other                        no    Wed   Mar      18\n 6 yes      17.8  City Service                 no    Mon   Mar       9\n 7 yes       0.53 Taxicab Insurance Agency Llc yes   Wed   Apr       8\n 8 yes       1.14 City Service                 no    Wed   Mar      14\n 9 yes       1.77 other                        no    Thu   Apr      15\n10 yes      18.6  Flash Cab                    no    Thu   Apr      12\n# â„¹ 2,490 more rows\n\n\nä½¿ç”¨ initial_validation_split() å°†æ•°æ®æ‹†åˆ†æˆè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚\n\nset.seed(123)\n(taxi_split_2 = initial_validation_split(taxi, prop = c(0.6, 0.2)))\n\n&lt;Training/Validation/Testing/Total&gt;\n&lt;6000/2000/2000/10000&gt;\n\ntraining(taxi_split_2)\n\n# A tibble: 6,000 Ã— 7\n   tip   distance company                      local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 3 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 4 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n 5 yes       0.53 Sun Taxi                     no    Tue   Mar      18\n 6 yes      16.8  Sun Taxi                     no    Wed   Apr      12\n 7 yes       0.86 other                        no    Tue   Feb      13\n 8 no        0.4  other                        yes   Fri   Mar      17\n 9 yes       0.1  Taxi Affiliation Services    no    Sun   Apr      10\n10 yes       1.6  Taxi Affiliation Services    no    Tue   Apr       8\n# â„¹ 5,990 more rows\n\ntesting(taxi_split_2)\n\n# A tibble: 2,000 Ã— 7\n   tip   distance company                      local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes       0.88 City Service                 yes   Thu   Mar       8\n 2 yes       1.47 City Service                 no    Tue   Mar      14\n 3 yes       1    other                        no    Fri   Mar      17\n 4 yes       1.35 Taxicab Insurance Agency Llc no    Thu   Feb      17\n 5 yes       1.14 City Service                 no    Wed   Mar      14\n 6 yes       1.77 other                        no    Thu   Apr      15\n 7 no        1.07 Sun Taxi                     no    Fri   Feb      15\n 8 no        1.13 other                        no    Sat   Feb      14\n 9 yes      12.1  Chicago Independents         no    Tue   Jan      11\n10 yes       1.91 Sun Taxi                     no    Tue   Jan      17\n# â„¹ 1,990 more rows\n\nvalidation(taxi_split_2)\n\n# A tibble: 2,000 Ã— 7\n   tip   distance company                      local dow   month  hour\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                        &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;\n 1 yes      18.1  other                        no    Mon   Feb      18\n 2 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 3 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 4 yes      17.7  other                        no    Sun   Jan       6\n 5 yes       6.65 Taxicab Insurance Agency Llc no    Sun   Apr      11\n 6 yes       1.21 Sun Taxi                     yes   Thu   Apr      19\n 7 yes       1    Taxi Affiliation Services    no    Mon   Feb      18\n 8 yes       1.91 Flash Cab                    no    Wed   Apr      15\n 9 yes       1.1  Chicago Independents         no    Sat   Mar      10\n10 no        0.96 Taxicab Insurance Agency Llc no    Mon   Apr       8\n# â„¹ 1,990 more rows\n\n\nä½¿ç”¨å‡½æ•°çš„ strataã€prop å‚æ•°ï¼Œä»¥åŠ initial_time_split()ã€group_initial_split() ç­‰å‡½æ•°ï¼Œå¯ä»¥å®ç°æ›´ç§‘å­¦çš„éšæœºåˆ†ç»„ã€‚"
  },
  {
    "objectID": "11.tidymodels-basic.html#æ¨¡å‹çš„ç»“æ„",
    "href": "11.tidymodels-basic.html#æ¨¡å‹çš„ç»“æ„",
    "title": "1Â  Basic tidymodels",
    "section": "1.3 æ¨¡å‹çš„ç»“æ„",
    "text": "1.3 æ¨¡å‹çš„ç»“æ„\nåœ¨ R ä¸­ä½¿ç”¨ tidymodels è¿›è¡Œå»ºæ¨¡çš„åŸºæœ¬æ­¥éª¤å¦‚ä¸‹ï¼š\n\né€‰æ‹©æ¨¡å‹ï¼š\n\né€‰æ‹©é€‚åˆä»»åŠ¡çš„æ¨¡å‹ï¼Œä¾‹å¦‚çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ã€‚\n\næŒ‡å®šå¼•æ“ï¼š\n\næŒ‡å®šæ¨¡å‹ä½¿ç”¨çš„å¼•æ“ï¼Œå¦‚ â€œlmâ€ æˆ– â€œglmnetâ€ã€‚\n\nè®¾ç½®æ¨¡å‹æ¨¡å¼ï¼š\n\nè®¾ç½®æ¨¡å‹çš„æ¨¡å¼ï¼Œæ˜¯ç”¨äºåˆ†ç±»è¿˜æ˜¯å›å½’ã€‚\n\n\n\n\n\n\n\n\nNote\n\n\n\nModels have default engines.\nSome models have a default mode.\n\n\n\n# ä½¿ç”¨é»˜è®¤å¼•æ“çš„é€»è¾‘å›å½’æ¨¡å‹\nlogistic_reg()\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n# ä½¿ç”¨ glmnet å¼•æ“çš„é€»è¾‘å›å½’æ¨¡å‹\nlogistic_reg() %&gt;%\n  set_engine(\"glmnet\")\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glmnet \n\n# ä½¿ç”¨ stan å¼•æ“çš„é€»è¾‘å›å½’æ¨¡å‹\nlogistic_reg() %&gt;%\n  set_engine(\"stan\")\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: stan \n\n# æœªæŒ‡å®šæ¨¡å¼çš„å†³ç­–æ ‘\ndecision_tree()\n\nDecision Tree Model Specification (unknown mode)\n\nComputational engine: rpart \n\n# æŒ‡å®šåˆ†ç±»æ¨¡å¼çš„å†³ç­–æ ‘\ndecision_tree() %&gt;% \n  set_mode(\"classification\")\n\nDecision Tree Model Specification (classification)\n\nComputational engine: rpart \n\n\n\n\n\n\n\n\nTip\n\n\n\nAll available models are listed at https://www.tidymodels.org/find/parsnip/\n\n\n\n1.3.1 æ¨¡å‹ä¸å¼•æ“çš„å·®å¼‚\nåœ¨ tidymodels ä¸­ï¼Œæ¨¡å‹å’Œè®¡ç®—å¼•æ“æ˜¯åˆ†å¼€çš„ã€‚è¿™å…è®¸ä½ ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹è§„æ ¼ï¼Œä½†å¯ä»¥é€‰æ‹©ç”¨äºè®­ç»ƒæ¨¡å‹çš„ä¸åŒç®—æ³•æˆ–ç¨‹åºåŒ…ã€‚\næ¨¡å‹å¼•æ“æ˜¯æŒ‡ç”¨äºå®ç°ç‰¹å®šç±»å‹æ¨¡å‹çš„è½¯ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªRåŒ…ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¯èƒ½çš„å¼•æ“åŒ…æ‹¬\"lm\"ã€\"glmnet\"ã€\"spark\"ç­‰ï¼Œæ¯ä¸ªéƒ½å¯¹åº”ä¸åŒçš„å®ç°æ–¹æ³•ã€‚\nä¸åŒçš„å¼•æ“å¯èƒ½ä¼šæœ‰ä»¥ä¸‹å‡ ç§å·®å¼‚ï¼š\n\nè®¡ç®—æ•ˆç‡ï¼šä¸€äº›å¼•æ“å¯èƒ½åœ¨å¤§æ•°æ®é›†ä¸Šæ›´æœ‰æ•ˆç‡ï¼Œè€Œå…¶ä»–å¼•æ“åœ¨å°æ•°æ®é›†ä¸Šå¯èƒ½æ›´å¿«ã€‚\nåŠŸèƒ½ï¼šä¸€äº›å¼•æ“å¯èƒ½åªæ”¯æŒæŸäº›ç‰¹å®šçš„åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œ\"glmnet\"å¼•æ“æ”¯æŒL1å’ŒL2æ­£åˆ™åŒ–ï¼Œè€Œ\"lm\"å¼•æ“åˆ™ä¸æ”¯æŒã€‚\nå¯æ‰©å±•æ€§ï¼šæŸäº›å¼•æ“ï¼ˆå¦‚\"spark\"ï¼‰å¯èƒ½è¢«è®¾è®¡ä¸ºå¯ä»¥åœ¨åˆ†å¸ƒå¼è®¡ç®—ç¯å¢ƒä¸­è¿è¡Œï¼Œä»è€Œå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ã€‚\nç»“æœï¼šç”±äºé‡‡ç”¨çš„ä¼˜åŒ–ç®—æ³•å’Œéšæœºåˆå§‹åŒ–ç­‰å› ç´ çš„å½±å“ï¼Œä¸åŒå¼•æ“å¯èƒ½ä¼šå¾—åˆ°ç•¥å¾®ä¸åŒçš„ç»“æœã€‚\n\næ€»çš„æ¥è¯´ï¼Œé€‰æ‹©å“ªä¸ªå¼•æ“å¹¶æ²¡æœ‰å›ºå®šçš„ç­”æ¡ˆï¼Œå–å†³äºå…·ä½“çš„éœ€æ±‚å’Œç¯å¢ƒã€‚ä½ å¯èƒ½éœ€è¦æ ¹æ®è®¡ç®—èµ„æºã€æ•°æ®å¤§å°å’Œæ¨¡å‹å¤æ‚æ€§ç­‰å› ç´ æ¥é€‰æ‹©æœ€é€‚åˆçš„å¼•æ“ã€‚\nä¾‹å¦‚ï¼Œä¸‹é¢ä½¿ç”¨ä¸¤ç§ä¸åŒçš„ÃŸå¼•æ“åˆ›å»ºäº†éšæœºæ£®æ—æ¨¡å‹ã€‚\nåœ¨ tidymodels ä¸­ï¼Œåˆ›å»ºéšæœºæ£®æ—æ¨¡å‹è§„æ ¼å¯ä»¥ä½¿ç”¨ rand_forest() å‡½æ•°ã€‚ä½†æ˜¯ï¼Œå…·ä½“çš„è®­ç»ƒè¿‡ç¨‹ä¼šç”±ä½ é€‰æ‹©çš„è®¡ç®—å¼•æ“å†³å®šã€‚ä¸‹é¢æ˜¯ä¸¤ä¸ªä¾‹å­ï¼Œåˆ†åˆ«è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ \"ranger\" å¼•æ“å’Œ \"randomForest\" å¼•æ“ã€‚\n\nä½¿ç”¨ \"ranger\" å¼•æ“ï¼š\n\nlibrary(tidymodels)\n\n# åˆ›å»ºæ¨¡å‹è§„æ ¼\nrf_spec &lt;- rand_forest(mtry = 10, trees = 1000) %&gt;%\n   set_engine(\"ranger\", importance = 'impurity') %&gt;%\n   set_mode(\"classification\")\n\n# è®­ç»ƒæ¨¡å‹\nrf_fit &lt;- rf_spec %&gt;% fit(Class ~ ., data = your_data)\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®¾ç½®äº† mtry = 10ï¼ˆå³æ¯ä¸ªæ ‘èŠ‚ç‚¹è€ƒè™‘çš„å˜é‡æ•°ï¼‰å’Œ trees = 1000ï¼ˆç”Ÿæˆçš„æ ‘çš„æ•°é‡ï¼‰ã€‚ç„¶åæˆ‘ä»¬æŒ‡å®šäº†å¼•æ“ä¸º \"ranger\"ã€‚ranger åŒ…æä¾›äº†ä¸€ä¸ªå‚æ•° importanceï¼Œç”¨äºè®¡ç®—å˜é‡é‡è¦æ€§ï¼ˆè¿™é‡Œæˆ‘ä»¬è®¾ä¸º â€˜impurityâ€™ï¼Œè¡¨ç¤ºè®¡ç®—åŸºäºä¸çº¯åº¦çš„å˜é‡é‡è¦æ€§ï¼‰ã€‚\n\nä½¿ç”¨ \"randomForest\" å¼•æ“ï¼š\n\n# åˆ›å»ºæ¨¡å‹è§„æ ¼\nrf_spec &lt;- rand_forest(mtry = 10, trees = 1000) %&gt;%\n   set_engine(\"randomForest\", importance = TRUE) %&gt;%\n   set_mode(\"classification\")\n\n# è®­ç»ƒæ¨¡å‹\nrf_fit &lt;- rf_spec %&gt;% fit(Class ~ ., data = your_data)\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æŒ‡å®šäº†å¼•æ“ä¸º \"randomForest\"ã€‚randomForest åŒ…æä¾›äº†ä¸€ä¸ªå‚æ•° importanceï¼Œå¦‚æœè®¾ç½®ä¸º TRUEï¼Œåˆ™è®¡ç®—å˜é‡é‡è¦æ€§ã€‚\nä¸¤ä¸ªå¼•æ“çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼š\n\n\"ranger\" å¼•æ“é€šå¸¸æ¯” \"randomForest\" å¼•æ“æ›´å¿«ï¼Œä¸”èƒ½å¤„ç†æ›´å¤§çš„æ•°æ®é›†ã€‚\n\"ranger\" å¼•æ“æä¾›äº†æ›´å¤šçš„é€‰é¡¹æ¥è®¡ç®—å˜é‡é‡è¦æ€§ã€‚\n\næœ€ç»ˆçš„æ¨¡å‹ç»“æœå¯èƒ½ä¼šæœ‰äº›å¾®å°çš„å·®å¼‚ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªåŒ…åœ¨å®ç°éšæœºæ£®æ—æ—¶ä½¿ç”¨äº†ä¸åŒçš„æ–¹æ³•å’Œä¼˜åŒ–æŠ€æœ¯ã€‚"
  },
  {
    "objectID": "11.tidymodels-basic.html#å¼€å§‹å»ºæ¨¡",
    "href": "11.tidymodels-basic.html#å¼€å§‹å»ºæ¨¡",
    "title": "1Â  Basic tidymodels",
    "section": "1.4 å¼€å§‹å»ºæ¨¡",
    "text": "1.4 å¼€å§‹å»ºæ¨¡\nä½¿ç”¨ 2 ç§æ¨¡å‹å¯¹ taxi æ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚\n\nLogistic regression\nDecision trees\n\n\n1.4.1 é€»è¾‘å›å½’æ¨¡å‹\né€»è¾‘å›å½’æ¨¡å‹å°†äº‹ä»¶æ¦‚ç‡çš„å¯¹æ•°å‡ ç‡ï¼ˆlogitï¼‰å»ºæ¨¡ä¸ºé¢„æµ‹å˜é‡çš„çº¿æ€§ç»„åˆï¼š\n\n\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 \\cdot A\n\nåœ¨è¿™é‡Œï¼š\n\np æ˜¯äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\n\\beta_0 æ˜¯æˆªè·ï¼Œ\n\\beta_1 æ˜¯ä¸é¢„æµ‹å˜é‡ A ç›¸å…³çš„ç³»æ•°ã€‚\n\n\n\n1.4.2 å†³ç­–æ ‘\nä½¿ç”¨å†³ç­–æ ‘å»ºæ¨¡ã€‚\n\nåŸºäºé¢„æµ‹å˜é‡çš„ä¸€ç³»åˆ—åˆ’åˆ†æˆ– if/then è¯­å¥ï¼š\né¦–å…ˆï¼Œæ ‘ä¼šåœ¨æ»¡è¶³æŸäº›æ¡ä»¶ä¹‹å‰ï¼ˆå¦‚è¾¾åˆ°æœ€å¤§æ·±åº¦æˆ–æ²¡æœ‰æ›´å¤šæ•°æ®æ—¶ï¼‰ä¸æ–­åœ°â€œç”Ÿé•¿â€ï¼ˆgrowï¼‰ã€‚\nç„¶åï¼Œä¸ºäº†é™ä½æ ‘çš„å¤æ‚æ€§ï¼Œæ ‘ä¼šè¢«â€œä¿®å‰ªâ€ï¼ˆprunedï¼‰ã€‚\n\n\ntree_fit &lt;- decision_tree(mode = \"classification\") %&gt;% \n  fit(class ~ A, data = mutate(dat, class = forcats::fct_rev(class)))\n\ntree_preds &lt;- augment(tree_fit, new_data = bin_midpoints)\n\nlibrary(rpart.plot)\n\nè½½å…¥éœ€è¦çš„ç¨‹è¾‘åŒ…ï¼šrpart\n\n\n\nè½½å…¥ç¨‹è¾‘åŒ…ï¼š'rpart'\n\n\nThe following object is masked from 'package:dials':\n\n    prune\n\ntree_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot(roundint = FALSE)\n\n\n\n\nå»ºæ¨¡çš„æ•ˆæœå¦‚ä¸‹ï¼š\n\n\n\n\n\n\nCaution\n\n\n\nAll models are wrong, but some are useful!\n\n\n\n\n\n\n\nFigureÂ 1.2: é€»è¾‘å›å½’æ¨¡å‹ä¸å†³ç­–æ ‘çš„é¢„æµ‹ç»“æœç¤ºæ„ã€‚ï¼ˆAï¼‰é€šè¿‡é€»è¾‘å‡½æ•°ï¼ˆSå½¢å‡½æ•°ï¼‰ï¼Œæ‰¾åˆ°ä¸€æ¡åˆ†éš”ä¸¤ä¸ªç±»åˆ«çš„æ›²çº¿ã€‚å½“ p å¤§äº 0.5 æ—¶ï¼Œé¢„æµ‹çš„ç±»åˆ«ä¸º 1ï¼›å¦åˆ™ï¼Œä¸º 0ã€‚ S å½¢æ›²çº¿çš„å½¢çŠ¶å®ç°äº†ä¸¤ä¸ªç±»åˆ«ä¹‹é—´çš„å¹³æ»‘è¿‡æ¸¡ã€‚ï¼ˆBï¼‰ä½¿ç”¨å†³ç­–æ ‘å»ºæ¨¡ã€‚\n\n\n\n\n\n\n1.4.3 å°†æ¨¡å‹æ•´åˆä¸º workflow\nä½¿ç”¨ workflow() æœ‰ä¸€äº›æ˜æ˜¾çš„ä¼˜åŠ¿ï¼ˆFigureÂ 1.3ï¼‰ã€‚\n\nWorkflow åœ¨å¤„ç†æ–°æ•°æ®æ–¹é¢æ¯”åŸºæœ¬çš„ R å·¥å…·æ›´åŠ çµæ´»ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠæ–°çš„å› å­æ°´å¹³æ—¶ï¼šè¿™åœ¨å¤„ç†åˆ†ç±»å˜é‡æ—¶å°¤ä¸ºé‡è¦ã€‚\nå¯ä»¥ä½¿ç”¨æ›´å¤šçš„æ•°æ®é¢„å¤„ç†å™¨æ¥æå–ç‰¹å¾ï¼ˆåœ¨é«˜çº§ tidymodels ä¸­æ›´å¤šå…³äºç‰¹å¾æå–çš„å†…å®¹ï¼ï¼‰\nä¾¿äºåŒæ—¶å¤„ç†å¤šä¸ªæ¨¡å‹ã€‚\næœ€é‡è¦çš„æ˜¯ï¼ŒWorkflow æ¶µç›–äº†æ•´ä¸ªå»ºæ¨¡è¿‡ç¨‹ï¼šfit() å’Œ predict() ä¸ä»…é€‚ç”¨äºæ¨¡å‹æ‹Ÿåˆï¼Œè¿˜é€‚ç”¨äºé¢„å¤„ç†æ­¥éª¤ã€‚\n\n\n\n\n\n\n\nWorkflow å¦‚ä½•æ›´å¥½åœ°å¤„ç†å› å­æ°´å¹³\n\n\n\n\nå¼ºåˆ¶æ‰§è¡Œä¸å…è®¸åœ¨é¢„æµ‹æ—¶å‡ºç°æ–°å› å­æ°´å¹³çš„è§„å®šï¼ˆå¯ä»¥å…³é—­ï¼‰\næ¢å¤åœ¨æ‹Ÿåˆæ—¶å­˜åœ¨ä½†åœ¨é¢„æµ‹æ—¶ç¼ºå¤±çš„å› å­æ°´å¹³\n\n\n\n\n\n\nFigureÂ 1.3: Workflows bind preprocessors and models\n\n\nç»å…¸æ–¹æ³•\n\ntree_spec &lt;-\n  decision_tree(cost_complexity = 0.002) %&gt;% \n  set_mode(\"classification\")\n\ntree_spec %&gt;% \n  fit(tip ~ ., data = taxi_train) \n\nparsnip model object\n\nn= 7500 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7500 579 yes (0.92280000 0.07720000)  \n   2) distance&gt;=11.805 2169  83 yes (0.96173352 0.03826648) *\n   3) distance&lt; 11.805 5331 496 yes (0.90695929 0.09304071)  \n     6) distance&lt; 5.405 5061 419 yes (0.91721004 0.08278996) *\n     7) distance&gt;=5.405 270  77 yes (0.71481481 0.28518519)  \n      14) company=Chicago Independents,City Service,Sun Taxi,Taxicab Insurance Agency Llc,other 181  38 yes (0.79005525 0.20994475) *\n      15) company=Flash Cab,Taxi Affiliation Services 89  39 yes (0.56179775 0.43820225)  \n        30) dow=Sun,Mon,Wed,Thu,Sat 59  17 yes (0.71186441 0.28813559) *\n        31) dow=Tue,Fri 30   8 no (0.26666667 0.73333333) *\n\n\nworkflowæ–¹æ³•\n\ntree_spec &lt;-\n  decision_tree(cost_complexity = 0.002) %&gt;% \n  set_mode(\"classification\")\n\n# å»ºç«‹ä¸€ä¸ª workflowï¼ŒåŒæ—¶ä¿å­˜æ¨¡å‹å‚æ•°ï¼Œè¡¨è¾¾å¼å’Œæ•°æ®\nworkflow() %&gt;%\n  add_formula(tip ~ .) %&gt;%\n  add_model(tree_spec) %&gt;%\n  fit(data = taxi_train) \n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nn= 7500 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7500 579 yes (0.92280000 0.07720000)  \n   2) distance&gt;=11.805 2169  83 yes (0.96173352 0.03826648) *\n   3) distance&lt; 11.805 5331 496 yes (0.90695929 0.09304071)  \n     6) distance&lt; 5.405 5061 419 yes (0.91721004 0.08278996) *\n     7) distance&gt;=5.405 270  77 yes (0.71481481 0.28518519)  \n      14) company=Chicago Independents,City Service,Sun Taxi,Taxicab Insurance Agency Llc,other 181  38 yes (0.79005525 0.20994475) *\n      15) company=Flash Cab,Taxi Affiliation Services 89  39 yes (0.56179775 0.43820225)  \n        30) dow=Sun,Mon,Wed,Thu,Sat 59  17 yes (0.71186441 0.28813559) *\n        31) dow=Tue,Fri 30   8 no (0.26666667 0.73333333) *\n\n# æˆ–è€…å†™åœ¨ä¸€èµ·\nworkflow(tip ~ ., tree_spec) %&gt;% \n  fit(data = taxi_train) \n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nn= 7500 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7500 579 yes (0.92280000 0.07720000)  \n   2) distance&gt;=11.805 2169  83 yes (0.96173352 0.03826648) *\n   3) distance&lt; 11.805 5331 496 yes (0.90695929 0.09304071)  \n     6) distance&lt; 5.405 5061 419 yes (0.91721004 0.08278996) *\n     7) distance&gt;=5.405 270  77 yes (0.71481481 0.28518519)  \n      14) company=Chicago Independents,City Service,Sun Taxi,Taxicab Insurance Agency Llc,other 181  38 yes (0.79005525 0.20994475) *\n      15) company=Flash Cab,Taxi Affiliation Services 89  39 yes (0.56179775 0.43820225)  \n        30) dow=Sun,Mon,Wed,Thu,Sat 59  17 yes (0.71186441 0.28813559) *\n        31) dow=Tue,Fri 30   8 no (0.26666667 0.73333333) *\n\n\nEdit this code to make a workflow with your own model of choice.\nExtension/Challenge: Other than formulas, what kinds of preprocessors are supported?\n\n\n1.4.4 ä½¿ç”¨æ¨¡å‹é¢„æµ‹\næ¨èä½¿ç”¨ augment() æ–¹æ³•è¿›è¡Œé¢„æµ‹ï¼Œä¸ä¼ ç»Ÿçš„ predict() ç›¸æ¯”çš„å·®å¼‚å¦‚ä¸‹ã€‚\n\ntree_fit &lt;-\n  workflow(tip ~ ., tree_spec) %&gt;% \n  fit(data = taxi_train) \n\npredict(tree_fit, new_data = taxi_test)\n\n# A tibble: 2,500 Ã— 1\n   .pred_class\n   &lt;fct&gt;      \n 1 yes        \n 2 yes        \n 3 yes        \n 4 yes        \n 5 yes        \n 6 yes        \n 7 yes        \n 8 yes        \n 9 yes        \n10 yes        \n# â„¹ 2,490 more rows\n\naugment(tree_fit, new_data = taxi_test)\n\n# A tibble: 2,500 Ã— 10\n   tip   distance company local dow   month  hour .pred_class .pred_yes .pred_no\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n 1 yes       0.94 Sun Taâ€¦ yes   Sat   Apr      23 yes             0.917   0.0828\n 2 yes       1    Taxi Aâ€¦ no    Mon   Feb      18 yes             0.917   0.0828\n 3 yes       1.91 Flash â€¦ no    Wed   Apr      15 yes             0.917   0.0828\n 4 yes       1.1  Chicagâ€¦ no    Sat   Mar      10 yes             0.917   0.0828\n 5 yes      11.7  other   no    Wed   Mar      18 yes             0.790   0.210 \n 6 yes      17.8  City Sâ€¦ no    Mon   Mar       9 yes             0.962   0.0383\n 7 yes       0.53 Taxicaâ€¦ yes   Wed   Apr       8 yes             0.917   0.0828\n 8 yes       1.14 City Sâ€¦ no    Wed   Mar      14 yes             0.917   0.0828\n 9 yes       1.77 other   no    Thu   Apr      15 yes             0.917   0.0828\n10 yes      18.6  Flash â€¦ no    Thu   Apr      12 yes             0.962   0.0383\n# â„¹ 2,490 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n\né¢„æµ‹ç»“æœåœ¨ä¸€ä¸ª tibble ä¸­ï¼›\nåˆ—åå’Œæ•°æ®ç±»å‹æ›´åŠ æ¸…æ™°å’Œæ˜“äºç†è§£ï¼›\nè¡Œæ•°å’Œè¾“å‡ºç»“æœçš„è¡Œæ•°æ˜¯ç›¸åŒçš„ï¼Œç¡®ä¿äº†æ•°æ®çš„å¯¹åº”å…³ç³»ã€‚\n\n\n\n\n\n1.4.5 è§£é‡Šæ¨¡å‹\nä½¿ç”¨ extract_*() å‡½æ•°æå–æ¨¡å‹ workflow å¯¹è±¡çš„ç»„ä»¶ã€‚å¦‚ FigureÂ 1.4 å±•ç¤ºäº†ä¸Šé¢å†³ç­–æ ‘æ¨¡å‹çš„åˆ†ç±»è¿‡ç¨‹ã€‚\n\nlibrary(rpart.plot)\ntree_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot(roundint = FALSE)\n\n\n\n\nFigureÂ 1.4: å†³ç­–æ ‘çš„å†³ç­–è¿‡ç¨‹\n\n\n\n\nYou can use your fitted workflow for model and/or prediction explanations:\n\noverall variable importance, such as with the vip package\nflexible model explainers, such as with the DALEXtra package"
  },
  {
    "objectID": "11.tidymodels-basic.html#æ¨¡å‹çš„è¯„ä»·",
    "href": "11.tidymodels-basic.html#æ¨¡å‹çš„è¯„ä»·",
    "title": "1Â  Basic tidymodels",
    "section": "1.5 æ¨¡å‹çš„è¯„ä»·",
    "text": "1.5 æ¨¡å‹çš„è¯„ä»·\nå…ˆè®­ç»ƒä¸€ä¸ªå†³ç­–æ ‘æ¨¡å‹ï¼Œç„¶åå†è¯„ä»·è¯¥æ¨¡å‹çš„æ€§èƒ½ã€‚\n\nlibrary(tidymodels)\n\nset.seed(123)\ntaxi_split &lt;- initial_split(taxi, prop = 0.8, strata = tip)\ntaxi_train &lt;- training(taxi_split)\ntaxi_test &lt;- testing(taxi_split)\n\ntree_spec &lt;- decision_tree(cost_complexity = 0.0001, mode = \"classification\")\ntaxi_wflow &lt;- workflow(tip ~ ., tree_spec)\ntaxi_fit &lt;- fit(taxi_wflow, taxi_train)\n\n\n1.5.1 æ··æ·†çŸ©é˜µ\næ··æ·†çŸ©é˜µå°†çœŸå®å€¼å’Œé¢„æµ‹å€¼ä»¥çƒ­å›¾çš„å½¢æˆå‘ˆç°å‡ºæ¥ã€‚\n\nlibrary(ggplot2)\nlibrary(forcats)\np1 = augment(taxi_fit, new_data = taxi_train) %&gt;%\n  conf_mat(truth = tip, estimate = .pred_class) %&gt;%\n  autoplot(type = \"heatmap\") +\n  coord_equal()\n\n# é˜³æ€§ä¸é˜´æ€§\ndf = tibble(Truth = as_factor(c(\"yes\",\"yes\",\"no\",\"no\")),\nPrediction = as_factor(c(\"no\",\"yes\",\"no\",\"yes\")),\nlabel = c(\"FN\",\"TP\",\"TN\",\"FP\"))\np2 = ggplot(df, aes(Truth, Prediction, label = label)) +\ngeom_tile(fill = \"grey90\", color = \"grey\", linewidth = 1) +\ngeom_text() +\ncoord_equal() +\ntheme_minimal()\n\naplot::plot_list(p1, p2, labels = c(\"A\",\"B\"))\n\n\n\n\nFigureÂ 1.5: æ··æ·†çŸ©é˜µ\n\n\n\n\n\n\n1.5.2 å‡†ç¡®æ€§\næ ¹æ® EquationÂ 1.1 å¯ä»¥è®¡ç®—å‡†ç¡®æ€§ä¸º 0.927625ã€‚\n\naccuracy = \\frac{TP + TN}{TP+FP+TN+FN}\n\\tag{1.1}\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  accuracy(truth = tip, estimate = .pred_class)\n\n# A tibble: 1 Ã— 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.928\n\n\n\n\n1.5.3 æ•æ„Ÿæ€§\næ ¹æ® EquationÂ 1.2 å¯ä»¥è®¡ç®—å…¶æ•°å€¼ä¸º 0.9941766ã€‚\n\nsensitivity = \\frac{TP}{TP+FP}\n\\tag{1.2}\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  sensitivity(truth = tip, estimate = .pred_class)\n\n# A tibble: 1 Ã— 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 sensitivity binary         0.994\n\n\n\n\n1.5.4 ç‰¹å¼‚æ€§\næ ¹æ® EquationÂ 1.3 å¯ä»¥è®¡ç®—å…¶æ•°å€¼ä¸º 0.1298701ã€‚\n\nsensitivity = \\frac{TP}{TP+FP}\n\\tag{1.3}\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  specificity(truth = tip, estimate = .pred_class)\n\n# A tibble: 1 Ã— 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 specificity binary         0.130\n\n\n\n\n\n\n\n\nNote\n\n\n\n\næ•æ„Ÿæ€§å‘Šè¯‰æˆ‘ä»¬ï¼Œæµ‹è¯•æœ‰å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿæ•æ‰åˆ°çœŸæ­£çš„é˜³æ€§å®ä¾‹ï¼Œå³å¯¹äºå®é™…ä¸ºé˜³æ€§çš„æ ·æœ¬ï¼Œæµ‹è¯•æœ‰å¤šå¤§å¯èƒ½æ€§èƒ½å¤Ÿæ­£ç¡®åœ°è¯†åˆ«å‡ºå®ƒä»¬ã€‚\nç‰¹å¼‚æ€§å‘Šè¯‰æˆ‘ä»¬ï¼Œæµ‹è¯•æœ‰å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿæ­£ç¡®åœ°æ’é™¤å®é™…ä¸ºé˜´æ€§çš„æ ·æœ¬ï¼Œå³å¯¹äºå®é™…ä¸ºé˜´æ€§çš„æ ·æœ¬ï¼Œæµ‹è¯•æœ‰å¤šå¤§å¯èƒ½æ€§èƒ½å¤Ÿæ­£ç¡®åœ°å°†å®ƒä»¬è¯†åˆ«ä¸ºé˜´æ€§ã€‚\nå‡†ç¡®ç‡æ˜¯ä¸€ä¸ªç»¼åˆæ€§æŒ‡æ ‡ï¼Œè¡¡é‡äº†åˆ†ç±»æ¨¡å‹å¯¹äºæ‰€æœ‰æ ·æœ¬çš„æ•´ä½“é¢„æµ‹å‡†ç¡®æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬åœ¨æ‰€æœ‰æ ·æœ¬ä¸­çš„æ¯”ä¾‹ã€‚\n\n\n\nä½¿ç”¨ metric_set() å¯ä»¥ä¸€æ¬¡è·å–å¤šä¸ªæŒ‡æ ‡ï¼ˆå¦è§ FigureÂ 1.6ï¼‰ã€‚\n\ntaxi_metrics &lt;- metric_set(accuracy, specificity, sensitivity)\n\naugment(taxi_fit, new_data = taxi_train) %&gt;%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n\n# A tibble: 3 Ã— 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy    binary         0.928\n2 specificity binary         0.130\n3 sensitivity binary         0.994\n\n\n\n\n\n\n\nFigureÂ 1.6: æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§é€šå¸¸æ˜¯ä¸€å¯¹çŸ›ç›¾çš„æŒ‡æ ‡ï¼Œå³æé«˜æ•æ„Ÿæ€§å¯èƒ½ä¼šé™ä½ç‰¹å¼‚æ€§ï¼Œåä¹‹äº¦ç„¶ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€‰æ‹©å“ªä¸ªæŒ‡æ ‡æ›´é‡è¦å–å†³äºå…·ä½“çš„é—®é¢˜å’Œåº”ç”¨èƒŒæ™¯ã€‚\n\n\n\n\n\n\n1.5.5 ROC æ›²çº¿\nROCï¼ˆReceiver Operating Characteristicï¼‰æ›²çº¿æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°äºŒåˆ†ç±»æ¨¡å‹æ€§èƒ½çš„å›¾å½¢å·¥å…·ã€‚ä»¥ä¸‹æ˜¯å…³äºROCæ›²çº¿çš„å®šä¹‰å’Œè§£é‡Šï¼š\n\nå®šä¹‰ï¼š\n\nROCæ›²çº¿æ˜¯ä¸€ç§ä»¥å‡æ­£ä¾‹ç‡ï¼ˆFalse Positive Rateï¼ŒFPRï¼‰ä¸ºæ¨ªè½´ã€çœŸæ­£ä¾‹ç‡ï¼ˆTrue Positive Rateï¼ŒTPRæˆ–æ•æ„Ÿæ€§ï¼‰ä¸ºçºµè½´çš„å›¾å½¢ã€‚å®ƒæ˜¾ç¤ºäº†åœ¨ä¸åŒé˜ˆå€¼ä¸‹ï¼Œæ¨¡å‹çš„çœŸæ­£ä¾‹ç‡å’Œå‡æ­£ä¾‹ç‡ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚\n\nç»˜åˆ¶æ–¹å¼ï¼š\n\nåœ¨ROCæ›²çº¿ä¸­ï¼Œæ¨ªè½´è¡¨ç¤ºFPRï¼Œçºµè½´è¡¨ç¤ºTPRã€‚æ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡æˆ–åˆ†æ•°è¢«ç”¨ä½œä¸åŒé˜ˆå€¼ï¼Œä»è€Œç”Ÿæˆä¸€ç³»åˆ—çš„TPRå’ŒFPRå€¼ã€‚\n\nè§£é‡Šï¼š\n\nROCæ›²çº¿èƒ½å¤Ÿå±•ç¤ºåœ¨ä¸åŒåˆ†ç±»é˜ˆå€¼ä¸‹ï¼Œæ¨¡å‹åœ¨è¯†åˆ«æ­£ä¾‹ï¼ˆé˜³æ€§ç±»åˆ«ï¼‰å’Œè´Ÿä¾‹ï¼ˆé˜´æ€§ç±»åˆ«ï¼‰æ–¹é¢çš„æ€§èƒ½ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼ŒROCæ›²çº¿è¶Šé è¿‘å·¦ä¸Šè§’ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½ï¼Œå› ä¸ºåœ¨é‚£é‡Œï¼ŒTPRè¾ƒé«˜è€ŒFPRè¾ƒä½ã€‚\n\nAUCå€¼ï¼š\n\nROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆArea Under the Curveï¼ŒAUCï¼‰ä¹Ÿæ˜¯ä¸€ä¸ªå¸¸ç”¨çš„æ€§èƒ½åº¦é‡ã€‚AUCå€¼è¶Šæ¥è¿‘1ï¼Œè¡¨ç¤ºæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚AUCå€¼ä¸º0.5æ—¶ï¼Œè¡¨ç¤ºæ¨¡å‹çš„æ€§èƒ½ç­‰åŒäºéšæœºçŒœæµ‹ã€‚\n\nç¤ºä¾‹ï¼š\n\nä¸€ä¸ªç†æƒ³çš„ROCæ›²çº¿ä¼šæ²¿ç€å·¦ä¸Šè§’çš„è¾¹ç¼˜ï¼Œæœ€ç»ˆè¾¾åˆ°ï¼ˆ0, 1ï¼‰ç‚¹ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒROCæ›²çº¿åœ¨å›¾å½¢ä¸Šæ˜¯å‘å·¦ä¸Šå‡¸èµ·çš„ã€‚\n\n\nåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒROCæ›²çº¿å’ŒAUCå€¼æ˜¯è¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½çš„é‡è¦å·¥å…·ï¼Œå°¤å…¶åœ¨å¤„ç†ä¸åŒç±»åˆ«åˆ†å¸ƒå’Œä¸åŒé˜ˆå€¼çš„æƒ…å†µä¸‹ã€‚\ngiven that sensitivity is the true positive rate, and specificity is the true negative rate. Hence 1 - specificity is the false positive rate.\nWe can use the area under the ROC curve as a classification metric:\n\nROC AUC = 1 ğŸ’¯\nROC AUC = 1/2 ğŸ˜¢\n\n\n# Assumes _first_ factor level is event; there are options to change that\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_curve(truth = tip, .pred_yes) %&gt;%\n  slice(1, 20, 50)\n\n# A tibble: 3 Ã— 3\n  .threshold specificity sensitivity\n       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1   -Inf           0         1      \n2      0.783       0.209     0.981  \n3      1           1         0.00135\n\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_auc(truth = tip, .pred_yes)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.691\n\n\nFigureÂ 1.7 æ˜¾ç¤ºäº†ä¸Šé¢è¿™ä¸ªæ¨¡å‹çš„ ROC æ›²çº¿ã€‚\n\naugment(taxi_fit, new_data = taxi_train) %&gt;% \n  roc_curve(truth = tip, .pred_yes) %&gt;%\n  autoplot()\n\n\n\n\nFigureÂ 1.7: è¿™ä¸ªæ¨¡å‹çš„ ROC AUC å€¼ä¸º 0.691ã€‚\n\n\n\n\n\n\n1.5.6 è¿‡æ‹Ÿåˆ\nå°†è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹åˆ†åˆ«ç”¨äºè®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ï¼Œæ¯”è¾ƒäºŒè€…é¢„æµ‹çš„å‡†ç¡®ç‡ï¼Œå¯ä»¥å‘ç°é¢„æµ‹è®­ç»ƒæ•°æ®é›†çš„ç»“æœä¼˜äºæµ‹è¯•æ•°æ®é›†ã€‚è¿™å°±æ˜¯æ¨¡å‹çš„è¿‡æ‹Ÿåˆç°è±¡ï¼ˆFigureÂ 1.8ï¼‰ã€‚\n\n\n\nFigureÂ 1.8: è¿‡æ‹Ÿåˆ\n\n\né¦–å…ˆï¼Œæ¯”è¾ƒä¸€ä¸‹æ¨¡å‹çš„å‡†ç¡®æ€§æŒ‡æ ‡ã€‚\n\n# æ¨¡å‹é¢„æµ‹è®­ç»ƒæ•°æ®é›†\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  accuracy(tip, .pred_class)\n\n# A tibble: 1 Ã— 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.928\n\n# æ¨¡å‹é¢„æµ‹æµ‹è¯•æ•°æ®é›†\ntaxi_fit %&gt;%\n  augment(taxi_test) %&gt;%\n  accuracy(tip, .pred_class)\n\n# A tibble: 1 Ã— 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.908\n\n\nå…¶æ¬¡ï¼Œæ¯”è¾ƒä¸€ä¸‹ Brier åˆ†æ•°ã€‚\n\ntaxi_fit %&gt;%\n  augment(taxi_train) %&gt;%\n  brier_class(tip, .pred_yes)\n\n# A tibble: 1 Ã— 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 brier_class binary        0.0632\n\ntaxi_fit %&gt;%\n  augment(taxi_test) %&gt;%\n  brier_class(tip, .pred_yes)\n\n# A tibble: 1 Ã— 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 brier_class binary        0.0782\n\n\nBrieråˆ†æ•°ï¼ˆBrier Scoreï¼‰æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ã€‚å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼ŒBrieråˆ†æ•°çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n\nBrier\\ Score = \\frac{1}{N} \\sum_{i=1}^{N} (f_i - o_i)^2\n\nå…¶ä¸­ï¼š\n\nN æ˜¯æ ·æœ¬æ•°ï¼›\nf_i æ˜¯æ¨¡å‹å¯¹äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡çš„é¢„æµ‹å€¼ï¼›\no_i æ˜¯å®é™…è§‚æµ‹åˆ°çš„äºŒåˆ†ç±»ç»“æœï¼Œå–å€¼ä¸º0æˆ–1ï¼ˆä¾‹å¦‚ï¼Œäº‹ä»¶æœªå‘ç”Ÿä¸º0ï¼Œäº‹ä»¶å‘ç”Ÿä¸º1ï¼‰ã€‚\n\nBrieråˆ†æ•°çš„å–å€¼èŒƒå›´åœ¨0åˆ°1ä¹‹é—´ï¼Œ0è¡¨ç¤ºå®Œç¾é¢„æµ‹ï¼Œ1è¡¨ç¤ºæœ€å·®çš„é¢„æµ‹ã€‚è¾ƒä½çš„Brieråˆ†æ•°è¡¨ç¤ºæ¨¡å‹å¯¹è§‚æµ‹ç»“æœçš„æ¦‚ç‡é¢„æµ‹æ›´å‡†ç¡®ã€‚æ‰€ä»¥ï¼Œä»ç„¶å¯ä»¥å‘ç°æ¨¡å‹è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚\n\n\n1.5.7 äº¤å‰éªŒè¯\nåœ¨ä¸ä½¿ç”¨æµ‹è¯•æ•°æ®é›†çš„å‰æä¸‹ï¼Œèƒ½ä¸èƒ½æ¯”è¾ƒæ¨¡å‹çš„å‚æ•°ï¼Ÿè¿™å°±è¦ç”¨åˆ°äº¤å‰éªŒè¯ã€‚vfold_cv() å‡½æ•°é»˜è®¤å°†è®­ç»ƒæ•°æ®é›†ä¸­çš„ååˆ†ä¹‹ä¸€ï¼ˆv = 10ï¼‰å–å‡ºæ¥ï¼Œç”¨äºè®¡ç®—ã€æ¯”è¾ƒæ¨¡å‹çš„æ€§èƒ½å‚æ•°ã€‚\n\nset.seed(123)\ntaxi_folds &lt;- vfold_cv(taxi_train, v = 10, strata = tip)\ntaxi_folds\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 Ã— 2\n   splits             id    \n   &lt;list&gt;             &lt;chr&gt; \n 1 &lt;split [7200/800]&gt; Fold01\n 2 &lt;split [7200/800]&gt; Fold02\n 3 &lt;split [7200/800]&gt; Fold03\n 4 &lt;split [7200/800]&gt; Fold04\n 5 &lt;split [7200/800]&gt; Fold05\n 6 &lt;split [7200/800]&gt; Fold06\n 7 &lt;split [7200/800]&gt; Fold07\n 8 &lt;split [7200/800]&gt; Fold08\n 9 &lt;split [7200/800]&gt; Fold09\n10 &lt;split [7200/800]&gt; Fold10\n\n\nä½¿ç”¨ fit_resamples() å‡½æ•°æ¥å¯¹å¤šæ¬¡å–æ ·çš„æ•°æ®è¿›è¡Œæ‹Ÿåˆï¼Œä½¿ç”¨ collect_mertics() è¯„ä»·æ¨¡å‹çš„æ€§èƒ½ã€‚\n\ntaxi_res &lt;- fit_resamples(taxi_wflow, taxi_folds)\ntaxi_res\n\n# Resampling results\n# 10-fold cross-validation using stratification \n# A tibble: 10 Ã— 4\n   splits             id     .metrics         .notes          \n   &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n 9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt;\n\n\n\ntaxi_res %&gt;%\n  collect_metrics()\n\n# A tibble: 2 Ã— 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.915    10 0.00309 Preprocessor1_Model1\n2 roc_auc  binary     0.624    10 0.0105  Preprocessor1_Model1\n\n\n\n\n\n\n\n\nNote\n\n\n\ncollect_metrics() is one of a suite of collect_*() functions that can be used to work with columns of tuning results. Most columns in a tuning result prefixed with . have a corresponding collect_*() function with options for common summaries.\n\n\näº¤å‰éªŒè¯é€šè¿‡é‡é‡‡æ ·å’Œæ€§èƒ½æ¯”è¾ƒï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥åœ¨ä»…ä½¿ç”¨è®­ç»ƒé›†å°±å¯ä»¥å¯é åœ°æ¯”è¾ƒæ¨¡å‹çš„æ€§èƒ½ã€‚\n\n\n\n\n\n\nWarning\n\n\n\nè®°ä½ï¼š\n\nè®­ç»ƒé›†ä¼šç»™å‡ºè¿‡äºä¹è§‚çš„æŒ‡æ ‡\næµ‹è¯•é›†éå¸¸å®è´µ\n\n\n\n\n# Save the assessment set results\nctrl_taxi &lt;- control_resamples(save_pred = TRUE)\ntaxi_res &lt;- fit_resamples(taxi_wflow, taxi_folds, control = ctrl_taxi)\n\ntaxi_res\n\n# Resampling results\n# 10-fold cross-validation using stratification \n# A tibble: 10 Ã— 5\n   splits             id     .metrics         .notes           .predictions\n   &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n\n# Save the assessment set results\ntaxi_preds &lt;- collect_predictions(taxi_res)\ntaxi_preds\n\n# A tibble: 8,000 Ã— 7\n   id     .pred_yes .pred_no  .row .pred_class tip   .config             \n   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt; &lt;chr&gt;               \n 1 Fold01     0.938   0.0615    14 yes         yes   Preprocessor1_Model1\n 2 Fold01     0.946   0.0544    19 yes         yes   Preprocessor1_Model1\n 3 Fold01     0.973   0.0269    33 yes         yes   Preprocessor1_Model1\n 4 Fold01     0.903   0.0971    43 yes         yes   Preprocessor1_Model1\n 5 Fold01     0.973   0.0269    74 yes         yes   Preprocessor1_Model1\n 6 Fold01     0.903   0.0971   103 yes         yes   Preprocessor1_Model1\n 7 Fold01     0.915   0.0851   104 yes         no    Preprocessor1_Model1\n 8 Fold01     0.903   0.0971   124 yes         yes   Preprocessor1_Model1\n 9 Fold01     0.667   0.333    126 yes         yes   Preprocessor1_Model1\n10 Fold01     0.949   0.0510   128 yes         yes   Preprocessor1_Model1\n# â„¹ 7,990 more rows\n\n# Evaluating model performance\ntaxi_preds %&gt;% \n  group_by(id) %&gt;%\n  taxi_metrics(truth = tip, estimate = .pred_class)\n\n# A tibble: 30 Ã— 4\n   id     .metric  .estimator .estimate\n   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n 1 Fold01 accuracy binary         0.905\n 2 Fold02 accuracy binary         0.925\n 3 Fold03 accuracy binary         0.926\n 4 Fold04 accuracy binary         0.915\n 5 Fold05 accuracy binary         0.902\n 6 Fold06 accuracy binary         0.912\n 7 Fold07 accuracy binary         0.906\n 8 Fold08 accuracy binary         0.91 \n 9 Fold09 accuracy binary         0.918\n10 Fold10 accuracy binary         0.931\n# â„¹ 20 more rows\n\ntaxi_res\n\n# Resampling results\n# 10-fold cross-validation using stratification \n# A tibble: 10 Ã— 5\n   splits             id     .metrics         .notes           .predictions\n   &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [7200/800]&gt; Fold01 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [7200/800]&gt; Fold02 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [7200/800]&gt; Fold03 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [7200/800]&gt; Fold04 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [7200/800]&gt; Fold05 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [7200/800]&gt; Fold06 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [7200/800]&gt; Fold07 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [7200/800]&gt; Fold08 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [7200/800]&gt; Fold09 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n10 &lt;split [7200/800]&gt; Fold10 &lt;tibble [2 Ã— 4]&gt; &lt;tibble [0 Ã— 3]&gt; &lt;tibble&gt;    \n\n\näº¤å‰éªŒè¯çš„è’™ç‰¹å¡æ´›æ–¹æ³•ï¼Œä»¥åŠåˆ›å»ºéªŒè¯æ•°æ®é›†ã€‚\n\nset.seed(322)\n# use the Monte Carlo Cross-Validation\nmc_cv(taxi_train, times = 10)\n\n# Monte Carlo cross-validation (0.75/0.25) with 10 resamples  \n# A tibble: 10 Ã— 2\n   splits              id        \n   &lt;list&gt;              &lt;chr&gt;     \n 1 &lt;split [6000/2000]&gt; Resample01\n 2 &lt;split [6000/2000]&gt; Resample02\n 3 &lt;split [6000/2000]&gt; Resample03\n 4 &lt;split [6000/2000]&gt; Resample04\n 5 &lt;split [6000/2000]&gt; Resample05\n 6 &lt;split [6000/2000]&gt; Resample06\n 7 &lt;split [6000/2000]&gt; Resample07\n 8 &lt;split [6000/2000]&gt; Resample08\n 9 &lt;split [6000/2000]&gt; Resample09\n10 &lt;split [6000/2000]&gt; Resample10\n\n# create validation set\ntaxi_val_split &lt;- initial_validation_split(taxi, strata = tip)\nvalidation_set(taxi_val_split)\n\n# A tibble: 1 Ã— 2\n  splits              id        \n  &lt;list&gt;              &lt;chr&gt;     \n1 &lt;split [6000/2000]&gt; validation"
  },
  {
    "objectID": "11.tidymodels-basic.html#éšæœºæ£®æ—æ¨¡å‹",
    "href": "11.tidymodels-basic.html#éšæœºæ£®æ—æ¨¡å‹",
    "title": "1Â  Basic tidymodels",
    "section": "1.6 éšæœºæ£®æ—æ¨¡å‹",
    "text": "1.6 éšæœºæ£®æ—æ¨¡å‹\nåœ¨äº†è§£äº†æ¨¡å‹è¯„ä»·æŒ‡æ ‡ä¹‹åï¼Œæˆ‘ä»¬å†å»ºä¸€ä¸ªéšæœºæ£®æ—æ¨¡å‹ï¼Œçœ‹çœ‹è¿™ä¸ªæ¨¡å‹çš„æ€§èƒ½æ˜¯ä¸æ˜¯ä¼šä¼˜äºå†³ç­–æ ‘ã€‚\néšæœºæ£®æ—ï¼ˆRandom Forestï¼‰æ˜¯ä¸€ç§é›†æˆå­¦ä¹ ï¼ˆEnsemble Learningï¼‰æ–¹æ³•ï¼Œç”¨äºè§£å†³åˆ†ç±»å’Œå›å½’é—®é¢˜ã€‚å®ƒå»ºç«‹åœ¨å†³ç­–æ ‘çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡æ„å»ºå¤šä¸ªå†³ç­–æ ‘å¹¶ç»“åˆå®ƒä»¬çš„é¢„æµ‹ç»“æœæ¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚\nä»¥ä¸‹æ˜¯éšæœºæ£®æ—æ¨¡å‹çš„ä¸»è¦ç‰¹ç‚¹å’Œå·¥ä½œåŸç†ï¼š\n\nå†³ç­–æ ‘åŸºå­¦ä¹ å™¨ï¼š éšæœºæ£®æ—ç”±å¤šä¸ªå†³ç­–æ ‘ç»„æˆã€‚æ¯ä¸ªå†³ç­–æ ‘éƒ½æ˜¯ç‹¬ç«‹è®­ç»ƒçš„ï¼Œé‡‡ç”¨ä¸åŒçš„éšæœºå­é›†æ•°æ®ã€‚è¿™æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¢åŠ æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\néšæœºå­é›†ï¼ˆBootstrapæŠ½æ ·ï¼‰ï¼š åœ¨è®­ç»ƒæ¯ä¸ªå†³ç­–æ ‘æ—¶ï¼Œéšæœºæ£®æ—ä½¿ç”¨è‡ªåŠ©æŠ½æ ·ï¼ˆBootstrap Samplingï¼‰ä»è®­ç»ƒé›†ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå­é›†ã€‚è¿™æ„å‘³ç€æ¯ä¸ªå†³ç­–æ ‘çš„è®­ç»ƒæ•°æ®éƒ½æ˜¯ä»åŸå§‹è®­ç»ƒé›†ä¸­æœ‰æ”¾å›åœ°éšæœºæŠ½å–çš„ã€‚\néšæœºç‰¹å¾é€‰æ‹©ï¼š åœ¨æ¯ä¸ªå†³ç­–æ ‘çš„èŠ‚ç‚¹ä¸Šï¼Œéšæœºæ£®æ—åªè€ƒè™‘ç‰¹å¾çš„éšæœºå­é›†è¿›è¡Œåˆ’åˆ†ã€‚è¿™æ ·åšæœ‰åŠ©äºç¡®ä¿æ¯ä¸ªå†³ç­–æ ‘çš„å¤šæ ·æ€§ï¼Œé˜²æ­¢æ‰€æœ‰å†³ç­–æ ‘è¿‡äºç›¸ä¼¼ã€‚\næŠ•ç¥¨æœºåˆ¶ï¼š å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œéšæœºæ£®æ—é€šè¿‡å¤šæ•°æŠ•ç¥¨åŸåˆ™ï¼ˆMajority Votingï¼‰æ¥ç¡®å®šæœ€ç»ˆçš„åˆ†ç±»ç»“æœã€‚å¯¹äºå›å½’é—®é¢˜ï¼Œéšæœºæ£®æ—å–å¤šä¸ªå†³ç­–æ ‘çš„å¹³å‡é¢„æµ‹ç»“æœã€‚\né«˜æ€§èƒ½å’Œé²æ£’æ€§ï¼š éšæœºæ£®æ—é€šå¸¸å¯¹äºå„ç§ç±»å‹çš„æ•°æ®å’Œé—®é¢˜éƒ½è¡¨ç°å¾—å¾ˆå¥½ã€‚å®ƒä»¬èƒ½å¤Ÿå¤„ç†å¤§é‡ç‰¹å¾å’Œæ ·æœ¬ï¼Œå…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œå¯¹äºå¤„ç†å™ªå£°å’Œå¤æ‚å…³ç³»ä¹Ÿæœ‰è‰¯å¥½çš„é€‚åº”æ€§ã€‚\n\néšæœºæ£®æ—çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå…¶ç®€å•è€Œå¼ºå¤§çš„é›†æˆå­¦ä¹ ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°é™ä½è¿‡æ‹Ÿåˆé£é™©ï¼Œå¹¶åœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­è¡¨ç°ä¼˜å¼‚ã€‚ç”±äºå…¶å¯è§£é‡Šæ€§ã€é²æ£’æ€§å’Œé«˜æ€§èƒ½ï¼Œéšæœºæ£®æ—æˆä¸ºäº†è®¸å¤šæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ é—®é¢˜çš„é¦–é€‰æ¨¡å‹ä¹‹ä¸€ã€‚\nBootstrap aggregatingï¼Œé€šå¸¸ç®€ç§°ä¸º Baggingï¼Œæ˜¯ä¸€ç§é›†æˆå­¦ä¹ çš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œè‡ªåŠ©æŠ½æ ·ï¼ˆBootstrap Samplingï¼‰ï¼Œåˆ›å»ºå¤šä¸ªæ•°æ®å­é›†ï¼Œç„¶ååˆ†åˆ«è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œæœ€åå°†å®ƒä»¬çš„é¢„æµ‹ç»“æœè¿›è¡Œç»„åˆã€‚\nä¸‹é¢ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹å»ºæ¨¡ï¼Œå¹¶æ£€æŸ¥å¾—åˆ°æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡ã€‚\n\n# initialize a random forest model\nrf_spec &lt;- rand_forest(trees = 1000, mode = \"classification\")\nrf_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  trees = 1000\n\nComputational engine: ranger \n\n# Create a random forest model (workflow)\nrf_wflow &lt;- workflow(tip ~ ., rf_spec)\nrf_wflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  trees = 1000\n\nComputational engine: ranger \n\nctrl_taxi &lt;- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\nset.seed(2)\ntaxi_folds = vfold_cv(taxi_train, strata = tip)\nrf_res &lt;- fit_resamples(rf_wflow, taxi_folds, control = ctrl_taxi)\ncollect_metrics(rf_res)\n\n# A tibble: 2 Ã— 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.923    10 0.00336 Preprocessor1_Model1\n2 roc_auc  binary     0.612    10 0.0178  Preprocessor1_Model1\n\n# taxi_split has train + test info\nfinal_fit &lt;- last_fit(rf_wflow, taxi_split) \nfinal_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 Ã— 6\n  splits              id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;              &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [8000/2000]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n## What is in final_fit\ncollect_metrics(final_fit)\n\n# A tibble: 2 Ã— 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.914 Preprocessor1_Model1\n2 roc_auc  binary         0.644 Preprocessor1_Model1\n\n# metrics computed with the test set\ncollect_predictions(final_fit)\n\n# A tibble: 2,000 Ã— 7\n   id               .pred_yes .pred_no  .row .pred_class tip   .config          \n   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt; &lt;chr&gt;            \n 1 train/test split     0.958  0.0415      4 yes         yes   Preprocessor1_Moâ€¦\n 2 train/test split     0.931  0.0689     10 yes         yes   Preprocessor1_Moâ€¦\n 3 train/test split     0.969  0.0313     19 yes         yes   Preprocessor1_Moâ€¦\n 4 train/test split     0.889  0.111      23 yes         yes   Preprocessor1_Moâ€¦\n 5 train/test split     0.945  0.0551     28 yes         yes   Preprocessor1_Moâ€¦\n 6 train/test split     0.981  0.0193     34 yes         yes   Preprocessor1_Moâ€¦\n 7 train/test split     0.952  0.0476     35 yes         yes   Preprocessor1_Moâ€¦\n 8 train/test split     0.936  0.0637     38 yes         yes   Preprocessor1_Moâ€¦\n 9 train/test split     0.991  0.00895    40 yes         yes   Preprocessor1_Moâ€¦\n10 train/test split     0.947  0.0526     42 yes         no    Preprocessor1_Moâ€¦\n# â„¹ 1,990 more rows\n\n## What is in final_fit\nextract_workflow(final_fit)\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  1000 \nSample size:                      8000 \nNumber of independent variables:  6 \nMtry:                             2 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.07054061"
  },
  {
    "objectID": "11.tidymodels-basic.html#æ¨¡å‹çš„è°ƒä¼˜",
    "href": "11.tidymodels-basic.html#æ¨¡å‹çš„è°ƒä¼˜",
    "title": "1Â  Basic tidymodels",
    "section": "1.7 æ¨¡å‹çš„è°ƒä¼˜",
    "text": "1.7 æ¨¡å‹çš„è°ƒä¼˜\n\n1.7.1 ä¸ºä»€ä¹ˆè¦è°ƒä¼˜ï¼Ÿ\næ¨¡å‹è°ƒæ•´ï¼ˆtuningï¼‰æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªé‡è¦æ­¥éª¤ï¼Œä¸»è¦å‡ºäºä»¥ä¸‹å‡ ä¸ªåŸå› ï¼š\n\næé«˜æ¨¡å‹æ€§èƒ½ï¼šè°ƒæ•´æ¨¡å‹å‚æ•°å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ‰¾åˆ°æœ€ä¼˜çš„å‚æ•°ç»„åˆï¼Œä»è€Œä½¿æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå®ç°æœ€ä½³æ€§èƒ½ã€‚\né¿å…è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆï¼šé€šè¿‡é€‚å½“çš„æ¨¡å‹è°ƒæ•´ï¼Œæˆ‘ä»¬å¯ä»¥å¹³è¡¡æ¨¡å‹çš„åå·®å’Œæ–¹å·®ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼ˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°å·®ï¼‰å’Œæ¬ æ‹Ÿåˆï¼ˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°éƒ½ä¸å¥½ï¼‰ã€‚\né€‚åº”ä¸åŒçš„æ•°æ®åˆ†å¸ƒï¼šä¸åŒçš„æ•°æ®é›†æœ‰å…¶ç‰¹å¼‚æ€§ï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„å‚æ•°é…ç½®æ‰èƒ½è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæœã€‚é€šè¿‡æ¨¡å‹è°ƒåº¦ï¼Œæˆ‘ä»¬å¯ä»¥é’ˆå¯¹å…·ä½“çš„æ•°æ®é›†ä¼˜åŒ–æ¨¡å‹ã€‚\nå¢åŠ æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼šé€šè¿‡åˆç†çš„å‚æ•°è®¾ç½®ï¼Œå¯ä»¥ä½¿æ¨¡å‹å¯¹æœªçŸ¥æ•°æ®æœ‰æ›´å¥½çš„é¢„æµ‹èƒ½åŠ›ã€‚\n\n\n\n1.7.2 é€‚ç”¨çš„æƒ…å†µ\næ¨¡å‹è°ƒä¼˜ä¸»è¦é€‚ç”¨äºä»¥ä¸‹å‡ ç§æƒ…å†µï¼š\n\næ¨¡å‹æ€§èƒ½ä¸ä½³ï¼šå½“æ¨¡å‹çš„é¢„æµ‹ç»“æœæˆ–åˆ†ç±»æ•ˆæœä¸å°½å¦‚äººæ„æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œè°ƒä¼˜ä»¥æå‡å…¶æ€§èƒ½ã€‚\næ•°æ®é›†ç‰¹æ€§å˜åŒ–ï¼šå½“æˆ‘ä»¬å¤„ç†çš„æ•°æ®é›†æœ‰æ˜¾è‘—çš„ç‰¹æ€§å˜åŒ–ï¼ˆä¾‹å¦‚ç‰¹å¾åˆ†å¸ƒæ”¹å˜ï¼Œå™ªå£°å¢åŠ ç­‰ï¼‰æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹åŸæœ‰æ¨¡å‹è¿›è¡Œè°ƒæ•´ä»¥é€‚åº”æ–°çš„æ•°æ®ç‰¹æ€§ã€‚\næ¨¡å‹è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆï¼šå½“æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°è¾ƒå·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰ï¼Œæˆ–è€…æ¨¡å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šçš„è¡¨ç°éƒ½ä¸ä½³ï¼ˆæ¬ æ‹Ÿåˆï¼‰æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚\nåˆå§‹å‚æ•°è®¾ç½®ä¸åˆç†ï¼šå¦‚æœæ¨¡å‹çš„åˆå§‹å‚æ•°è®¾ç½®å¹¶ä¸åˆé€‚ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡è¾ƒä½æˆ–è€…æ— æ³•åˆ°è¾¾æœ€ä¼˜è§£ï¼Œæ­¤æ—¶éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œè°ƒä¼˜ã€‚\né’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–æ¨¡å‹ï¼šå½“æˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨æŸä¸ªç‰¹å®šä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ¨¡å‹åšé’ˆå¯¹æ€§çš„è°ƒä¼˜ã€‚\n\næ€»çš„æ¥è¯´ï¼Œåªè¦æ˜¯å¸Œæœ›æå‡æ¨¡å‹æ€§èƒ½ï¼Œé€‚åº”æ•°æ®å˜åŒ–ï¼Œæˆ–è€…è§£å†³æ¨¡å‹çš„è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆé—®é¢˜ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥é€šè¿‡æ¨¡å‹è°ƒä¼˜æ¥å®ç°ã€‚\n\n\n1.7.3 å¸¸è§ç­–ç•¥\næœ€å¸¸è§çš„æ¨¡å‹è°ƒä¼˜ç­–ç•¥ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š\n\nç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰ï¼šè¿™æ˜¯ä¸€ç§ç©·ä¸¾æœç´¢çš„æ–¹æ³•ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸€ä¸ªå‚æ•°è®¾å®šä¸€ç»„å€¼ï¼Œç„¶åé€šè¿‡éå†æ¯ä¸ªå‚æ•°å¯èƒ½çš„ç»„åˆæ¥å¯»æ‰¾æœ€ä¼˜è§£ã€‚\néšæœºæœç´¢ï¼ˆRandom Searchï¼‰ï¼šä¸åŒäºç½‘æ ¼æœç´¢çš„ç©·ä¸¾æ€§è´¨ï¼Œå®ƒåœ¨æ¯ä¸ªå‚æ•°çš„å¯èƒ½å€¼ä¸­éšæœºé€‰å–ä¸€éƒ¨åˆ†è¿›è¡Œç»„åˆï¼Œç„¶åä»è¿™äº›ç»„åˆä¸­å¯»æ‰¾æœ€ä¼˜è§£ã€‚\næ‰‹åŠ¨æœç´¢ï¼ˆManual Searchï¼‰ï¼šä¹Ÿç§°ä¸ºäººå·¥æœç´¢ï¼Œå³ç”±ç ”ç©¶è€…æ ¹æ®ç»éªŒæˆ–è€…å¯¹é—®é¢˜çš„ç†è§£ï¼Œæ‰‹åŠ¨è®¾å®šå¹¶è°ƒæ•´å‚æ•°ã€‚è¿™ç§æ–¹å¼éœ€è¦æœ‰ä¸€å®šçš„ä¸“ä¸šçŸ¥è¯†å’Œç»éªŒï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½ä¼šæ‰¾åˆ°æ›´å¥½çš„è§£ã€‚\nè‡ªåŠ¨åŒ–æœç´¢ï¼ˆAutomated Searchï¼‰ï¼šè¿™ç±»æ–¹æ³•ï¼Œå¦‚è´å¶æ–¯ä¼˜åŒ–ã€é—ä¼ ç®—æ³•ç­‰ï¼Œä½¿ç”¨ç®—æ³•è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜å‚æ•°ç»„åˆã€‚ç›¸æ¯”å‰é¢å‡ ç§æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å¯ä»¥åœ¨æ›´å¤§çš„èŒƒå›´å†…å¯»æ‰¾æœ€ä¼˜å‚æ•°ï¼Œå¹¶ä¸”èŠ‚çœäº†äººå·¥å‚ä¸è°ƒæ•´çš„æ—¶é—´ã€‚\n\nä»¥ä¸Šå°±æ˜¯ç›®å‰æœ€å¸¸ç”¨çš„æ¨¡å‹è°ƒä¼˜ç­–ç•¥ï¼Œé€‰æ‹©å“ªç§ç­–ç•¥ä¾èµ–äºå…·ä½“çš„éœ€æ±‚ã€é—®é¢˜å¤æ‚åº¦ä»¥åŠå¯ç”¨èµ„æºã€‚\n\n\n1.7.4 è°ƒä¼˜æ¨¡å‹\ntune_grid() works similar to fit_resamples() but covers multiple parameter values:\n\nrf_spec &lt;- rand_forest(min_n = tune()) %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- workflow(tip ~ ., rf_spec)\nrf_wflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  min_n = tune()\n\nComputational engine: ranger \n\n## Try out multiple values\nset.seed(22)\nrf_res &lt;- tune_grid(\n  rf_wflow,\n  taxi_folds,\n  grid = 5\n)\n\n## Compare results\n# Inspecting results and selecting the best-performing hyperparameter(s):\nshow_best(rf_res)\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n# A tibble: 5 Ã— 7\n  min_n .metric .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1    33 roc_auc binary     0.620    10  0.0157 Preprocessor1_Model1\n2    31 roc_auc binary     0.619    10  0.0163 Preprocessor1_Model3\n3    21 roc_auc binary     0.614    10  0.0169 Preprocessor1_Model4\n4     6 roc_auc binary     0.613    10  0.0180 Preprocessor1_Model2\n5    13 roc_auc binary     0.608    10  0.0186 Preprocessor1_Model5\n\nbest_parameter &lt;- select_best(rf_res)\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\nbest_parameter\n\n# A tibble: 1 Ã— 2\n  min_n .config             \n  &lt;int&gt; &lt;chr&gt;               \n1    33 Preprocessor1_Model1\n\n## The final fit\n(rf_wflow &lt;- finalize_workflow(rf_wflow, best_parameter))\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Formula\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntip ~ .\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  min_n = 33\n\nComputational engine: ranger \n\n(final_fit &lt;- last_fit(rf_wflow, taxi_split))\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 Ã— 6\n  splits              id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;              &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [8000/2000]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ncollect_metrics(final_fit)\n\n# A tibble: 2 Ã— 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.913 Preprocessor1_Model1\n2 roc_auc  binary         0.648 Preprocessor1_Model1\n\n\nè¿™æ®µä»£ç æ˜¯åœ¨ä½¿ç”¨ tidymodels åŒ…ä¸­çš„å‡½æ•°è¿›è¡Œéšæœºæ£®æ—æ¨¡å‹çš„å‚æ•°è°ƒä¼˜å’Œæœ€åçš„æ‹Ÿåˆã€‚ä¸‹é¢æ˜¯å¯¹å„ä¸ªéƒ¨åˆ†çš„è§£é‡Šï¼š\n\nrf_spec &lt;- rand_forest(min_n = tune()) %&gt;% set_mode(\"classification\")\nè¿™è¡Œä»£ç å®šä¹‰äº†ä¸€ä¸ªéšæœºæ£®æ—åˆ†ç±»å™¨ï¼Œå¹¶è®¾å®š min_n å‚æ•°ä¸ºå¾…è°ƒæ•´çš„å‚æ•°ã€‚\nrf_wflow &lt;- workflow(tip ~ ., rf_spec)\nè¿™è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªå·¥ä½œæµï¼Œå°†ç‰¹å¾å’Œæ¨¡å‹è§„æ ¼ç»“åˆèµ·æ¥ã€‚\nrf_res &lt;- tune_grid(rf_wflow, taxi_folds, grid = 5)\nè¿™è¡Œä»£ç ä½¿ç”¨ tune_grid å‡½æ•°åœ¨é¢„å®šä¹‰çš„äº¤å‰éªŒè¯æŠ˜å  taxi_folds ä¸Šè¿›è¡Œç½‘æ ¼æœç´¢ï¼Œå°è¯• grid=5 æŒ‡å®šçš„ä¸åŒçš„ min_n å‚æ•°å€¼ã€‚\nshow_best(rf_res)\nè¿™è¡Œä»£ç æ˜¾ç¤ºäº†æœ€ä½³æ€§èƒ½çš„æ¨¡å‹å‚æ•°ã€‚\nbest_parameter &lt;- select_best(rf_res)\nè¿™è¡Œä»£ç é€‰æ‹©å‡ºè¡¨ç°æœ€å¥½çš„æ¨¡å‹å‚æ•°ã€‚\nrf_wflow &lt;- finalize_workflow(rf_wflow, best_parameter)\nè¿™è¡Œä»£ç å°†æœ€ä½³å‚æ•°è®¾ç½®åˆ°å·¥ä½œæµä¸­ã€‚\nfinal_fit &lt;- last_fit(rf_wflow, taxi_split)\nè¿™è¡Œä»£ç åœ¨è®­ç»ƒé›†ä¸Šç”¨ç¡®å®šçš„æœ€ä½³å‚æ•°è¿›è¡Œæœ€åçš„æ¨¡å‹æ‹Ÿåˆã€‚\ncollect_metrics(final_fit)\nè¿™è¡Œä»£ç æ”¶é›†å¹¶æ˜¾ç¤ºæœ€ç»ˆæ¨¡å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šçš„æ€§èƒ½æŒ‡æ ‡ã€‚"
  },
  {
    "objectID": "11.tidymodels-basic.html#å‚è€ƒèµ„æ–™",
    "href": "11.tidymodels-basic.html#å‚è€ƒèµ„æ–™",
    "title": "1Â  Basic tidymodels",
    "section": "1.8 å‚è€ƒèµ„æ–™",
    "text": "1.8 å‚è€ƒèµ„æ–™\n\nhttps://www.tidymodels.org/\nhttps://www.tmwr.org/\nhttp://www.feat.engineering/\nhttps://smltar.com/"
  },
  {
    "objectID": "12.tidymodels-advanced.html#ä½¿ç”¨-recipes-è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "href": "12.tidymodels-advanced.html#ä½¿ç”¨-recipes-è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "title": "2Â  Advanced tidymodels",
    "section": "2.1 ä½¿ç”¨ recipes è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "text": "2.1 ä½¿ç”¨ recipes è¿›è¡Œç‰¹å¾å·¥ç¨‹\nç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰æ˜¯æŒ‡å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºæ¨¡å‹å¯ä»¥åˆ©ç”¨çš„ç‰¹å¾çš„è¿‡ç¨‹ã€‚é€šè¿‡è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°è¡¨ç¤ºæ½œåœ¨é—®é¢˜ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚\nç‰¹å¾ï¼ˆFeatureï¼‰å¯ä»¥ç†è§£ä¸ºæ¨¡å‹é¢„æµ‹æ‰€éœ€è¦çš„æŸç§è¡¨ç¤ºæˆ–è€…å±æ€§ã€‚è­¬å¦‚åœ¨æˆ¿ä»·é¢„æµ‹é—®é¢˜ä¸­ï¼Œæˆ¿å±‹çš„é¢ç§¯ã€æˆ¿é—´æ•°é‡ã€åœ°æ®µç­‰éƒ½å¯ä»¥è¢«è§†ä¸ºç‰¹å¾ã€‚\nä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ç‰¹å¾è¡¨ç¤ºï¼š\n\näº¤äº’é¡¹ï¼ˆInteractionsï¼‰ï¼šè¿™æ˜¯é€šè¿‡ç»„åˆåŸæœ‰çš„ç‰¹å¾åˆ›å»ºæ–°çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸¤ä¸ªç‰¹å¾ A å’Œ Bï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ç‰¹å¾ A*B æ¥è¡¨ç¤º A å’Œ B çš„äº¤äº’æ•ˆåº”ã€‚\nå¤šé¡¹å¼æ‰©å±•/æ ·æ¡å‡½æ•°ï¼ˆPolynomial expansions/splinesï¼‰ï¼šè¿™æ˜¯é€šè¿‡å¯¹åŸæœ‰ç‰¹å¾è¿›è¡Œéçº¿æ€§è½¬æ¢åˆ›å»ºæ–°çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªç‰¹å¾ Xï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºæ–°çš„ç‰¹å¾ X^2, X^3 ç­‰æ¥æ•æ‰ X çš„éçº¿æ€§æ•ˆåº”1ã€‚\n\n\nä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ç‰¹å¾æå–ï¼šè¿™æ˜¯ä¸€ç§é™ç»´æŠ€æœ¯ï¼Œé€šè¿‡å°†åŸæœ‰çš„å¤šä¸ªç‰¹å¾è½¬åŒ–ä¸ºå°‘æ•°å‡ ä¸ªä¸»æˆåˆ†ï¼ˆä¹Ÿå°±æ˜¯æ–°çš„ç‰¹å¾ï¼‰ï¼Œä»è€Œä¿ç•™æ•°æ®ä¸­çš„ä¸»è¦ä¿¡æ¯ã€‚è¿™ç§æ–¹æ³•é€šå¸¸ç”¨äºå¤„ç†å…·æœ‰å¤šé‡å…±çº¿æ€§çš„é«˜ç»´æ•°æ®ã€‚\n\nä»¥ä¸Šå°±æ˜¯ç‰¹å¾å·¥ç¨‹çš„åŸºæœ¬æ¦‚å¿µä»¥åŠä¸€äº›å¸¸è§çš„ç‰¹å¾è¡¨ç¤ºæ–¹å¼ã€‚é€šè¿‡åˆé€‚çš„ç‰¹å¾å·¥ç¨‹ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæå–å‡ºæ›´æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œä»è€Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹é—®é¢˜ã€‚\n\n2.1.1 ç‰¹å¾å·¥ç¨‹çš„è½¯ä»¶åŒ…\nrecipes åŒ…æ˜¯ R è¯­è¨€ä¸­çš„ä¸€ä¸ªç”¨äºæ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹çš„å·¥å…·åŒ…ã€‚å®ƒæä¾›äº†ä¸€ç§çµæ´»ä¸”å¼ºå¤§çš„æ–¹å¼æ¥åˆ›å»ºå’Œç®¡ç†æ¨¡å‹éœ€è¦çš„é¢„å¤„ç†æ­¥éª¤ã€‚è¿™äº›æ­¥éª¤å¯ä»¥åŒ…æ‹¬æ•°æ®æ¸…æ´—ã€æ•°æ®è½¬æ¢ã€ç‰¹å¾é€‰æ‹©ã€ç‰¹å¾æ„å»ºç­‰ã€‚\nä»¥ä¸‹æ˜¯ recipes åŒ…çš„ä¸€äº›ä¸»è¦åŠŸèƒ½ï¼š\n\næ•°æ®é¢„å¤„ç†ï¼šrecipes åŒ…æä¾›äº†è®¸å¤šå‡½æ•°æ¥è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå¦‚ç¼©æ”¾å’Œä¸­å¿ƒåŒ–ï¼ˆæ ‡å‡†åŒ–ï¼‰ã€å¤„ç†ç¼ºå¤±å€¼ã€ç¦»ç¾¤å€¼æ£€æµ‹å’Œå¤„ç†ç­‰ã€‚\nç‰¹å¾é€‰æ‹©ï¼šrecipes åŒ…å¯ä»¥å¸®åŠ©æˆ‘ä»¬é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾ï¼Œä»¥é™ä½æ¨¡å‹çš„å¤æ‚æ€§å’Œè¿‡æ‹Ÿåˆçš„é£é™©ã€‚\nç‰¹å¾å·¥ç¨‹ï¼šrecipes åŒ…å¯ä»¥ç”¨äºåˆ›å»ºæ–°çš„ç‰¹å¾ï¼Œå¦‚åŸºäºç°æœ‰ç‰¹å¾çš„æ•°å­¦å˜æ¢ï¼ˆä¾‹å¦‚å¹³æ–¹ã€å¯¹æ•°å˜æ¢ç­‰ï¼‰ã€äº¤äº’é¡¹ã€è™šæ‹Ÿå˜é‡ï¼ˆç‹¬çƒ­ç¼–ç ï¼‰ç­‰ã€‚\nç®€æ˜“æ“ä½œï¼šæ‰€æœ‰çš„é¢„å¤„ç†æ­¥éª¤éƒ½å¯ä»¥è¢«å°è£…åœ¨ä¸€ä¸ª â€œrecipeâ€ å¯¹è±¡ä¸­ï¼Œè¿™ä½¿å¾—æ•´ä¸ªé¢„å¤„ç†è¿‡ç¨‹æ›´åŠ ç»„ç»‡åŒ–å’Œå¯å¤ç°ã€‚\n\næ€»çš„æ¥è¯´ï¼Œrecipes åŒ…æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å·¥å…·ï¼Œå®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´æœ‰æ•ˆåœ°è¿›è¡Œæ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ï¼Œå¹¶åº”ç”¨åˆ°æ¨¡å‹å¼€å‘çš„å·¥ä½œæµç¨‹ä¸­ã€‚\n\n\n2.1.2 å¯¹æ—¶é—´å˜é‡è¿›è¡Œç‰¹å¾æå–\nå¯¹æ—¶é—´å˜é‡è¿›è¡Œç‰¹å¾æå–æœ‰å¾ˆå¤šå¸¸è§çš„æ–¹æ³•ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­ï¼š\n\næ—¶é—´åˆ†è§£ï¼šå°†æ—¶é—´æˆ³åˆ†è§£ä¸ºå¹´ã€æœˆã€æ—¥ã€å°æ—¶ã€åˆ†é’Ÿå’Œç§’ã€‚è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬ç†è§£æ—¶é—´çš„ä¸åŒç»„æˆéƒ¨åˆ†å¦‚ä½•å½±å“ç›®æ ‡å˜é‡ã€‚\nå­£èŠ‚æ€§ç‰¹å¾ï¼šä½ å¯ä»¥åˆ›å»ºè¡¨ç¤ºå­£èŠ‚æ€§ä¿¡æ¯çš„ç‰¹å¾ï¼Œå¦‚å­£åº¦ã€æœˆä»½ã€ä¸€å‘¨ä¸­çš„å“ªä¸€å¤©ã€ä¸€å¤©ä¸­çš„å“ªä¸ªæ—¶æ®µç­‰ã€‚\nèŠ‚å‡æ—¥å’Œäº‹ä»¶ï¼šå¦‚æœæ•°æ®ä¸­åŒ…å«ç‰¹å®šçš„èŠ‚å‡æ—¥æˆ–äº‹ä»¶ï¼Œè¿™å¯èƒ½ä¼šå½±å“åˆ°ç›®æ ‡å˜é‡ã€‚æ­¤æ—¶ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªäºŒå…ƒç‰¹å¾æ¥è¡¨ç¤ºè¿™äº›ç‰¹æ®Šçš„æ—¥æœŸæˆ–äº‹ä»¶ã€‚\næ—¶é—´é—´éš”ï¼šè®¡ç®—ä¸¤ä¸ªæ—¥æœŸä¹‹é—´çš„æ—¶é—´å·®ï¼Œä¾‹å¦‚ç”¨æˆ·ä¸Šæ¬¡è´­ä¹°äº§å“åˆ°ç°åœ¨çš„å¤©æ•°ã€‚\nè¶‹åŠ¿ï¼šå¦‚æœä½ çš„æ•°æ®é›†è·¨è¶Šäº†å¾ˆé•¿ä¸€æ®µæ—¶é—´ï¼Œé‚£ä¹ˆå¯èƒ½å­˜åœ¨ä¸€äº›é•¿æœŸè¶‹åŠ¿ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªç‰¹å¾æ¥æ•æ‰è¿™ç§è¶‹åŠ¿ï¼Œä¾‹å¦‚æ•°æ®ç‚¹è·ç¦»å¼€å§‹æ—¥æœŸçš„å¤©æ•°ã€‚\næ»‘åŠ¨çª—å£ç»Ÿè®¡ï¼šä¾‹å¦‚è¿‡å»7å¤©æˆ–30å¤©çš„å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼ç­‰ã€‚\n\nè¿™äº›åªæ˜¯ä¸€éƒ¨åˆ†å¸¸è§çš„å¤„ç†æ—¶é—´å˜é‡çš„ç­–ç•¥ï¼Œå…·ä½“é‡‡ç”¨å“ªç§ç­–ç•¥éœ€è¦ç»“åˆå®é™…çš„ä¸šåŠ¡åœºæ™¯å’Œé—®é¢˜æ¥å†³å®šã€‚\n\n\n2.1.3 å¯¹å› å­å˜é‡è¿›è¡Œç‰¹å¾æå–\nå¯¹å› å­å˜é‡è¿›è¡Œç‰¹å¾æå–çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œä¸‹é¢åˆ—å‡ºäº†ä¸€äº›å¸¸è§çš„æ–¹æ³•ï¼š\n\nç‹¬çƒ­ç¼–ç ï¼ˆOne-Hot Encodingï¼‰ï¼šä¹Ÿè¢«ç§°ä¸ºè™šæ‹Ÿå˜é‡ï¼Œè¿™æ˜¯æœ€å¸¸è§çš„ç¼–ç æ–¹æ³•ã€‚æ¯ä¸ªç±»åˆ«éƒ½è¢«è½¬æ¢ä¸ºä¸€ä¸ªäºŒå…ƒå˜é‡ï¼ˆå³0æˆ–1ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ‰ä¸€ä¸ªé¢œè‰²çš„å› å­å˜é‡åŒ…å«â€œçº¢è‰²â€ï¼Œâ€œè“è‰²â€å’Œâ€œç»¿è‰²â€ä¸‰ä¸ªçº§åˆ«ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸‰ä¸ªæ–°çš„äºŒå…ƒå˜é‡ï¼Œåˆ†åˆ«è¡¨ç¤ºè¿™ä¸ªè§‚å¯Ÿæ˜¯ä¸æ˜¯çº¢è‰²ï¼Œæ˜¯ä¸æ˜¯è“è‰²ï¼Œæ˜¯ä¸æ˜¯ç»¿è‰²ã€‚\næ ‡ç­¾ç¼–ç ï¼ˆLabel Encodingï¼‰ï¼šå°†æ¯ä¸ªç±»åˆ«æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°ã€‚è¿™ç§æ–¹å¼é€‚åˆäºç±»åˆ«ä¹‹é—´å­˜åœ¨è‡ªç„¶é¡ºåºçš„æƒ…å†µï¼Œæ¯”å¦‚è¯„çº§ï¼ˆé«˜ã€ä¸­ã€ä½ï¼‰ã€‚\näºŒè¿›åˆ¶ç¼–ç ï¼ˆBinary Encodingï¼‰ï¼šé¦–å…ˆï¼Œå°†æ‰€æœ‰ç±»åˆ«æŒ‰ç…§ä¸€å®šçš„é¡ºåºç¼–ç ä¸ºè¿ç»­çš„æ•´æ•°ï¼›ç„¶åï¼Œå°†è¿™äº›æ•´æ•°è½¬æ¢ä¸ºäºŒè¿›åˆ¶å½¢å¼ã€‚è¿™ç§æ–¹å¼ç‰¹åˆ«é€‚åˆé«˜åŸºæ•°ç‰¹å¾ï¼Œå› ä¸ºå®ƒå¯ä»¥å¤§å¤§å‡å°‘æ–°ç”Ÿæˆçš„ç‰¹å¾çš„æ•°é‡ã€‚\nå“ˆå¸Œç¼–ç ï¼ˆHashing Encodingï¼‰ï¼šå“ˆå¸Œç¼–ç é€šè¿‡å“ˆå¸Œå‡½æ•°ï¼Œå°†ç±»åˆ«æ˜ å°„åˆ°æ›´å°çš„å›ºå®šé•¿åº¦çš„åˆ—ã€‚è¿™ç§æ–¹å¼å¯¹äºå¤„ç†å…·æœ‰å¤§é‡ç±»åˆ«çš„å˜é‡éå¸¸æœ‰æ•ˆã€‚\nç›®æ ‡ç¼–ç ï¼ˆTarget Encodingï¼‰ï¼šä¹Ÿè¢«ç§°ä¸ºå‡å€¼ç¼–ç æˆ–è€…å“åº”ç¼–ç ï¼Œè¿™ç§æ–¹å¼æ˜¯åŸºäºç±»åˆ«ç›®æ ‡å˜é‡çš„å¹³å‡å€¼æ¥å¯¹ç±»åˆ«è¿›è¡Œç¼–ç ã€‚å®ƒå¯ä»¥å¸®åŠ©æ¨¡å‹æ•æ‰åˆ°ç±»åˆ«å’Œç›®æ ‡å˜é‡ä¹‹é—´å¯èƒ½å­˜åœ¨çš„å…³ç³»ï¼Œä½†æ˜¯å¦‚æœä¸æ…é‡å¤„ç†ï¼Œå®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚\nåµŒå…¥å¼æ–¹æ³•ï¼ˆEmbeddingï¼‰ï¼šè¿™æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œå¤„ç†å› å­å˜é‡çš„æ–¹å¼ï¼Œå°†æ¯ä¸ªç±»åˆ«æ˜ å°„åˆ°ä¸€ä¸ªå¤šç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå¯ä»¥æ•è·æ›´å¤æ‚çš„å…³ç³»ã€‚\n\nè¿™äº›æ–¹æ³•å„æœ‰ä¼˜ç¼ºç‚¹ï¼Œé€‰æ‹©å“ªä¸€ç§å–å†³äºå…·ä½“çš„é—®é¢˜å’Œæ•°æ®ã€‚ä¾‹å¦‚ï¼Œç‹¬çƒ­ç¼–ç å¯èƒ½ä¼šäº§ç”Ÿå¾ˆå¤šåˆ—ï¼Œè€Œå“ˆå¸Œç¼–ç å¯èƒ½ä¼šäº§ç”Ÿç¢°æ’ï¼ˆä¸åŒçš„ç±»åˆ«æ˜ å°„åˆ°åŒä¸€å“ˆå¸Œå€¼ï¼‰ã€‚\nä¸‹é¢ä»¥æˆ¿ä»·é¢„æµ‹æ¨¡å‹ä¸ºä¾‹ï¼Œå±•ç¤ºå¯¹æ•°æ®ä¸­çš„å› å­å˜é‡è¿›è¡Œç‰¹å¾æå–çš„æ–¹æ³•ã€‚\n\n# recipes-startup\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” recipes      1.0.9\nâœ” dials        1.2.0     âœ” rsample      1.2.0\nâœ” dplyr        1.1.4     âœ” tibble       3.2.1\nâœ” ggplot2      3.4.4     âœ” tidyr        1.3.0\nâœ” infer        1.0.5     âœ” tune         1.1.2\nâœ” modeldata    1.2.0     âœ” workflows    1.1.3\nâœ” parsnip      1.1.1     âœ” workflowsets 1.0.1\nâœ” purrr        1.0.2     âœ” yardstick    1.2.0\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– purrr::discard() masks scales::discard()\nâœ– dplyr::filter()  masks stats::filter()\nâœ– dplyr::lag()     masks stats::lag()\nâœ– recipes::step()  masks stats::step()\nâ€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(modeldatatoo)\n\n# Add another package:\nlibrary(textrecipes)\n\n# Max's usual settings: \ntidymodels_prefer()\ntheme_set(theme_bw())\noptions(\n  pillar.advice = FALSE, \n  pillar.min_title_chars = Inf\n)\n\n\n# data-import\ndata(hotel_rates)\nset.seed(295)\nhotel_rates &lt;- \n  hotel_rates %&gt;% \n  sample_n(5000) %&gt;% \n  arrange(arrival_date) %&gt;% \n  select(-arrival_date) %&gt;% \n  mutate(\n    company = factor(as.character(company)),\n    country = factor(as.character(country)),\n    agent = factor(as.character(agent))\n  )\n\nset.seed(4028)\nhotel_split &lt;- initial_split(hotel_rates, strata = avg_price_per_room)\n\nhotel_train &lt;- training(hotel_split)\nhotel_test &lt;- testing(hotel_split)\n\nhotel_rs &lt;- vfold_cv(hotel_train, strata = avg_price_per_room)\nhotel_rs\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 Ã— 2\n   splits             id    \n   &lt;list&gt;             &lt;chr&gt; \n 1 &lt;split [3372/377]&gt; Fold01\n 2 &lt;split [3373/376]&gt; Fold02\n 3 &lt;split [3373/376]&gt; Fold03\n 4 &lt;split [3373/376]&gt; Fold04\n 5 &lt;split [3373/376]&gt; Fold05\n 6 &lt;split [3374/375]&gt; Fold06\n 7 &lt;split [3375/374]&gt; Fold07\n 8 &lt;split [3376/373]&gt; Fold08\n 9 &lt;split [3376/373]&gt; Fold09\n10 &lt;split [3376/373]&gt; Fold10\n\nhotel_rec &lt;- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_corr(all_numeric_predictors(), threshold = 0.9)\nsummary(hotel_rec)\n\n# A tibble: 27 Ã— 4\n   variable                type      role      source  \n   &lt;chr&gt;                   &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 lead_time               &lt;chr [2]&gt; predictor original\n 2 stays_in_weekend_nights &lt;chr [2]&gt; predictor original\n 3 stays_in_week_nights    &lt;chr [2]&gt; predictor original\n 4 adults                  &lt;chr [2]&gt; predictor original\n 5 children                &lt;chr [2]&gt; predictor original\n 6 babies                  &lt;chr [2]&gt; predictor original\n 7 meal                    &lt;chr [3]&gt; predictor original\n 8 country                 &lt;chr [3]&gt; predictor original\n 9 market_segment          &lt;chr [3]&gt; predictor original\n10 distribution_channel    &lt;chr [3]&gt; predictor original\n# â„¹ 17 more rows\n\nhotel_rec &lt;- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  embed::step_umap(all_numeric_predictors(), outcome = vars(avg_price_per_room))\nsummary(hotel_rec)\n\n# A tibble: 27 Ã— 4\n   variable                type      role      source  \n   &lt;chr&gt;                   &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 lead_time               &lt;chr [2]&gt; predictor original\n 2 stays_in_weekend_nights &lt;chr [2]&gt; predictor original\n 3 stays_in_week_nights    &lt;chr [2]&gt; predictor original\n 4 adults                  &lt;chr [2]&gt; predictor original\n 5 children                &lt;chr [2]&gt; predictor original\n 6 babies                  &lt;chr [2]&gt; predictor original\n 7 meal                    &lt;chr [3]&gt; predictor original\n 8 country                 &lt;chr [3]&gt; predictor original\n 9 market_segment          &lt;chr [3]&gt; predictor original\n10 distribution_channel    &lt;chr [3]&gt; predictor original\n# â„¹ 17 more rows\n\nhotel_rec &lt;- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  embed::step_umap(all_numeric_predictors(), outcome = vars(avg_price_per_room))\nsummary(hotel_rec)\n\n# A tibble: 27 Ã— 4\n   variable                type      role      source  \n   &lt;chr&gt;                   &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 lead_time               &lt;chr [2]&gt; predictor original\n 2 stays_in_weekend_nights &lt;chr [2]&gt; predictor original\n 3 stays_in_week_nights    &lt;chr [2]&gt; predictor original\n 4 adults                  &lt;chr [2]&gt; predictor original\n 5 children                &lt;chr [2]&gt; predictor original\n 6 babies                  &lt;chr [2]&gt; predictor original\n 7 meal                    &lt;chr [3]&gt; predictor original\n 8 country                 &lt;chr [3]&gt; predictor original\n 9 market_segment          &lt;chr [3]&gt; predictor original\n10 distribution_channel    &lt;chr [3]&gt; predictor original\n# â„¹ 17 more rows\n\nhotel_rec &lt;- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_spline_natural(arrival_date_num, deg_free = 10)\nsummary(hotel_rec)\n\n# A tibble: 27 Ã— 4\n   variable                type      role      source  \n   &lt;chr&gt;                   &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 lead_time               &lt;chr [2]&gt; predictor original\n 2 stays_in_weekend_nights &lt;chr [2]&gt; predictor original\n 3 stays_in_week_nights    &lt;chr [2]&gt; predictor original\n 4 adults                  &lt;chr [2]&gt; predictor original\n 5 children                &lt;chr [2]&gt; predictor original\n 6 babies                  &lt;chr [2]&gt; predictor original\n 7 meal                    &lt;chr [3]&gt; predictor original\n 8 country                 &lt;chr [3]&gt; predictor original\n 9 market_segment          &lt;chr [3]&gt; predictor original\n10 distribution_channel    &lt;chr [3]&gt; predictor original\n# â„¹ 17 more rows\n\n\nè¿™æ®µä»£ç ä¸»è¦å®ç°äº†å¯¹æ•°æ®é›† hotel_rates è¿›è¡Œé¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹çš„æ“ä½œã€‚å…·ä½“æ¥è¯´ï¼š\n\nè®¾ç½®ç¯å¢ƒï¼šåŠ è½½éœ€è¦çš„åº“å¹¶è¿›è¡Œä¸€äº›é€šç”¨è®¾ç½®ã€‚\næ•°æ®å¯¼å…¥å’Œåˆæ­¥å¤„ç†ï¼šé¦–å…ˆä» hotel_rates æ•°æ®ä¸­éšæœºæŠ½å–äº†5000ä¸ªæ ·æœ¬ï¼Œç„¶åå»é™¤äº† arrival_date åˆ—ï¼Œæœ€åå°† companyã€country å’Œ agent ä¸‰åˆ—è½¬æ¢ä¸ºå› å­ç±»å‹ã€‚\nåˆ›å»ºäº¤å‰éªŒè¯åˆ†å‰²ï¼šä½¿ç”¨ vfold_cv å‡½æ•°å¯¹è®­ç»ƒé›†è¿›è¡Œ10æŠ˜äº¤å‰éªŒè¯åˆ†å‰²ï¼Œå¹¶æŒ‰ç…§ avg_price_per_room è¿™ä¸€åˆ—è¿›è¡Œåˆ†å±‚æŠ½æ ·ã€‚\nåˆ›å»ºæ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼ˆrecipeï¼‰ï¼šä½¿ç”¨ recipe å‡½æ•°åˆ›å»ºä¸€ä¸ªæ•°æ®é¢„å¤„ç†é£Ÿè°±ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ‰§è¡Œäº†ä»¥ä¸‹æ­¥éª¤ï¼š\n\nä½¿ç”¨ step_dummy å°†æ‰€æœ‰åä¹‰é¢„æµ‹å˜é‡è½¬æ¢ä¸ºè™šæ‹Ÿï¼ˆdummyï¼‰å˜é‡ã€‚\nä½¿ç”¨ step_zv åˆ é™¤æ‰€æœ‰é›¶æ–¹å·®é¢„æµ‹å˜é‡ã€‚\nä½¿ç”¨ step_normalize å¯¹æ‰€æœ‰æ•°å€¼é¢„æµ‹å˜é‡è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆå³å˜æ¢ä¸ºå‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„æ­£æ€åˆ†å¸ƒï¼‰ã€‚\nåœ¨ç¬¬ä¸€ä¸ªé£Ÿè°±ä¸­ï¼Œä½¿ç”¨ step_corr åˆ é™¤æ‰€æœ‰ä¸å…¶ä»–æ•°å€¼é¢„æµ‹å˜é‡ç›¸å…³æ€§å¤§äº0.9çš„é¢„æµ‹å˜é‡ã€‚\nåœ¨ç¬¬äºŒã€ä¸‰ä¸ªé£Ÿè°±ä¸­ï¼Œä½¿ç”¨ step_umap å¯¹æ‰€æœ‰æ•°å€¼é¢„æµ‹å˜é‡è¿›è¡ŒUMAPé™ç»´ï¼Œå¹¶å°† avg_price_per_room ä½œä¸ºç›®æ ‡å˜é‡ã€‚\nåœ¨ç¬¬å››ä¸ªé£Ÿè°±ä¸­ï¼Œä½¿ç”¨ step_spline_natural å¯¹ arrival_date_num è¿™ä¸€é¢„æµ‹å˜é‡è¿›è¡Œè‡ªç„¶æ ·æ¡å˜æ¢ã€‚\n\n\næ¯æ¬¡åˆ›å»ºå®Œä¸€ä¸ªé£Ÿè°±åï¼Œéƒ½ä½¿ç”¨äº† summary å‡½æ•°æŸ¥çœ‹äº†è¯¥é£Ÿè°±çš„å†…å®¹ã€‚è¿™æ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ç†è§£æ¯ä¸€æ­¥é¢„å¤„ç†æ“ä½œå¯¹æ•°æ®çš„å½±å“ã€‚\nä¸‹é¢è¿™æ®µä»£ç é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªåä¸º hotel_indicators çš„é¢„å¤„ç† â€œrecipeâ€ï¼Œç„¶ååˆ©ç”¨è¿™ä¸ª â€œrecipeâ€ å’Œç®€å•çº¿æ€§å›å½’æ¨¡å‹å»ºç«‹äº†ä¸€ä¸ªå·¥ä½œæµï¼ˆworkflowï¼‰ï¼Œæœ€åä½¿ç”¨10æŠ˜äº¤å‰éªŒè¯çš„æ–¹å¼å¯¹è¿™ä¸ªå·¥ä½œæµè¿›è¡Œäº†æ‹Ÿåˆå¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚\nå…·ä½“æ­¥éª¤åŒ…æ‹¬ï¼š\n\nhotel_indicators &lt;-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_YeoJohnson(lead_time) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors()) %&gt;% \n  step_spline_natural(arrival_date_num, deg_free = 10)\nsummary(hotel_indicators)\n\n# A tibble: 27 Ã— 4\n   variable                type      role      source  \n   &lt;chr&gt;                   &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 lead_time               &lt;chr [2]&gt; predictor original\n 2 stays_in_weekend_nights &lt;chr [2]&gt; predictor original\n 3 stays_in_week_nights    &lt;chr [2]&gt; predictor original\n 4 adults                  &lt;chr [2]&gt; predictor original\n 5 children                &lt;chr [2]&gt; predictor original\n 6 babies                  &lt;chr [2]&gt; predictor original\n 7 meal                    &lt;chr [3]&gt; predictor original\n 8 country                 &lt;chr [3]&gt; predictor original\n 9 market_segment          &lt;chr [3]&gt; predictor original\n10 distribution_channel    &lt;chr [3]&gt; predictor original\n# â„¹ 17 more rows\n\n\nè¿™æ®µä»£ç æ˜¯åˆ›å»ºä¸€ä¸ªé¢„å¤„ç†æ•°æ®çš„ â€œrecipeâ€ã€‚ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š\n\nrecipe(avg_price_per_room ~ ., data = hotel_train)ï¼šå»ºç«‹ä¸€ä¸ªrecipeå¯¹è±¡ï¼Œå…¶ç›®æ ‡ï¼ˆå“åº”å˜é‡ï¼‰æ˜¯avg_price_per_roomï¼Œé¢„æµ‹å˜é‡æ˜¯hotel_trainæ•°æ®é›†ä¸­çš„æ‰€æœ‰å…¶ä»–å˜é‡ã€‚\nstep_YeoJohnson(lead_time)ï¼šå¯¹lead_timeåˆ—åº”ç”¨ Yeo-Johnson å˜æ¢ã€‚Yeo-Johnson å˜æ¢æ˜¯ä¸€ç§ç”¨äºæ­£æ€åŒ–æ•°æ®å’Œç®¡ç†å¼‚æ–¹å·®æ€§çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨äºæ­£æ•°ã€è´Ÿæ•°å’Œé›¶çš„æ•°æ®ã€‚\nstep_dummy(all_nominal_predictors())ï¼šå°†æ‰€æœ‰åä¹‰å‹é¢„æµ‹å˜é‡è½¬æ¢ä¸ºè™šæ‹Ÿï¼ˆdummyï¼‰å˜é‡ï¼Œä¹Ÿå°±æ˜¯è¿›è¡Œç‹¬çƒ­ç¼–ç ã€‚è¿™æ ·åšèƒ½å¤Ÿè®©æˆ‘ä»¬æŠŠåŒ…å«å¤šç±»åˆ«çš„åä¹‰å˜é‡è½¬æ¢ä¸ºäºŒå…ƒå˜é‡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå¤„ç†ã€‚\nstep_zv(all_predictors())ï¼šåˆ é™¤æ‰€æœ‰é›¶æ–¹å·®é¢„æµ‹å˜é‡ã€‚é›¶æ–¹å·®é¢„æµ‹å˜é‡æ˜¯æŒ‡åœ¨æ‰€æœ‰è§‚å¯Ÿä¸­å€¼éƒ½ç›¸åŒçš„å˜é‡ï¼Œè¿™æ ·çš„å˜é‡å¯¹æ¨¡å‹é¢„æµ‹é€šå¸¸æ²¡æœ‰å¸®åŠ©ã€‚\nstep_spline_natural(arrival_date_num, deg_free = 10)ï¼šå¯¹arrival_date_numè¿™ä¸€å˜é‡è¿›è¡Œè‡ªç„¶æ ·æ¡å˜æ¢ï¼Œè‡ªç”±åº¦è®¾ç½®ä¸º10ã€‚æ ·æ¡å˜æ¢èƒ½å¤Ÿå¸®åŠ©å¤„ç†éçº¿æ€§å…³ç³»ï¼Œå°¤å…¶æ˜¯å½“æˆ‘ä»¬é¢„æœŸæŸä¸ªé¢„æµ‹å˜é‡å’Œå“åº”å˜é‡ä¹‹é—´å­˜åœ¨å¤æ‚çš„éçº¿æ€§å…³ç³»æ—¶ã€‚\n\nè¿™ä¸ªrecipeå®šä¹‰äº†æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹çš„æ­¥éª¤ï¼Œåç»­å¯ä»¥é€šè¿‡ prep() å’Œ bake() å‡½æ•°æ¥å®æ–½è¿™ä¸ªrecipeã€‚\n\nreg_metrics &lt;- metric_set(mae, rsq)\n\nå®šä¹‰è¯„ä¼°æŒ‡æ ‡ï¼šé€šè¿‡ metric_set(mae, rsq) å‘½ä»¤å®šä¹‰äº†ä¸¤ä¸ªæ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼Œå³å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆmean absolute errorï¼Œmaeï¼‰å’Œå†³å®šç³»æ•°ï¼ˆR-squaredï¼Œrsqï¼‰ã€‚\n\n\\begin{align}\nMAE &= \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i| \\notag \\\\\nR^2 &= cor(y_i, \\hat{y}_i)^2\n\\end{align}\n\\tag{2.1}\n\nset.seed(9)\nhotel_lm_wflow &lt;-\n  workflow() %&gt;%\n  add_recipe(hotel_indicators) %&gt;%\n  add_model(linear_reg())\n\nåˆ›å»ºå·¥ä½œæµï¼šå»ºç«‹äº†ä¸€ä¸ªåŒ…å«é¢„å¤„ç† â€œrecipeâ€ å’Œç®€å•çº¿æ€§å›å½’æ¨¡å‹çš„å·¥ä½œæµã€‚\n\nctrl &lt;- control_resamples(save_pred = TRUE)\nhotel_lm_res &lt;-\n  hotel_lm_wflow %&gt;%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\nâ†’ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x2\n\n\nThere were issues with some computations   A: x9\nThere were issues with some computations   A: x9\n\n\n\n\n\næ‹Ÿåˆå¹¶è¯„ä¼°æ¨¡å‹ï¼šé€šè¿‡ fit_resamples å‡½æ•°å°†å·¥ä½œæµåº”ç”¨åˆ°10æŠ˜äº¤å‰éªŒè¯çš„æ¯ä¸€ä¸ªåˆ†å‰²ä¸­ï¼Œå¹¶è®¡ç®—äº†åœ¨æ¯ä¸€ä¸ªåˆ†å‰²ä¸­æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ã€‚ç»“æœä¿å­˜åœ¨ hotel_lm_res ä¸­ã€‚\n\ncollect_metrics(hotel_lm_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   16.7      10 0.251   Preprocessor1_Model1\n2 rsq     standard    0.883    10 0.00532 Preprocessor1_Model1\n\n\næ”¶é›†è¯„ä¼°æŒ‡æ ‡ï¼šä½¿ç”¨ collect_metrics(hotel_lm_res) å‘½ä»¤æ”¶é›†æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ã€‚\n\n# Since we used `save_pred = TRUE`\nlm_cv_pred &lt;- collect_predictions(hotel_lm_res)\nlm_cv_pred %&gt;% print(n = 7)\n\n# A tibble: 3,749 Ã— 5\n  id     .pred  .row avg_price_per_room .config             \n  &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt;              &lt;dbl&gt; &lt;chr&gt;               \n1 Fold01  26.2    31               54   Preprocessor1_Model1\n2 Fold01  23.0    35               48   Preprocessor1_Model1\n3 Fold01  68.9    45               50   Preprocessor1_Model1\n4 Fold01  60.2    47               55   Preprocessor1_Model1\n5 Fold01  48.6    59               52.8 Preprocessor1_Model1\n6 Fold01  49.0    67               49   Preprocessor1_Model1\n7 Fold01  49.0    72               49   Preprocessor1_Model1\n# â„¹ 3,742 more rows\n\n\næ”¶é›†é¢„æµ‹ç»“æœï¼šå› ä¸ºåœ¨ control_resamples å‡½æ•°ä¸­è®¾ç½®äº† save_pred = TRUEï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡ collect_predictions(hotel_lm_res) å‘½ä»¤æ”¶é›†æ¨¡å‹åœ¨10æŠ˜äº¤å‰éªŒè¯çš„æ¯ä¸€ä¸ªåˆ†å‰²ä¸­çš„é¢„æµ‹ç»“æœã€‚\n\n## Calibration Plot\n#| label: fig-lm-cal-plot\n#| fig-width: 5\n#| fig-height: 5\n\nlibrary(probably)\n\ncal_plot_regression(hotel_lm_res, alpha = 1 / 5)\n\n\n\n\nç»˜åˆ¶æ ¡å‡†å›¾ï¼šä½¿ç”¨ cal_plot_regression å‡½æ•°ç»˜åˆ¶äº†æ¨¡å‹çš„æ ¡å‡†å›¾ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°å›å½’æ¨¡å‹é¢„æµ‹ç²¾åº¦çš„å¯è§†åŒ–æ–¹æ³•ã€‚"
  },
  {
    "objectID": "12.tidymodels-advanced.html#å¯¹-agent-è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "href": "12.tidymodels-advanced.html#å¯¹-agent-è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "title": "2Â  Advanced tidymodels",
    "section": "2.2 å¯¹ agent è¿›è¡Œç‰¹å¾å·¥ç¨‹",
    "text": "2.2 å¯¹ agent è¿›è¡Œç‰¹å¾å·¥ç¨‹\n\n2.2.1 ä½¿ç”¨åˆ†ç±»æ±‡æ€»\nä¸‹é¢è¿™æ®µä»£ç åŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼šé¦–å…ˆå¯¹agentå­—æ®µè¿›è¡Œç»Ÿè®¡å¹¶ç»˜åˆ¶ç›´æ–¹å›¾ï¼Œç„¶åæ„å»ºä¸€ä¸ªæ–°çš„é¢„å¤„ç†â€recipeâ€ï¼Œä½¿ç”¨äº†ä¸€ä¸ªæ–°çš„æ­¥éª¤ï¼šstep_other()ã€‚\né€šè¿‡åˆ†æå‘ç°æœ‰ä¸€äº› agent å‡ºç°çš„é¢‘ç‡å¾ˆä½ï¼Œè¿™ç§æƒ…å†µä¸‹å¯ä»¥å°†å…¶åˆå¹¶åˆ° other ç»„ä¸­ã€‚\n\nagent_stats &lt;- \n  hotel_train %&gt;%\n  group_by(agent) %&gt;%\n  summarize(\n    ADR = mean(avg_price_per_room), \n    num_reservations = n(),\n    .groups = \"drop\"\n    ) %&gt;%\n  mutate(agent = reorder(agent, ADR))\n\nagent_stats %&gt;%   \n  ggplot(aes(x = num_reservations)) +\n  geom_histogram(bins = 30, col = \"blue\", fill = \"blue\", alpha = 1/3) +\n  labs(x = \"Number of reservations per agent\")\n\n\n\nagent_stats %&gt;%   \n  ggplot(aes(x = ADR)) +\n  geom_histogram(bins = 30, col = \"red\", fill = \"red\", alpha = 1/3) +\n  labs(x = \"Average ADR per agent\")\n\n\n\n\nä»£ç†ç»Ÿè®¡ï¼šå¯¹ hotel_train æ•°æ®é›†æŒ‰ agent è¿›è¡Œåˆ†ç»„ï¼Œå¹¶è®¡ç®—æ¯ä¸ªä»£ç†çš„å¹³å‡æˆ¿ä»·ï¼ˆADRï¼‰å’Œé¢„è®¢æ•°é‡ï¼ˆnum_reservationsï¼‰ã€‚ç„¶å, è¿™äº›ç»Ÿè®¡ä¿¡æ¯è¢«ç”¨æ¥åˆ›å»ºä¸¤ä¸ªç›´æ–¹å›¾ï¼Œåˆ†åˆ«æ˜¾ç¤ºäº†æ¯ä¸ªä»£ç†çš„é¢„è®¢æ•°é‡å’Œå¹³å‡ADRã€‚\n\nretained_agents &lt;-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;%\n  step_mutate(original = agent) %&gt;% \n  step_other(agent, threshold = 0.001) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors()) %&gt;% \n  step_spline_natural(arrival_date_num, deg_free = 10) %&gt;% \n  prep() %&gt;% \n  tidy(number = 2)\n\n(num_agents &lt;- length(unique(hotel_train$agent)))\n\n[1] 98\n\n(num_other &lt;- num_agents - length(retained_agents$retained))\n\n[1] 34\n\n\næ–°çš„é¢„å¤„ç†â€recipeâ€ï¼šæ–°çš„recipeå’Œä¹‹å‰çš„éå¸¸ç›¸ä¼¼ï¼Œä½†å¢åŠ äº†ä¸€ä¸ª step_other(agent, threshold = 0.001) æ­¥éª¤ã€‚è¿™ä¸€æ­¥æŠŠæ‰€æœ‰é¢„æµ‹å˜é‡ä¸­åœ¨æ•°æ®é›†ä¸­å‡ºç°é¢‘ç‡ä½äºé˜ˆå€¼ï¼ˆæ­¤å¤„ä¸º0.001ï¼‰çš„ agent ä»£ç†æ ‡è®°ä¸º â€œOtherâ€ã€‚ç„¶åï¼Œè¯¥é¢„å¤„ç†æ­¥éª¤é€šè¿‡ prep() å‡½æ•°åº”ç”¨åœ¨æ•°æ®ä¸Šï¼Œç»“æœé€šè¿‡ tidy(number = 2) å±•ç¤º outã€‚\n\nhotel_other_rec &lt;-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_YeoJohnson(lead_time) %&gt;%\n  step_other(agent, threshold = 0.001) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors()) %&gt;% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n\nhotel_other_wflow &lt;-\n  hotel_lm_wflow %&gt;%\n  update_recipe(hotel_other_rec)\n\nhotel_other_res &lt;-\n  hotel_other_wflow %&gt;%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\nâ†’ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x5\n\n\nThere were issues with some computations   A: x9\n\n\n\n\ncollect_metrics(hotel_other_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   16.8      10 0.245   Preprocessor1_Model1\n2 rsq     standard    0.883    10 0.00530 Preprocessor1_Model1\n\n\næ›´æ–°å·¥ä½œæµå¹¶é‡æ–°æ‹Ÿåˆæ¨¡å‹ï¼šä½¿ç”¨ update_recipe(hotel_other_rec) æ›´æ–°å·¥ä½œæµä¸­çš„ recipeï¼Œç„¶åå†æ¬¡æ‹Ÿåˆæ ·æœ¬ï¼Œå¹¶æ”¶é›†è¯„ä¼°æŒ‡æ ‡ã€‚\nè¿™æ®µä»£ç çš„ç›®çš„æ˜¯å¤„ç†é‚£äº›åªæœ‰å°‘æ•°è§‚å¯Ÿå€¼çš„ç±»åˆ«å˜é‡â€”â€”è¿™é‡Œæ˜¯ agent å˜é‡ã€‚è¿™æ ·åšå¯ä»¥é¿å…è¿‡æ‹Ÿåˆï¼Œå¹¶å¯èƒ½æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\n\n2.2.2 ä½¿ç”¨å“ˆå¸Œç¼–ç \nä¸‹é¢è¿™æ®µä»£ç åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„é¢„å¤„ç† â€œrecipeâ€ï¼Œå¹¶ä½¿ç”¨è¯¥ â€œrecipeâ€ æ›´æ–°äº†å·¥ä½œæµï¼Œç„¶åå†æ¬¡æ‹Ÿåˆæ ·æœ¬ï¼Œå¹¶æ”¶é›†è¯„ä¼°æŒ‡æ ‡ã€‚\nä¸»è¦æ”¹å˜æ˜¯ï¼šåœ¨æ–°çš„ â€œrecipeâ€ ä¸­ï¼Œå¯¹ agent å’Œ company ä½¿ç”¨äº†å“ˆå¸Œè™šæ‹Ÿç¼–ç ï¼ˆhashing trickï¼‰ã€‚å“ˆå¸Œè™šæ‹Ÿç¼–ç å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†é«˜åŸºæ•°çš„åˆ†ç±»ç‰¹å¾ã€‚è¿™æ˜¯ä¸€ç§ç»´åº¦çº¦å‡æŠ€æœ¯ï¼Œé€šè¿‡å°†æ‰€æœ‰ç±»åˆ«æ˜ å°„åˆ°æ›´å°çš„å›ºå®šæ•°é‡çš„åˆ—æ¥å®ç°ã€‚\nå…·ä½“æ­¥éª¤åŒ…æ‹¬ï¼š\n\nåˆ›å»ºæ–°çš„é¢„å¤„ç† â€œrecipeâ€ï¼šæ–°çš„ â€œrecipeâ€ åŒ…å«äº†ä»¥ä¸‹æ­¥éª¤ï¼š\n\nå¯¹ lead_time è¿›è¡ŒYeo-Johnsonå˜æ¢ã€‚\nå¯¹ agent å’Œ company è¿›è¡Œå“ˆå¸Œè™šæ‹Ÿç¼–ç ï¼ˆé»˜è®¤ç”Ÿæˆ32ä¸ªæœ‰ç¬¦å·çš„æŒ‡ç¤ºåˆ—ï¼‰ã€‚\nå¯¹å…¶ä»–åä¹‰é¢„æµ‹å˜é‡è¿›è¡Œæ™®é€šçš„è™šæ‹Ÿç¼–ç ã€‚\nåˆ é™¤æ‰€æœ‰é›¶æ–¹å·®é¢„æµ‹å˜é‡ã€‚\nå¯¹ arrival_date_num è¿›è¡Œè‡ªç„¶æ ·æ¡å˜æ¢ã€‚\n\næ›´æ–°å·¥ä½œæµï¼šä½¿ç”¨ update_recipe(hash_rec) æ¥æ›´æ–°å·¥ä½œæµä¸­çš„ â€œrecipeâ€ã€‚\né‡æ–°æ‹Ÿåˆæ¨¡å‹å¹¶æ”¶é›†è¯„ä¼°æŒ‡æ ‡ï¼šå’Œä¹‹å‰ç›¸åŒï¼Œå†æ¬¡æ‹Ÿåˆæ ·æœ¬ï¼Œå¹¶æ”¶é›†è¯„ä¼°æŒ‡æ ‡ã€‚\n\nå“ˆå¸Œè™šæ‹Ÿç¼–ç æ˜¯ä¸€ç§å¤„ç†é«˜åŸºæ•°åˆ†ç±»ç‰¹å¾çš„æ–¹æ³•ï¼Œå¯¹äºæœ‰å¤§é‡å”¯ä¸€å€¼çš„åˆ†ç±»å˜é‡ï¼ˆå¦‚ IP åœ°å€ï¼Œç”¨æˆ· ID ç­‰ï¼‰éå¸¸æœ‰ç”¨ã€‚\n\nhash_rec &lt;-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;%\n  step_YeoJohnson(lead_time) %&gt;%\n  # Defaults to 32 signed indicator columns\n  step_dummy_hash(agent) %&gt;%\n  step_dummy_hash(company) %&gt;%\n  # Regular indicators for the others\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_spline_natural(arrival_date_num, deg_free = 10)\n\nhotel_hash_wflow &lt;-\n  hotel_lm_wflow %&gt;%\n  update_recipe(hash_rec)\n\nhotel_hash_res &lt;-\n  hotel_hash_wflow %&gt;%\n  fit_resamples(hotel_rs, control = ctrl, metrics = reg_metrics)\n\nâ†’ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x5\n\n\nThere were issues with some computations   A: x9\n\n\n\n\ncollect_metrics(hotel_hash_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   16.7      10 0.254   Preprocessor1_Model1\n2 rsq     standard    0.884    10 0.00572 Preprocessor1_Model1"
  },
  {
    "objectID": "12.tidymodels-advanced.html#debug-recipes",
    "href": "12.tidymodels-advanced.html#debug-recipes",
    "title": "2Â  Advanced tidymodels",
    "section": "2.3 Debug recipes",
    "text": "2.3 Debug recipes\n\nhash_rec_fit &lt;- prep(hash_rec)\nhash_rec_fit\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 26\n\n\n\n\n\nâ”€â”€ Training information \n\n\nTraining data contained 3749 data points and no incomplete rows.\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Yeo-Johnson transformation on: lead_time | Trained\n\n\nâ€¢ Feature hashing with: agent | Trained\n\n\nâ€¢ Feature hashing with: company | Trained\n\n\nâ€¢ Dummy variables from: meal, country, market_segment, ... | Trained\n\n\nâ€¢ Zero variance filter removed: dummyhash_agent_09, ... | Trained\n\n\nâ€¢ Natural spline expansion: arrival_date_num | Trained\n\n# Get the transformation coefficient\ntidy(hash_rec_fit, number = 1)\n\n# A tibble: 1 Ã— 3\n  terms     value id              \n  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;           \n1 lead_time 0.173 YeoJohnson_IpstB\n\n# Get the processed data\nbake(hash_rec_fit, hotel_train %&gt;% slice(1:3), contains(\"_agent_\"))\n\n# A tibble: 3 Ã— 30\n  dummyhash_agent_01 dummyhash_agent_02 dummyhash_agent_03 dummyhash_agent_04\n               &lt;int&gt;              &lt;int&gt;              &lt;int&gt;              &lt;int&gt;\n1                  0                  0                  0                  0\n2                  0                 -1                  0                  0\n3                  0                  0                  0                  0\n# â„¹ 26 more variables: dummyhash_agent_05 &lt;int&gt;, dummyhash_agent_06 &lt;int&gt;,\n#   dummyhash_agent_07 &lt;int&gt;, dummyhash_agent_08 &lt;int&gt;,\n#   dummyhash_agent_10 &lt;int&gt;, dummyhash_agent_11 &lt;int&gt;,\n#   dummyhash_agent_12 &lt;int&gt;, dummyhash_agent_13 &lt;int&gt;,\n#   dummyhash_agent_14 &lt;int&gt;, dummyhash_agent_15 &lt;int&gt;,\n#   dummyhash_agent_16 &lt;int&gt;, dummyhash_agent_18 &lt;int&gt;,\n#   dummyhash_agent_19 &lt;int&gt;, dummyhash_agent_20 &lt;int&gt;, â€¦"
  },
  {
    "objectID": "12.tidymodels-advanced.html#å‚è€ƒèµ„æ–™",
    "href": "12.tidymodels-advanced.html#å‚è€ƒèµ„æ–™",
    "title": "2Â  Advanced tidymodels",
    "section": "2.4 å‚è€ƒèµ„æ–™",
    "text": "2.4 å‚è€ƒèµ„æ–™\n\nOnce fit() is called on a workflow, changing the model does not re-fit the recipe.\nA list of all known steps is at https://www.tidymodels.org/find/recipes/.\nSome steps can be skipped when using predict().\nuse feature hashing to create a smaller set of indicator variables\nFeature hashing (for more see FES, SMLTAR, and TMwR):\nHash functions are meant to emulate randomness.\nThe order of the steps matters."
  },
  {
    "objectID": "12.tidymodels-advanced.html#footnotes",
    "href": "12.tidymodels-advanced.html#footnotes",
    "title": "2Â  Advanced tidymodels",
    "section": "",
    "text": "æ ·æ¡ï¼ˆSplineï¼‰æ˜¯ä¸€ç§æ•°å­¦å·¥å…·ï¼Œç”¨äºåœ¨ç»™å®šçš„æ•°æ®ç‚¹ä¹‹é—´åˆ›å»ºå¹³æ»‘æ›²çº¿ã€‚å®ƒå¹¿æ³›åº”ç”¨äºè®¡ç®—æœºå›¾å½¢å­¦ã€æ•°æ®æ’å€¼å’Œå›å½’åˆ†æç­‰é¢†åŸŸã€‚â†©ï¸"
  },
  {
    "objectID": "13.tidymodels-extra.html#éƒ¨ç½²æ¨¡å‹",
    "href": "13.tidymodels-extra.html#éƒ¨ç½²æ¨¡å‹",
    "title": "3Â  Extra tidymodels",
    "section": "3.1 éƒ¨ç½²æ¨¡å‹",
    "text": "3.1 éƒ¨ç½²æ¨¡å‹\nä½¿ç”¨ vetiver åŒ…å¯ä»¥å¿«é€Ÿå®ç°æ¨¡å‹éƒ¨ç½²ã€‚\nè¿™æ®µä»£ç åŒ…å«äº†å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š\n\næ•°æ®é›†çš„åˆ’åˆ†ï¼šä½¿ç”¨tidymodelsåŒ…ä¸­çš„initial_split()å‡½æ•°å°†taxiæ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­80%çš„æ•°æ®ç”¨äºè®­ç»ƒï¼Œå‰©ä½™20%çš„æ•°æ®ç”¨äºæµ‹è¯•ã€‚è¿™ä¸ªåˆ’åˆ†æ˜¯æ ¹æ®tipåˆ—ï¼ˆåº”è¯¥æ˜¯ç›®æ ‡å˜é‡ï¼‰è¿›è¡Œåˆ†å±‚çš„ã€‚\n\n\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” recipes      1.0.9\nâœ” dials        1.2.0     âœ” rsample      1.2.0\nâœ” dplyr        1.1.4     âœ” tibble       3.2.1\nâœ” ggplot2      3.4.4     âœ” tidyr        1.3.0\nâœ” infer        1.0.5     âœ” tune         1.1.2\nâœ” modeldata    1.2.0     âœ” workflows    1.1.3\nâœ” parsnip      1.1.1     âœ” workflowsets 1.0.1\nâœ” purrr        1.0.2     âœ” yardstick    1.2.0\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– purrr::discard() masks scales::discard()\nâœ– dplyr::filter()  masks stats::filter()\nâœ– dplyr::lag()     masks stats::lag()\nâœ– recipes::step()  masks stats::step()\nâ€¢ Use tidymodels_prefer() to resolve common conflicts.\n\nset.seed(123)\ntaxi_split &lt;- initial_split(taxi, prop = 0.8, strata = tip)\ntaxi_train &lt;- training(taxi_split)\ntaxi_test &lt;- testing(taxi_split)\n\n\næ¨¡å‹çš„å®šä¹‰å’Œè®­ç»ƒï¼šå®šä¹‰äº†ä¸€ä¸ªå†³ç­–æ ‘æ¨¡å‹è§„æ ¼ï¼ˆä½¿ç”¨decision_tree()å‡½æ•°ï¼‰ï¼Œå¹¶è®¾ç½®äº†æˆæœ¬å¤æ‚åº¦å‚æ•°ä¸º0.0001ï¼Œæ¨¡å¼ä¸ºâ€åˆ†ç±»â€ã€‚ç„¶åï¼Œä½¿ç”¨workflow()å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªå·¥ä½œæµï¼ŒæŒ‡å®šäº†ç›®æ ‡å˜é‡å’Œé¢„æµ‹å™¨ï¼Œå¹¶ç”¨è®­ç»ƒé›†æ‹Ÿåˆäº†è¿™ä¸ªå·¥ä½œæµã€‚\n\n\ntree_spec &lt;- decision_tree(cost_complexity = 0.0001, mode = \"classification\")\ntree_fit &lt;- workflow(tip ~ ., tree_spec) %&gt;% fit(taxi_train)\n\n\næ¨¡å‹éƒ¨ç½²å‡†å¤‡ï¼šä½¿ç”¨vetiveråŒ…çš„vetiver_model()å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªvetiveræ¨¡å‹å¯¹è±¡ï¼Œè¿™æ˜¯å¯¹å·²ç»æ‹Ÿåˆçš„æ¨¡å‹è¿›è¡Œå°è£…ï¼Œä¸ºæ¨¡å‹çš„éƒ¨ç½²åšå‡†å¤‡ã€‚\n\n\n## Deploying a model\nlibrary(vetiver)\n\n\nè½½å…¥ç¨‹è¾‘åŒ…ï¼š'vetiver'\n\n\nThe following object is masked from 'package:tune':\n\n    load_pkgs\n\nv &lt;- vetiver_model(tree_fit, \"taxi\")\nv\n\n\nâ”€â”€ taxi â”€ &lt;bundled_workflow&gt; model for deployment \nA rpart classification modeling workflow using 6 features\n\n\n\nå»ºç«‹APIï¼šä½¿ç”¨plumberåŒ…æä¾›çš„pr()å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„Plumber APIï¼Œç„¶ååˆ©ç”¨vetiver_api(v)å°†vetiveræ¨¡å‹å¯¹è±¡è½¬åŒ–ä¸ºä¸€ä¸ªAPIç«¯ç‚¹ã€‚è¿™æ ·å°±å¯ä»¥é€šè¿‡è¿™ä¸ªAPIæ¥è°ƒç”¨æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚\n\n\n## Deploy your model\nlibrary(plumber)\npr() %&gt;%\n  vetiver_api(v)\n\n# Plumber router with 4 endpoints, 4 filters, and 1 sub-router.\n# Use `pr_run()` on this object to start the API.\nâ”œâ”€â”€[queryString]\nâ”œâ”€â”€[body]\nâ”œâ”€â”€[cookieParser]\nâ”œâ”€â”€[sharedSecret]\nâ”œâ”€â”€/logo\nâ”‚  â”‚ # Plumber static router serving from directory: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/vetiver\nâ”œâ”€â”€/metadata (GET)\nâ”œâ”€â”€/ping (GET)\nâ”œâ”€â”€/predict (POST)\nâ””â”€â”€/prototype (GET)\n\n\nä»¥ä¸Šå°±æ˜¯ä»£ç çš„åŸºæœ¬è§£é‡Šã€‚å¦‚æœä½ æƒ³è¦å®é™…éƒ¨ç½²è¿™ä¸ªæ¨¡å‹ï¼Œä½ éœ€è¦å°†è¿™ä¸ªPlumber APIéƒ¨ç½²åˆ°ä¸€ä¸ªå¯ä»¥æä¾›HTTPæœåŠ¡çš„æœåŠ¡å™¨ä¸Šï¼Œä¾‹å¦‚ RStudio Connectã€‚"
  },
  {
    "objectID": "13.tidymodels-extra.html#ç¼–ç çš„å½±å“",
    "href": "13.tidymodels-extra.html#ç¼–ç çš„å½±å“",
    "title": "3Â  Extra tidymodels",
    "section": "3.2 ç¼–ç çš„å½±å“",
    "text": "3.2 ç¼–ç çš„å½±å“\nè¿™æ®µä»£ç æ‰§è¡Œäº†ä»¥ä¸‹æ“ä½œï¼š\næ•°æ®é¢„å¤„ç†: ä½ åŠ è½½äº†ä¸€ä¸ªå«åšhotel_ratesçš„æ•°æ®é›†ï¼Œå¹¶ä»ä¸­éšæœºé€‰æ‹©äº†5000è¡Œã€‚ç„¶åï¼Œä½ å¯¹è¿™ä¸ªæ•°æ®é›†è¿›è¡Œäº†ä¸€äº›é¢„å¤„ç†ï¼ŒåŒ…æ‹¬å»é™¤arrival_dateåˆ—ï¼Œä»¥åŠå°†companyã€countryå’Œagentåˆ—è½¬æ¢ä¸ºå› å­ç±»å‹ã€‚\n\ndata(hotel_rates)\nset.seed(295)\nhotel_rates &lt;- \n  hotel_rates %&gt;% \n  sample_n(5000) %&gt;% \n  arrange(arrival_date) %&gt;% \n  select(-arrival_date) %&gt;% \n  mutate(\n    company = factor(as.character(company)),\n    country = factor(as.character(country)),\n    agent = factor(as.character(agent))\n  )\n\næ•°æ®åˆ’åˆ†: ä½ ä½¿ç”¨tidymodelsåŒ…çš„initial_split()å‡½æ•°å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­åˆ’åˆ†æ˜¯åŸºäºavg_price_per_roomåˆ—è¿›è¡Œçš„ã€‚\n\nset.seed(4028)\nhotel_split &lt;-\n  initial_split(hotel_rates, strata = avg_price_per_room)\n\nhotel_train &lt;- training(hotel_split)\nhotel_test &lt;- testing(hotel_split)\n\näº¤å‰éªŒè¯: ä½ è®¾ç½®äº†ä¸€ä¸ª10æŠ˜äº¤å‰éªŒè¯ï¼ˆé»˜è®¤è®¾ç½®ï¼‰çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯åŸºäºavg_price_per_roomåˆ—è¿›è¡Œçš„ã€‚\n\nset.seed(472)\nhotel_rs &lt;- vfold_cv(hotel_train, strata = avg_price_per_room)\n\nç‰¹å¾å·¥ç¨‹: ä½ è®¡ç®—äº†æ¯ä¸ªä»£ç†çš„å¹³å‡æˆ¿ä»·(ADR)å’Œé¢„è®¢æ•°é‡ã€‚ç„¶åï¼Œä½ ä½¿ç”¨äº†embedåŒ…çš„step_lencode_mixed()å‡½æ•°æ¥å¯¹agentåˆ—è¿›è¡Œæ··åˆç¼–ç ã€‚è¿™ä¸ªå‡½æ•°æ ¹æ®ç›®æ ‡å˜é‡çš„å€¼æ¥è®¡ç®—æ¯ä¸ªçº§åˆ«çš„æ¦‚ç‡ï¼Œå¹¶ç”¨è¿™ä¸ªæ¦‚ç‡æ¥æ›¿æ¢åŸå§‹çš„åˆ†ç±»å˜é‡ã€‚\n\nagent_stats &lt;- \n  hotel_train %&gt;%\n  group_by(agent) %&gt;%\n  summarize(\n    ADR = mean(avg_price_per_room), \n    num_reservations = n(),\n    .groups = \"drop\"\n    ) %&gt;%\n  mutate(agent = reorder(agent, ADR))\n\nlibrary(embed)\n\nestimates &lt;- \n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_lencode_mixed(agent, outcome = vars(avg_price_per_room), id = \"encoding\") %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  prep() %&gt;% \n  tidy(id = \"encoding\") %&gt;% \n  select(agent = level, estimate = value)\n\nä¸ºäº†å¾—åˆ° estimates çš„å€¼ï¼Œä¾æ¬¡æ‰§è¡Œäº†ä»¥ä¸‹æ“ä½œï¼š\n\nåˆ›å»ºé¢„å¤„ç†é…æ–¹ï¼šä½¿ç”¨recipe()å‡½æ•°åˆ›å»ºä¸€ä¸ªé¢„å¤„ç†é…æ–¹ï¼ŒæŒ‡å®šè¦æ ¹æ®æ‰€æœ‰å…¶ä»–å˜é‡æ¥é¢„æµ‹çš„ç›®æ ‡avg_price_per_roomã€‚\næ··åˆç¼–ç ï¼šä½¿ç”¨step_lencode_mixed()å‡½æ•°å¯¹agentè¿›è¡Œæ··åˆç¼–ç ã€‚è¿™ä¸ªå‡½æ•°ä¼šè®¡ç®—æ¯ä¸ªçº§åˆ«çš„æ•ˆåº”å¤§å°ï¼Œå¹¶ç”¨è¿™ä¸ªæ•ˆåº”å¤§å°æ›¿æ¢åŸå§‹åˆ†ç±»å˜é‡çš„å€¼ã€‚è¿™æ˜¯ä¸€ç§å¤„ç†åˆ†ç±»å˜é‡çš„æ–¹æ³•ï¼Œå¯ä»¥å°†åˆ†ç±»å˜é‡çš„æ¯ä¸ªçº§åˆ«ä¸ç›®æ ‡å˜é‡çš„æŸç§ç»Ÿè®¡é‡ï¼ˆå¦‚å‡å€¼ï¼‰å…³è”èµ·æ¥ã€‚\nå“‘å˜é‡ç¼–ç ï¼šä½¿ç”¨step_dummy()å‡½æ•°å¯¹æ‰€æœ‰çš„åä¹‰é¢„æµ‹å˜é‡è¿›è¡Œå“‘å˜é‡ç¼–ç ã€‚è¿™ä¼šä¸ºæ¯ä¸ªåˆ†ç±»å˜é‡çš„æ¯ä¸ªçº§åˆ«åˆ›å»ºä¸€ä¸ªæ–°çš„äºŒå…ƒå˜é‡ã€‚\nç§»é™¤é›¶æ–¹å·®é¢„æµ‹å˜é‡ï¼šä½¿ç”¨step_zv()å‡½æ•°ç§»é™¤æ‰€æœ‰çš„é›¶æ–¹å·®é¢„æµ‹å˜é‡ã€‚è¿™äº›å˜é‡åœ¨æ‰€æœ‰è§‚æµ‹ä¸­çš„å€¼éƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤ä¸åŒ…å«ä»»ä½•æœ‰ç”¨çš„ä¿¡æ¯ã€‚\nå½’ä¸€åŒ–ï¼šä½¿ç”¨step_normalize()å‡½æ•°å¯¹æ‰€æœ‰çš„æ•°å€¼é¢„æµ‹å˜é‡è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™ä¼šå°†æ¯ä¸ªå˜é‡çš„å€¼è½¬æ¢ä¸ºå…¶Zåˆ†æ•°ï¼Œå³å‡å»å‡å€¼ç„¶åé™¤ä»¥æ ‡å‡†å·®ã€‚\nå‡†å¤‡é…æ–¹ï¼šä½¿ç”¨prep()å‡½æ•°å‡†å¤‡ï¼ˆå³è®­ç»ƒï¼‰è¿™ä¸ªé…æ–¹ã€‚è¿™ä¼šä½¿é…æ–¹å­¦ä¹ åˆ°è®­ç»ƒæ•°æ®çš„ç‰¹æ€§ï¼Œä¾‹å¦‚å„å˜é‡çš„å‡å€¼å’Œæ ‡å‡†å·®ç­‰ã€‚\næå–ç¼–ç ä¼°è®¡å€¼ï¼šä½¿ç”¨tidy()å‡½æ•°å’Œselect()å‡½æ•°æå–æ··åˆç¼–ç çš„ä¼°è®¡å€¼ï¼Œå¹¶å°†ç»“æœä¿å­˜åœ¨estimatesä¸­ã€‚è¿™ä¸ªæ•°æ®æ¡†åŒ…å«ä¸¤åˆ—ï¼šagentï¼ˆåŸå§‹çš„çº§åˆ«ï¼‰å’Œestimateï¼ˆå¯¹åº”çš„æ•ˆåº”å¤§å°ï¼‰ã€‚\næ¨¡å‹è®­ç»ƒä¸è¯„ä¼°: ä½ å®šä¹‰äº†ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶åœ¨ä¸Šé¢åº”ç”¨äº†ä½ çš„é¢„å¤„ç†æ­¥éª¤ã€‚ç„¶åï¼Œä½ åœ¨äº¤å‰éªŒè¯çš„æ•°æ®é›†ä¸Šæ‹Ÿåˆäº†è¿™ä¸ªæ¨¡å‹ï¼Œå¹¶æ”¶é›†äº†æ¯ä¸ªæŠ˜å çš„åº¦é‡ç»“æœã€‚\n\n\nhotel_effect_rec &lt;-\n  recipe(avg_price_per_room ~ ., data = hotel_train) %&gt;% \n  step_YeoJohnson(lead_time) %&gt;%\n  step_lencode_mixed(agent, company, outcome = vars(avg_price_per_room)) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())\n\nhotel_effect_wflow &lt;-\n  workflow() %&gt;%\n  add_model(linear_reg()) %&gt;% \n  update_recipe(hotel_effect_rec)\n\nWarning: The workflow has no recipe preprocessor to remove.\n\nreg_metrics &lt;- metric_set(mae, rsq)\n\nhotel_effect_res &lt;-\n  hotel_effect_wflow %&gt;%\n  fit_resamples(hotel_rs, metrics = reg_metrics)\n\nâ†’ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\ncollect_metrics(hotel_effect_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   17.8      10 0.189   Preprocessor1_Model1\n2 rsq     standard    0.870    10 0.00357 Preprocessor1_Model1\n\n\nå¯è§†åŒ–: åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œä½ åˆ›å»ºäº†å‡ ä¸ªç›´æ–¹å›¾æ¥å¯è§†åŒ–agent_statsæ•°æ®ï¼Œä»¥åŠä¸€ä¸ªæ•£ç‚¹å›¾æ¥æ¯”è¾ƒADRçš„æ ·æœ¬å‡å€¼å’Œé€šè¿‡æ•ˆæœç¼–ç ä¼°è®¡çš„å€¼ã€‚\n\nbefore &lt;- hotel_train %&gt;% \n    select(avg_price_per_room, agent) %&gt;% \n    slice(1:7) %&gt;% \n    add_rowindex()\nbefore\n\n# A tibble: 7 Ã— 3\n  avg_price_per_room agent            .row\n               &lt;dbl&gt; &lt;fct&gt;           &lt;int&gt;\n1               52.7 cynthia_worsley     1\n2               51.8 carlos_bryant       2\n3               53.8 lance_hitchcock     3\n4               51.8 lance_hitchcock     4\n5               46.8 cynthia_worsley     5\n6               54.7 charles_najera      6\n7               46.8 cynthia_worsley     7\n\nafter &lt;- left_join(before, estimates, by = \"agent\") %&gt;% \n  select(avg_price_per_room, agent = estimate, .row)\nafter\n\n# A tibble: 7 Ã— 3\n  avg_price_per_room agent  .row\n               &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1               52.7  88.5     1\n2               51.8  89.5     2\n3               53.8  79.8     3\n4               51.8  79.8     4\n5               46.8  88.5     5\n6               54.7 109.      6\n7               46.8  88.5     7\n\n\n\nagent_stats %&gt;%   \n  ggplot(aes(x = num_reservations)) +\n  geom_histogram(bins = 30, col = \"blue\", fill = \"blue\", alpha = 1/3) +\n  labs(x = \"Number of reservations per agent\")\n\n\n\nagent_stats %&gt;%   \n  ggplot(aes(x = ADR)) +\n  geom_histogram(bins = 30, col = \"red\", fill = \"red\", alpha = 1/3) +\n  labs(x = \"Average ADR per agent\")\n\n\n\nagent_stats %&gt;%   \n  ggplot(aes(x = num_reservations)) +\n  geom_histogram(bins = 30, col = \"blue\", fill = \"blue\", alpha = 1/3) +\n  labs(x = \"Number of reservations per agent\")\n\n\n\nagent_stats %&gt;%   \n  ggplot(aes(x = ADR)) +\n  geom_histogram(bins = 30, col = \"red\", fill = \"red\", alpha = 1/3) +\n  labs(x = \"Average ADR per agent\")\n\n\n\ninner_join(agent_stats, estimates, by = \"agent\") %&gt;% \n  ggplot(aes(x = ADR, y = estimate)) + \n  geom_abline(col = \"green\", lty = 2) +\n  geom_point(aes(size = num_reservations), alpha = 1/3) +\n  coord_obs_pred() +\n  scale_size(range = c(1/3, 5)) +\n  labs(x = \"ADR Sample Mean\", y = \"Estimated via Effects Encoding\")\n\n\n\n\nè¿™æ®µä»£ç æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹çš„å®ä¾‹ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ç­‰æ­¥éª¤ã€‚å®ƒå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Rå’Œä¸€äº›å…³é”®çš„æ•°æ®ç§‘å­¦åŒ…ï¼ˆå¦‚tidymodelså’Œembedï¼‰æ¥è¿›è¡Œå¤æ‚çš„æ•°æ®åˆ†æå’Œå»ºæ¨¡ä»»åŠ¡ã€‚"
  },
  {
    "objectID": "14.tidymodels-list.html#å¸¸è§æœºå™¨å­¦ä¹ æ¨¡å‹",
    "href": "14.tidymodels-list.html#å¸¸è§æœºå™¨å­¦ä¹ æ¨¡å‹",
    "title": "4Â  å¸¸è§æ¨¡å‹å’Œè½¯ä»¶åŒ…",
    "section": "4.1 å¸¸è§æœºå™¨å­¦ä¹ æ¨¡å‹",
    "text": "4.1 å¸¸è§æœºå™¨å­¦ä¹ æ¨¡å‹\ntidymodels ä¸­åŒ…å«äº†å¾ˆå¤šä¸åŒçš„æ¨¡å‹ï¼ˆhttps://www.tidymodels.org/find/parsnip/ï¼‰ã€‚\n\n4.1.1 æ‰§è¡Œå›å½’ä»»åŠ¡çš„æ¨¡å‹\nä»…å°±æ‰§è¡Œâ€å›å½’â€œä»»åŠ¡çš„æ¨¡å‹è€Œè¨€ï¼Œæœ‰ä¸‹é¢è¿™äº›ã€‚\n\nBoosted ARIMA Regression Models: è¿™ç§æ–¹æ³•ç»“åˆäº†è‡ªå›å½’ç»¼åˆç§»åŠ¨å¹³å‡(ARIMA)å’Œå¢å¼ºç®—æ³•ã€‚ä¸»è¦ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚\nADAM Regression Models: ADAMæŒ‡çš„æ˜¯è‡ªé€‚åº”åŠ¨æ€è‡ªå›å½’ç§»åŠ¨å¹³å‡æ¨¡å‹ï¼Œä¹Ÿä¸»è¦ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚\nARIMA Regression Models: ARIMAæ¨¡å‹æ˜¯ä¸€ç§å¸¸è§çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚\nAutomatic machine learning: è‡ªåŠ¨æœºå™¨å­¦ä¹ (AutoML)æ˜¯ä¸€ç§è‡ªåŠ¨åŒ–é€‰æ‹©æœ€ä½³ç®—æ³•å’Œå‚æ•°çš„è¿‡ç¨‹ã€‚\nBagged MARS: Bagged MARSç»“åˆäº†å¤šé‡è‡ªé€‚åº”å›å½’æ ·æ¡(MARS)å’Œè£…è¢‹(bagging)æŠ€æœ¯ä»¥æé«˜é¢„æµ‹ç²¾åº¦ã€‚\nBagged neural networks: è¿™ç§æ–¹æ³•ç»“åˆäº†ç¥ç»ç½‘ç»œå’Œè£…è¢‹ç®—æ³•ä»¥æå‡ç¨³å¥æ€§ã€‚\nBagged trees: è¢‹è£…å†³ç­–æ ‘æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œæé«˜æ¨¡å‹å‡†ç¡®æ€§å’Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚\nBayesian additive regression trees: BART æ˜¯ä¸€ç§è´å¶æ–¯æ–¹æ³•ï¼Œå¯ç”¨äºå¤„ç†çº¿æ€§å’Œéçº¿æ€§é—®é¢˜ã€‚\nBoosted PROPHET Time Series Models: ç»“åˆäº† Facebookâ€™s Prophet æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•å’Œ boosting æ–¹æ³•ã€‚\nBoosted trees: æå‡æ ‘æ¨¡å‹æ˜¯ä¸€ç§é¢„æµ‹æ¨¡å‹ï¼Œä½¿ç”¨æ¢¯åº¦æå‡æ„å»ºå¼ºå­¦ä¹ å™¨ã€‚\nCubist rule-based regression models: Cubist æ˜¯ä¸€ç§åŸºäºè§„åˆ™çš„å›å½’æ¨¡å‹ï¼Œèƒ½å¤Ÿé€‚åº”éçº¿æ€§å…³ç³»ã€‚\nDecision trees: å†³ç­–æ ‘æ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»å’Œå›å½’æ–¹æ³•ã€‚\nExponential Smoothing State Space Models: ä¹Ÿè¢«ç§°ä¸º ETSï¼Œä¸»è¦ç”¨äºæ—¶é—´åºåˆ—åˆ†æã€‚\nGeneralized additive models: GAM æ˜¯ä¸€ç§çµæ´»çš„çº¿æ€§å›å½’æ–¹æ³•ï¼Œèƒ½å¤„ç†éçº¿æ€§çš„å…³ç³»ã€‚\nK-nearest neighbors: KNN æ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»å’Œå›å½’æ–¹æ³•ã€‚\nLinear regression via keras/tensorflow/glmnet/glm: è¿™äº›éƒ½æ˜¯å®ç°çº¿æ€§å›å½’çš„å·¥å…·æˆ–æ¡†æ¶ã€‚\nLinear support vector machines (SVMs): SVM æ˜¯ä¸€ç§ç±»åˆ«é¢„æµ‹å·¥å…·ï¼Œçº¿æ€§ SVM ä¸»è¦ç”¨äºäºŒå…ƒåˆ†ç±»é—®é¢˜ã€‚\nMultilayer perceptron: MLP æ˜¯ä¸€ç§å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå¤šç”¨äºåˆ†ç±»å’Œå›å½’åˆ†æã€‚\nMultiple Seasonality Regression Models: å¤šå­£èŠ‚æ€§å›å½’æ¨¡å‹ç”¨äºå¤„ç†å…·æœ‰å¤šå­£èŠ‚æ€§å½±å“çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚\nMultivariate adaptive regression splines: MARS æ˜¯ä¸€ç§çµæ´»çš„å›å½’æ–¹æ³•ï¼Œé€‚ç”¨äºé«˜ç»´æ•°æ®é›†ã€‚\nNAIVE Forecast Models: NAIVE æ¨¡å‹æ˜¯ä¸€ç§ç®€å•çš„æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•ï¼Œé€šå¸¸ç”¨ä½œåŸºçº¿é¢„æµ‹ã€‚\nNNETAR Regression Models: NNETAR æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œè‡ªå›å½’æ¨¡å‹ï¼Œä¸»è¦ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚\nParametric survival regression: æ­¤æ–¹æ³•ç”¨äºç”Ÿå­˜åˆ†æä¸­ï¼Œå½“æ•°æ®å…·æœ‰æ—¶é—´è‡³äº‹ä»¶ç‰¹æ€§æ—¶ã€‚\nPoisson regression: æ³Šæ¾å›å½’é€‚ç”¨äºå› å˜é‡ä¸ºè®¡æ•°æ•°æ®çš„æƒ…å†µã€‚\n\n\n\n4.1.2 æ‰§è¡Œåˆ†ç±»ä»»åŠ¡çš„æ¨¡å‹\næ­¤å¤–ï¼Œæ‰§è¡Œâ€œåˆ†ç±»â€ä»»åŠ¡çš„æ¨¡å‹æœ‰ï¼š\n\nAutomatic machine learning: è‡ªåŠ¨æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰æ˜¯ä¸€ç§åˆ©ç”¨ä¼˜åŒ–ç®—æ³•æŒ‘é€‰å‡ºæœ€ä½³ç®—æ³•å’Œå‚æ•°çš„è¿‡ç¨‹ã€‚è¿™å¤§å¤§é™ä½äº†äººå·¥é€‰æ‹©å’Œè°ƒæ•´æ¨¡å‹çš„å¤æ‚åº¦ã€‚\nBagged MARS: è¿™æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œå®ƒç»“åˆäº†å¤šé‡è‡ªé€‚åº”å›å½’æ ·æ¡ï¼ˆMARSï¼‰å’Œè£…è¢‹ï¼ˆbaggingï¼‰æŠ€æœ¯ï¼Œä»¥æé«˜é¢„æµ‹ç²¾åº¦ã€‚\nBagged neural networks: è¿™æ˜¯ä¸€ç§é›†æˆç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚é€šè¿‡åˆ›å»ºå¤šä¸ªç¥ç»ç½‘ç»œå¹¶å–å…¶å¹³å‡å€¼ï¼Œå¯ä»¥æå‡æ¨¡å‹çš„ç¨³å®šæ€§ï¼Œå¹¶å‡å°‘è¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§ã€‚\nBagged trees: è¢‹è£…å†³ç­–æ ‘æ˜¯ä¸€ç§é›†æˆå­¦ä¹ ç­–ç•¥ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ï¼Œå¹¶é™ä½æ¨¡å‹çš„æ–¹å·®ã€‚\nBayesian additive regression trees (BART): BART æ˜¯ä¸€ç§éå‚æ•°è´å¶æ–¯æ–¹æ³•ï¼Œå¯ä»¥ç”¨äºå¤„ç†éçº¿æ€§å’Œäº¤äº’æ•ˆåº”çš„é—®é¢˜ã€‚\nBoosted trees: æå‡æ ‘æ˜¯ä¸€ç§å¼ºå¤§çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡ä¸²è¡Œæ„å»ºä¸€ç³»åˆ—çš„å°å‹å†³ç­–æ ‘ï¼Œæ¯ä¸€ä¸ªæ–°çš„æ ‘å­¦ä¹ å‰é¢æ ‘çš„é”™è¯¯æ¥è¿›è¡Œæ”¹è¿›ã€‚\nC5.0 rule-based classification models: C5.0 æ˜¯ä¸€ä¸ªå†³ç­–æ ‘æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ªè§„åˆ™é›†çš„ç”Ÿæˆå™¨ã€‚å®ƒæ¯”å®ƒçš„å‰èº«C4.5 æ›´å¿«ï¼Œéœ€è¦æ›´å°‘çš„å†…å­˜ï¼Œå¹¶ä¸”æœ‰ä¸€ä¸ªèƒ½æé«˜é¢„æµ‹ç²¾åº¦çš„boostingé€‰é¡¹ã€‚\nDecision trees: å†³ç­–æ ‘æ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€‚ç”¨äºåˆ†ç±»å’Œå›å½’é—®é¢˜ã€‚\nFlexible discriminant analysis (FDA): FDA æ˜¯ä¸€ç§åˆ†ç±»æŠ€æœ¯ï¼Œå®ƒæ‰©å±•äº†çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ï¼Œå…è®¸åœ¨é¢„æµ‹åˆ†ç±»æ—¶ä½¿ç”¨éçº¿æ€§å‡½æ•°ã€‚\nGeneralized additive models (GAM): GAM æ˜¯ä¸€ç§çµæ´»çš„çº¿æ€§å›å½’æ–¹æ³•ï¼Œèƒ½å¤„ç†éçº¿æ€§å’Œéå‚æ•°å…³ç³»ã€‚\nK-nearest neighbors(KNN): KNN æ˜¯ä¸€ç§åŸºäºå®ä¾‹çš„å­¦ä¹ æˆ–å±€éƒ¨è¿‘ä¼¼å’Œæ‰€æœ‰è®¡ç®—åœ¨åˆ†ç±»é˜¶æ®µå®Œæˆçš„éæ³›åŒ–æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚\nLinear discriminant analysis(LDA): LDA æ˜¯ä¸€ç§åˆ†ç±»æŠ€æœ¯ï¼Œå®ƒå¯»æ‰¾æœ€å¤§åŒ–ç±»é—´å·®å¼‚å¹¶æœ€å°åŒ–ç±»å†…å·®å¼‚çš„ç‰¹å¾æŠ•å½±æ–¹å‘ã€‚\nLinear support vector machines (SVMs): çº¿æ€§æ”¯æŒå‘é‡æœºæ˜¯ä¸€ç§äºŒå…ƒåˆ†ç±»æ¨¡å‹ï¼Œå…¶å†³ç­–è¾¹ç•Œæ˜¯æ•°æ®çš„è¶…å¹³é¢ã€‚\nLogistic regression: é€»è¾‘å›å½’æ˜¯ä¸€ç§è§£å†³äºŒå…ƒåˆ†ç±»é—®é¢˜çš„å¸¸è§ç»Ÿè®¡æ–¹æ³•ã€‚\nMultilayer perceptron(MLP): MLP æ˜¯ä¸€ç§å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå®ƒå¯ä»¥å¤„ç†å¤æ‚çš„æ•°æ®é›†ï¼Œå¹¶åœ¨å¤šç§ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ã€‚\nMultinomial regression: å¤šé¡¹å¼å›å½’æ˜¯ä¸€ä¸ªç”¨äºå¤šç±»åˆ†ç±»çš„å¹¿ä¹‰çº¿æ€§æ¨¡å‹ã€‚\nMultivariate adaptive regression splines (MARS): MARS æ˜¯ä¸€ç§çµæ´»çš„éçº¿æ€§å›å½’æ–¹æ³•ï¼Œé€‚ç”¨äºé«˜ç»´é—®é¢˜ã€‚\nNaive Bayes models: æœ´ç´ è´å¶æ–¯æ˜¯ä¸€ç§åŸºäºåº”ç”¨è´å¶æ–¯å®šç†ä¸ç‰¹å¾ç‹¬ç«‹å‡è®¾çš„ç®€å•æ¦‚ç‡åˆ†ç±»å™¨ã€‚\nNull model: ç©ºæ¨¡å‹æ˜¯ä¸€ä¸ªä¸åŒ…å«ä»»ä½•é¢„æµ‹å˜é‡çš„æ¨¡å‹ï¼Œé€šå¸¸ç”¨ä½œæ¯”è¾ƒçš„åŸºå‡†æ¨¡å‹ã€‚\nPartial least squares(PLS): PLS æ˜¯ä¸€ç§å¤„ç†å…·æœ‰å¤šé‡å…±çº¿æ€§æ•°æ®çš„å›å½’åˆ†ææ–¹æ³•ã€‚\nå¤šé¡¹å¼æ”¯æŒå‘é‡æœº (Polynomial SVMs)ï¼š è¿™æ˜¯ä¸€ç§åŸºäºæ”¯æŒå‘é‡æœº (SVM) çš„åˆ†ç±»å’Œå›å½’æ–¹æ³•ã€‚å®ƒé€šè¿‡åœ¨è¾“å…¥æ•°æ®ä¸­å¼•å…¥é«˜é˜¶é¡¹æ¥å¤„ç†éçº¿æ€§é—®é¢˜ã€‚è¿™ä½¿å¾—ç®—æ³•å¯ä»¥åœ¨é«˜ç»´ç©ºé—´ä¸­æ‰¾åˆ°æ•°æ®çš„æœ€ä¼˜åˆ†éš”è¶…å¹³é¢ã€‚\näºŒæ¬¡åˆ¤åˆ«åˆ†æ (Quadratic Discriminant Analysis)ï¼š è¿™æ˜¯ä¸€ç§ç»Ÿè®¡åˆ†ç±»æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨è´å¶æ–¯ç†è®ºå’ŒäºŒæ¬¡åˆ¤åˆ«åˆ†ææ¥ä¼°è®¡ç»™å®šè§‚å¯Ÿå€¼å±äºå“ªä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚å®ƒä¸å‡è®¾å„ç±»åˆ«çš„åæ–¹å·®çŸ©é˜µç›¸åŒï¼Œæ‰€ä»¥èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„æƒ…å†µã€‚\nå¾„å‘åŸºå‡½æ•°æ”¯æŒå‘é‡æœº (Radial Basis Function SVMs)ï¼š å®ƒæ˜¯ä¸€ç§ä½¿ç”¨å¾„å‘åŸºå‡½æ•° (RBF) ä½œä¸ºæ ¸å‡½æ•°çš„æ”¯æŒå‘é‡æœºã€‚RBFå¯ä»¥æ˜ å°„è¾“å…¥åˆ°æ— é™ç»´çš„ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—éçº¿æ€§é—®é¢˜å˜å¾—çº¿æ€§å¯è§£ã€‚\néšæœºæ£®æ— (Random forests)ï¼š è¿™æ˜¯ä¸€ç§åŸºäºå†³ç­–æ ‘çš„é›†æˆå­¦ä¹ ç®—æ³•ã€‚å®ƒé€šè¿‡ç”Ÿæˆå’Œç»“åˆè®¸å¤šä¸ªå†³ç­–æ ‘ï¼Œå‡å°‘è¿‡æ‹Ÿåˆçš„é£é™©ï¼Œå¹¶æé«˜é¢„æµ‹æ€§èƒ½ã€‚\næ­£åˆ™åŒ–åˆ¤åˆ«åˆ†æ (Regularized Discriminant Analysis)ï¼š å®ƒæ˜¯ä¸€ç§æ”¹è¿›çš„åˆ¤åˆ«åˆ†ææ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æ­£åˆ™åŒ–å‚æ•°æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚è¿™ä½¿å¾—æ¨¡å‹æ—¢èƒ½ä¿æŒé«˜åº¦çš„å¤æ‚æ€§ï¼Œåˆèƒ½é˜²æ­¢å¯¹è®­ç»ƒæ•°æ®çš„è¿‡åº¦æ‹Ÿåˆã€‚\nRuleFit æ¨¡å‹: è¿™æ˜¯ä¸€ä¸ªå¯¹æ•°æ®ç”Ÿæˆå¯è§£é‡Šè§„åˆ™çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å®ƒç»“åˆäº†å†³ç­–æ ‘å’Œçº¿æ€§æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œå¯ä»¥ç”Ÿæˆç®€å•ã€ç›´è§‚ä¸”å¥½ç†è§£çš„è§„åˆ™ã€‚"
  },
  {
    "objectID": "14.tidymodels-list.html#ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡çš„-r-è½¯ä»¶åŒ…",
    "href": "14.tidymodels-list.html#ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡çš„-r-è½¯ä»¶åŒ…",
    "title": "4Â  å¸¸è§æ¨¡å‹å’Œè½¯ä»¶åŒ…",
    "section": "4.2 ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡çš„ R è½¯ä»¶åŒ…",
    "text": "4.2 ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡çš„ R è½¯ä»¶åŒ…\nè¿™äº›æ¨¡å‹é€šè¿‡è°ƒç”¨èƒŒåçš„è½¯ä»¶åŒ…æˆ–ç®—æ³•å®ç°åŠŸèƒ½ã€‚åœ¨ CRAN çš„ MachineLearning Viewsï¼Œå°±åˆ—ä¸¾äº†å¾ˆå¤šè¿™æ ·çš„è½¯ä»¶åŒ…ã€‚\n\n4.2.1 R è½¯ä»¶åŒ…çš„åˆ—è¡¨\nè¿™äº›è½¯ä»¶åŒ…æ°›å›´æ ¸å¿ƒåŒ…ã€å¸¸ç”¨åŒ…å’Œå·²è¢«å½’æ¡£çš„åŒ…ï¼ˆåœæ­¢ç»´æŠ¤çš„è½¯ä»¶åŒ…ï¼‰ã€‚\nCore:\nabess, e1071, gbm, kernlab, mboost, nnet, randomForest, rpart.\nRegular:\nadabag, ahaz, ALEPlot, arules, BART, bartMachine, BayesTree, BDgraph, Boruta, bst, C50, caret, CORElearn, Cubist, DALEX, deepnet, dipm, DoubleML, earth, effects, elasticnet, evclass, evreg, evtree, fastshap, frbs, gamboostLSS, glmertree, glmnet, glmpath, GMMBoost, grf, grplasso, grpreg, h2o, hda, hdi, hdm, iBreakDown, ICEbox, iml, ipred, islasso, joinet, kernelshap, klaR, lars, LiblineaR, lightgbm, lime, maptree, mlpack, mlr3, model4you, mpath, naivebayes, ncvreg, nestedcv, OneR, opusminer, pamr, party, partykit, pdp, penalized, picasso, plotmo, pre, quantregForest, quint, randomForestSRC, ranger, Rborist, rgenoud, RGF, RLT, Rmalschains, rminer, ROCR, RoughSets, RPMM, RSNNS, RWeka, RXshrink, sda, semtree, shapper, shapr, shapviz, SIS, splitTools, ssgraph, stabs, SuperLearner, svmpath, tensorflow, tgp, tidymodels, torch, tree, trtf, varSelRF, wsrf, xgboost.\nArchived:\npenalizedLDA, RcppDL.\n\n\n\n\n\n\nNote\n\n\n\nä¸‹é¢æ˜¯å¯¹è¿™äº›è½¯ä»¶åŒ…åŠŸèƒ½çš„åˆ†ç±»ä»‹ç»ã€‚ä¸ºäº†ç¡®ä¿ä¸€è‡´æ€§ï¼Œä»¥ä¸­è‹±æ–‡å¯¹ç…§çš„å½¢å¼å±•ç¤ºã€‚\n\n\n\n\n4.2.2 ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ çš„è½¯ä»¶åŒ…\nç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ ï¼šå•éšå±‚ç¥ç»ç½‘ç»œåœ¨ nnet åŒ…ä¸­å®ç°ï¼ˆéšåŸºç¡€ R ä¸€èµ·æä¾›ï¼‰ã€‚RSNNS åŒ…æä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œå¯ä»¥è¿æ¥åˆ°æ–¯å›¾åŠ ç‰¹ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿå™¨ï¼ˆSNNSï¼‰ã€‚å®ç°æ·±åº¦å­¦ä¹ é£æ ¼çš„ç¥ç»ç½‘ç»œçš„åŒ…åŒ…æ‹¬ deepnetï¼ˆå‰é¦ˆç¥ç»ç½‘ç»œï¼Œå—é™ç»å°”å…¹æ›¼æœºï¼Œæ·±åº¦ä¿¡å¿µç½‘ç»œï¼Œå †å è‡ªç¼–ç å™¨ï¼‰ï¼ŒRcppDLï¼ˆå·²å½’æ¡£ï¼‰ï¼ˆå»å™ªè‡ªç¼–ç å™¨ï¼Œå †å å»å™ªè‡ªç¼–ç å™¨ï¼Œå—é™ç»å°”å…¹æ›¼æœºï¼Œæ·±åº¦ä¿¡å¿µç½‘ç»œï¼‰å’Œ h2oï¼ˆå‰é¦ˆç¥ç»ç½‘ç»œï¼Œæ·±åº¦è‡ªç¼–ç å™¨ï¼‰ã€‚tensorflow åŒ…æä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œå¯ä»¥è¿æ¥åˆ° tensorflowã€‚torch åŒ…å®ç°äº†ä¸€ä¸ªæ¥å£ï¼Œå¯ä»¥è¿æ¥åˆ° libtorch åº“ã€‚evreg åŒ…ä¸­å®ç°çš„ ENNreg è¯æ®å›å½’ç¥ç»ç½‘ç»œæ¨¡å‹å¯ä»¥é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚\n\nNeural Networks and Deep Learning : Single-hidden-layer neural network are implemented in package nnet (shipped with base R). Package RSNNS offers an interface to the Stuttgart Neural Network Simulator (SNNS). Packages implementing deep learning flavours of neural networks include deepnet (feed-forward neural network, restricted Boltzmann machine, deep belief network, stacked autoencoders), RcppDL (archived) (denoising autoencoder, stacked denoising autoencoder, restricted Boltzmann machine, deep belief network) and h2o (feed-forward neural network, deep autoencoders). An interface to tensorflow is available in tensorflow. The torchpackage implements an interface to the libtorch library. Prediction uncertainty can be quantified by the ENNreg evidential regression neural network model implemented in evreg.\n\n\n\n4.2.3 é€’å½’åˆ’åˆ†çš„è½¯ä»¶åŒ…\n\né€’å½’åˆ’åˆ†ï¼šæ ¹æ®CARTä¹¦ä¸­çš„æ€æƒ³ï¼Œå®ç°äº†ç”¨äºå›å½’ã€åˆ†ç±»å’Œç”Ÿå­˜åˆ†æçš„æ ‘ç»“æ„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨ rpartï¼ˆä¸åŸºç¡€Rä¸€èµ·æä¾›ï¼‰å’Œ tree ä¸­å®ç°ã€‚å»ºè®®ä½¿ç”¨rpart åŒ…æ¥è®¡ç®—ç±»ä¼¼CARTçš„æ ‘ã€‚Weka æä¾›äº†ä¸°å¯Œçš„åˆ’åˆ†ç®—æ³•å·¥å…·ç®±ï¼ŒRWekaåŒ…ä¸ºæ­¤å®ç°æä¾›äº†æ¥å£ï¼ŒåŒ…æ‹¬C4.5çš„J4.8å˜ä½“å’ŒM5ã€‚CubiståŒ…é€‚åˆå¸¦æœ‰çº¿æ€§å›å½’æ¨¡å‹çš„è§„åˆ™åŸºç¡€æ¨¡å‹ï¼ˆç±»ä¼¼äºæ ‘ï¼‰ï¼Œç»ˆç«¯å¶å­ã€åŸºäºå®ä¾‹çš„ä¿®æ­£å’Œboostingã€‚C50åŒ…å¯ä»¥æ‹Ÿåˆ C5.0 åˆ†ç±»æ ‘ã€åŸºäºè§„åˆ™çš„æ¨¡å‹ã€ä»¥åŠè¿™äº›æ¨¡å‹çš„boostedç‰ˆæœ¬ã€‚pre å¯ä»¥æ‹Ÿåˆæ›´å¹¿æ³›å“åº”å˜é‡ç±»å‹çš„åŸºäºè§„åˆ™çš„æ¨¡å‹ã€‚\nåœ¨party å’Œ partykitåŒ…ä¸­å®ç°äº†ä¸¤ç§å…·æœ‰æ— åå˜é‡é€‰æ‹©å’Œç»Ÿè®¡åœæ­¢å‡†åˆ™çš„é€’å½’åˆ’åˆ†ç®—æ³•ã€‚å‡½æ•° ctree() åŸºäºéå‚æ•°æ¡ä»¶æ¨ç†è¿‡ç¨‹ç”¨äºæµ‹è¯•å“åº”ä¸æ¯ä¸ªè¾“å…¥å˜é‡ä¹‹é—´çš„ç‹¬ç«‹æ€§ï¼Œè€Œ mob() å¯ç”¨äºå¯¹å‚æ•°æ¨¡å‹è¿›è¡Œåˆ’åˆ†ã€‚åœ¨party å’Œ partykitåŒ…ä¸­ä¹Ÿæä¾›äº†å¯æ‰©å±•çš„å·¥å…·ç”¨äºå¯è§†åŒ–äºŒå‰æ ‘å’Œå“åº”çš„èŠ‚ç‚¹åˆ†å¸ƒã€‚æ··åˆæ•ˆåº”æ¨¡å‹ï¼ˆGLMMsï¼‰çš„åˆ’åˆ†å¯ä»¥ä½¿ç”¨ glmertree åŒ…æ‰§è¡Œï¼›ç»“æ„æ–¹ç¨‹æ¨¡å‹ï¼ˆSEMsï¼‰çš„åˆ’åˆ†å¯ä»¥ä½¿ç”¨ semtree åŒ…æ‰§è¡Œã€‚ ç”¨äºå¯è§†åŒ–æ ‘çš„å›¾å½¢å·¥å…·åœ¨ maptree åŒ…ä¸­å¯ç”¨ã€‚\næ··åˆæ¨¡å‹çš„åˆ’åˆ†ç”± RPMM æ‰§è¡Œã€‚\nåœ¨ partykit ä¸­å®ç°äº†ä»£è¡¨æ ‘å’Œç»Ÿä¸€é¢„æµ‹å’Œå¯è§†åŒ–æ–¹æ³•çš„è®¡ç®—åŸºç¡€è®¾æ–½ã€‚è¿™ç§åŸºç¡€è®¾æ–½è¢« evtree åŒ…ç”¨äºå®ç°å…¨å±€æœ€ä¼˜æ ‘çš„è¿›åŒ–å­¦ä¹ ã€‚å„ç§åŒ…ä¸­éƒ½æœ‰ç”Ÿå­˜æ ‘ã€‚\nå…³äºå¼‚è´¨å¤„ç†æ•ˆåº”çš„å­ç»„è¯†åˆ«çš„æ ‘ï¼Œåœ¨partykitï¼Œmodel4youï¼Œdipmï¼Œquintï¼Œpkg(\"SIDES\")ï¼Œpkg(\"psica\") å’Œ pkg(\"MrSGUIDE\")åŒ…ï¼ˆå¯èƒ½è¿˜æœ‰æ›´å¤šï¼‰ä¸­å¯ç”¨ã€‚\nRecursive Partitioning : Tree-structured models for regression, classification and survival analysis, following the ideas in the CART book, are implemented in rpart (shipped with base R) and tree. Package rpart is recommended for computing CART-like trees. A rich toolbox of partitioning algorithms is available in Weka, package RWeka provides an interface to this implementation, including the J4.8-variant of C4.5 and M5. The Cubist package fits rule-based models (similar to trees) with linear regression models in the terminal leaves, instance-based corrections and boosting. The C50 package can fit C5.0 classification trees, rule-based models, and boosted versions of these. pre can fit rule-based models for a wider range of response variable types.\nTwo recursive partitioning algorithms with unbiased variable selection and statistical stopping criterion are implemented in package party and partykit. Function ctree() is based on non-parametric conditional inference procedures for testing independence between response and each input variable whereas mob() can be used to partition parametric models. Extensible tools for visualizing binary trees and node distributions of the response are available in package party and partykit as well. Partitioning of mixed-effects models (GLMMs) can be performed with package glmertree; partitioning of structural equation models (SEMs) can be performed with package semtree. Graphical tools for the visualization of trees are available in package maptree.\nPartitioning of mixture models is performed by RPMM.\nComputational infrastructure for representing trees and unified methods for prediction and visualization is implemented in partykit. This infrastructure is used by package evtree to implement evolutionary learning of globally optimal trees. Survival trees are available in various packages.\nTrees for subgroup identification with respect to heterogenuous treatment effects are available in packages partykit, model4you, dipm, quint, pkg(\"SIDES\"), pkg(\"psica\"), and pkg(\"MrSGUIDE\") (and probably many more).\n\n\n\n4.2.4 éšæœºæ£®æ—çš„è½¯ä»¶åŒ…\n\néšæœºæ£®æ—ï¼šéšæœºæ£®æ—ç®—æ³•çš„å‚è€ƒå®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å›å½’å’Œåˆ†ç±»ï¼Œåœ¨randomForeståŒ…ä¸­éƒ½æœ‰æä¾›ã€‚ipredåŒ…æä¾›ç”¨äºå›å½’ã€åˆ†ç±»å’Œç”Ÿå­˜åˆ†æçš„baggingæ–¹å¼ï¼Œä»¥åŠé€šè¿‡é›†æˆå­¦ä¹ ç»“åˆå¤šä¸ªæ¨¡å‹çš„bundlingæ–¹å¼ã€‚æ­¤å¤–ï¼ŒåŸºäºæ¡ä»¶æ¨æ–­æ ‘é€‚åº”ä»»æ„å°ºåº¦æµ‹é‡çš„å“åº”å˜é‡çš„éšæœºæ£®æ—å˜ä½“åœ¨partyåŒ…ä¸­æœ‰å®ç°ã€‚randomForestSRCå®ç°äº†Breimançš„éšæœºæ£®æ—å¯¹ç”Ÿå­˜ã€å›å½’å’Œåˆ†ç±»é—®é¢˜çš„ç»Ÿä¸€å¤„ç†ã€‚Quantileå›å½’æ£®æ—quantregForestå…è®¸é€šè¿‡éšæœºæ£®æ—æ–¹æ³•å¯¹æ¢ç´¢æ€§å˜é‡è¿›è¡Œæ•°å€¼å“åº”çš„åˆ†ä½æ•°å›å½’ã€‚é’ˆå¯¹äºŒå…ƒæ•°æ®ï¼ŒvarSelRFå’ŒBorutaåŒ…å…³æ³¨é€šè¿‡éšæœºæ£®æ—ç®—æ³•è¿›è¡Œçš„å˜é‡é€‰æ‹©ã€‚æ­¤å¤–ï¼Œrangerå’ŒRboriståŒ…æä¾›äº†Ræ¥å£å¿«é€Ÿå®ç°C++éšæœºæ£®æ—ã€‚åœ¨RLTåŒ…ä¸­å®ç°äº†å¼ºåŒ–å­¦ä¹ æ ‘ï¼Œç‰¹ç‚¹æ˜¯åœ¨å°†æ¥å¯èƒ½é‡è¦çš„å˜é‡ä¸­è¿›è¡Œåˆ’åˆ†ã€‚wsrfå®ç°äº†ä¸€ä¸ªæ›¿ä»£æ€§çš„å˜é‡æƒé‡æ³•ï¼Œç”¨äºæ›¿ä»£ä¼ ç»Ÿçš„éšæœºå˜é‡æŠ½æ ·è¿›è¡Œå˜é‡å­ç©ºé—´é€‰æ‹©ã€‚RGFåŒ…æ˜¯ä¸€ä¸ªæ¥å£ï¼Œè¿æ¥åˆ°Pythonå®ç°çš„ä¸€ç§å«åšæ­£åˆ™åŒ–è´ªå©ªæ£®æ—çš„ç¨‹åºã€‚é’ˆå¯¹å‚æ•°æ¨¡å‹çš„éšæœºæ£®æ—ï¼ŒåŒ…æ‹¬ç”¨äºé¢„æµ‹åˆ†å¸ƒä¼°è®¡çš„æ£®æ—ï¼Œå¯ä»¥åœ¨trtfï¼ˆå¯èƒ½åœ¨å®¡æŸ¥å’Œæˆªæ–­ä¸‹çš„é¢„æµ‹è½¬æ¢æ£®æ—ï¼‰å’Œgrfï¼ˆæ³›åŒ–éšæœºæ£®æ—çš„å®ç°ï¼‰åŒ…ä¸­æ‰¾åˆ°ã€‚\nRandom Forests : The reference implementation of the random forest algorithm for regression and classification is available in package randomForest. Package ipred has bagging for regression, classification and survival analysis as well as bundling, a combination of multiple models via ensemble learning. In addition, a random forest variant for response variables measured at arbitrary scales based on conditional inference trees is implemented in package party. randomForestSRC implements a unified treatment of Breimanâ€™s random forests for survival, regression and classification problems. Quantile regression forests quantregForest allow to regress quantiles of a numeric response on exploratory variables via a random forest approach. For binary data, The varSelRF and Boruta packages focus on variable selection by means for random forest algorithms. In addition, packages ranger and Rborist offer R interfaces to fast C++ implementations of random forests. Reinforcement Learning Trees, featuring splits in variables which will be important down the tree, are implemented in package RLT. wsrf implements an alternative variable weighting method for variable subspace selection in place of the traditional random variable sampling. Package RGF is an interface to a Python implementation of a procedure called regularized greedy forests. Random forests for parametric models, including forests for the estimation of predictive distributions, are available in packages trtf (predictive transformation forests, possibly under censoring and trunction) and grf (an implementation of generalised random forests).\n\n\n\n4.2.5 æ­£åˆ™åŒ–å’Œæ”¶ç¼©æ–¹æ³•çš„è½¯ä»¶åŒ…\n\næ­£è§„åŒ–å’Œæ”¶ç¼©æ–¹æ³•ï¼šå¯ä»¥ä½¿ç”¨larsåŒ…æ¥æ‹Ÿåˆå¸¦æœ‰æŸäº›å‚æ•°ä¼°è®¡çº¦æŸçš„å›å½’æ¨¡å‹ã€‚åœ¨grplassoåŒ…ä¸­æä¾›äº†åŒæ—¶æ›´æ–°å‚æ•°ç»„ï¼ˆå³ç»„lassoï¼‰çš„Lassoï¼›grpregåŒ…å®ç°äº†è¯¸å¦‚ç»„MCPå’Œç»„SCADç­‰å…¶ä»–ä¸€äº›ç»„æƒ©ç½šæ¨¡å‹ã€‚å¯ä»¥ä»glmpathåŒ…ä¸­è·å¾—å¹¿ä¹‰çº¿æ€§æ¨¡å‹å’ŒCoxæ¨¡å‹çš„L1æ­£åˆ™åŒ–è·¯å¾„ï¼Œæ•´ä¸ªlassoæˆ–å¼¹æ€§ç½‘æ­£åˆ™åŒ–è·¯å¾„ï¼ˆä¹Ÿåœ¨elasticnetä¸­ï¼‰ç”¨äºçº¿æ€§å›å½’ã€é€»è¾‘å›å½’å’Œå¤šé¡¹å¼å›å½’æ¨¡å‹ï¼Œå¯ä»¥ä»glmnetåŒ…ä¸­è·å¾—ã€‚penalizedåŒ…æä¾›äº†lassoï¼ˆL1ï¼‰å’Œridgeï¼ˆL2ï¼‰æƒ©ç½šå›å½’æ¨¡å‹ï¼ˆåŒ…æ‹¬GLMå’ŒCoxæ¨¡å‹ï¼‰çš„å¦ä¸€ç§å®ç°ã€‚å¯ä»¥ä½¿ç”¨RXshrinkåŒ…ç”ŸæˆTRACEæ˜¾ç¤ºï¼Œå½“é”™è¯¯ä¸ºIID Normalæ—¶ï¼Œæ ‡è¯†å‡ºæœ€å¤§ä¼¼ç„¶æˆ–æœ€å°MSEé£é™©çš„æ”¶ç¼©ç¨‹åº¦ã€‚ahazåŒ…æä¾›äº†åœ¨lassoæƒ©ç½šä¸‹çš„åŠå‚æ•°åŠ æ€§é£é™©æ¨¡å‹ã€‚Fisherçš„LDAæŠ•å½±é€šè¿‡å¯é€‰çš„LASSOæƒ©ç½šäº§ç”Ÿç¨€ç–è§£ï¼Œåœ¨penalizedLDA (archived)åŒ…ä¸­å®ç°ã€‚pamråŒ…å®ç°äº†æ”¶ç¼©è´¨å¿ƒåˆ†ç±»å™¨å’ŒåŸºå› è¡¨è¾¾åˆ†æçš„å®ç”¨å·¥å…·ã€‚earthåŒ…ä¸­æä¾›äº†å¤šå˜é‡è‡ªé€‚åº”å›å½’æ ·æ¡çš„å®ç°ã€‚å„ç§å½¢å¼çš„æƒ©ç½šåˆ¤åˆ«åˆ†æåœ¨hdaå’ŒsdaåŒ…ä¸­å®ç°ã€‚LiblineaRåŒ…æä¾›äº†å¯¹LIBLINEARåº“çš„æ¥å£ã€‚ncvregåŒ…ä½¿ç”¨åæ ‡ä¸‹é™ç®—æ³•æ‹ŸåˆSCADå’ŒMCPå›å½’æƒ©ç½šä¸‹çš„çº¿æ€§å’Œé€»è¾‘å›å½’æ¨¡å‹ã€‚åŒæ ·çš„æƒ©ç½šä¹Ÿåœ¨picassoåŒ…ä¸­å®ç°ã€‚åœ¨éé«˜æ–¯å’Œå¼‚æ–¹å·®é”™è¯¯ä¸‹çš„Lassoç”±hdmä¼°è®¡ï¼ŒåŒ…å«åœ¨é«˜ç»´è®¾å®šä¸­å¯¹Lassoå›å½’å’Œä¼°è®¡å¤„ç†æ•ˆæœçš„ä½ç»´ç»„ä»¶çš„æ¨æ–­ã€‚SISåŒ…å®ç°äº†å¹¿ä¹‰çº¿æ€§å’ŒCoxæ¨¡å‹çš„ç‹¬ç«‹ç­›é€‰ã€‚ç›¸å…³ç»“æœçš„å¼¹æ€§ç½‘åœ¨joinetåŒ…ä¸­æä¾›ã€‚é€šè¿‡å¤åˆä¼˜åŒ–å…±è½­ç®—å­æ¥æ‹Ÿåˆä½¿ç”¨mpathåŒ…çš„ç¨³å¥æƒ©ç½šå¹¿ä¹‰çº¿æ€§æ¨¡å‹å’Œç¨³å¥æ”¯æŒå‘é‡æœºã€‚islassoåŒ…æä¾›äº†åŸºäºè¯±å¯¼å¹³æ»‘ç†å¿µçš„lassoå®ç°ï¼Œè¿™å¯ä»¥ä¸ºæ‰€æœ‰æ¨¡å‹å‚æ•°è·å¾—å¯é çš„på€¼ã€‚æœ€ä½³å­é›†é€‰æ‹©ï¼Œç”¨äºçº¿æ€§ã€é€»è¾‘ã€Coxç­‰å…¶ä»–å›å½’æ¨¡å‹ï¼ŒåŸºäºä¸€ä¸ªå¿«é€Ÿçš„å¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼Œå¯ä»abessåŒ…è·å–ã€‚\nRegularized and Shrinkage Methods : Regression models with some constraint on the parameter estimates can be fitted with the lars package. Lasso with simultaneous updates for groups of parameters (groupwise lasso) is available in package grplasso; the grpreg package implements a number of other group penalization models, such as group MCP and group SCAD. The L1 regularization path for generalized linear models and Cox models can be obtained from functions available in package glmpath, the entire lasso or elastic-net regularization path (also in elasticnet) for linear regression, logistic and multinomial regression models can be obtained from package glmnet. The penalized package provides an alternative implementation of lasso (L1) and ridge (L2) penalized regression models (both GLM and Cox models). Package RXshrink can be used to generate TRACE displays that identify the extent of shrinkage with Maximum Likelihood of Minimum MSE Risk when errors are IID Normal. Semiparametric additive hazards models under lasso penalties are offered by package ahaz. Fisherâ€™s LDA projection with an optional LASSO penalty to produce sparse solutions is implemented in package penalizedLDA (archived). The shrunken centroids classifier and utilities for gene expression analyses are implemented in package pamr. An implementation of multivariate adaptive regression splines is available in package earth. Various forms of penalized discriminant analysis are implemented in packages hda and sda. Package LiblineaR offers an interface to the LIBLINEAR library. The ncvreg package fits linear and logistic regression models under the the SCAD and MCP regression penalties using a coordinate descent algorithm. The same penalties are also implemented in the picasso package. The Lasso under non-Gaussian and heteroscedastic errors is estimated by hdm, inference on low-dimensional components of Lasso regression and of estimated treatment effects in a high-dimensional setting are also contained. Package SIS implements sure independence screening in generalised linear and Cox models. Elastic nets for correlated outcomes are available from package joinet. Robust penalized generalized linear models and robust support vector machines are fitted by package mpath using composite optimization by conjugation operator. The islasso package provides an implementation of lasso based on the induced smoothing idea which allows to obtain reliable p-values for all model parameters. Best-subset selection for linear, logistic, Cox and other regression models, based on a fast polynomial time algorithm, is available from package abess.\n\n\n\n4.2.6 å¢å¼ºå’Œæ¢¯åº¦ä¸‹é™çš„è½¯ä»¶åŒ…\n\nå¢å¼ºå’Œæ¢¯åº¦ä¸‹é™ï¼šå„ç§å½¢å¼çš„æ¢¯åº¦æå‡åœ¨gbmåŒ…ä¸­å®ç°ï¼ˆåŸºäºæ ‘çš„å‡½æ•°æ¢¯åº¦ä¸‹é™æå‡ï¼‰ã€‚lightgbmå’ŒxgbooståŒ…å®ç°äº†åŸºäºé«˜æ•ˆæ ‘ä½œä¸ºåŸºç¡€å­¦ä¹ å™¨çš„æ ‘å½¢æå‡ï¼Œé€‚ç”¨äºå¤šä¸ªå’Œç”¨æˆ·è‡ªå®šä¹‰çš„ç›®æ ‡å‡½æ•°ã€‚bståŒ…ä¸­çš„æå‡å®ç°ä¼˜åŒ–äº†é“°é“¾æŸå¤±ã€‚ä¸€ä¸ªå¯æ‰©å±•çš„æå‡æ¡†æ¶ï¼Œé€‚ç”¨äºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ã€åŠ æ³•æ¨¡å‹å’Œéå‚æ•°æ¨¡å‹ï¼Œå¯ä»¥åœ¨mbooståŒ…ä¸­æ‰¾åˆ°ã€‚æ··åˆæ¨¡å‹çš„ä¼¼ç„¶åŸºæå‡åœ¨GMMBoostä¸­å®ç°ã€‚GAMLSSæ¨¡å‹å¯ä»¥é€šè¿‡gamboostLSSä½¿ç”¨æå‡æ¥æ‹Ÿåˆã€‚adabagå®ç°äº†ç»å…¸çš„AdaBoostç®—æ³•ï¼Œå¹¶æ·»åŠ äº†åŠŸèƒ½ï¼Œå¦‚å˜é‡é‡è¦æ€§ã€‚\nBoosting and Gradient Descent : Various forms of gradient boosting are implemented in package gbm (tree-based functional gradient descent boosting). Package lightgbm and xgboost implement tree-based boosting using efficient trees as base learners for several and also user-defined objective functions. The Hinge-loss is optimized by the boosting implementation in package bst. An extensible boosting framework for generalized linear, additive and nonparametric models is available in package mboost. Likelihood-based boosting for mixed models is implemented in GMMBoost. GAMLSS models can be fitted using boosting by gamboostLSS. adabag implements the classical AdaBoost algorithm with added functionality, such as variable importances.\n\n\n\n4.2.7 æ”¯æŒå‘é‡æœºå’Œæ ¸æ–¹æ³•çš„è½¯ä»¶åŒ…\n\næ”¯æŒå‘é‡æœºå’Œæ ¸æ–¹æ³•ï¼še1071ä¸­çš„svm()å‡½æ•°æä¾›äº†ä¸€ä¸ªæ¥å£åˆ°LIBSVMåº“ï¼ŒkernlabåŒ…å®ç°äº†ä¸€ä¸ªçµæ´»çš„æ ¸å­¦ä¹ æ¡†æ¶ï¼ˆåŒ…æ‹¬SVMsã€RVMså’Œå…¶ä»–æ ¸å­¦ä¹ ç®—æ³•ï¼‰ã€‚klaRåŒ…æä¾›äº†ä¸€ä¸ªæ¥å£åˆ°SVMlightå®ç°ï¼ˆä»…ç”¨äºä¸€å¯¹æ‰€æœ‰çš„åˆ†ç±»ï¼‰ã€‚\nSupport Vector Machines and Kernel Methods : The function svm() from e1071 offers an interface to the LIBSVM library and package kernlab implements a flexible framework for kernel learning (including SVMs, RVMs and other kernel learning algorithms). An interface to the SVMlight implementation (only for one-against-all classification) is provided in package klaR.\n\n\n\n4.2.8 è´å¶æ–¯æ–¹æ³•çš„è½¯ä»¶åŒ…\n\nè´å¶æ–¯æ–¹æ³•ï¼šè´å¶æ–¯åŠ æ³•å›å½’æ ‘ï¼ˆBARTï¼‰åœ¨BayesTreeï¼ŒBART å’Œ bartMachine åŒ…ä¸­æœ‰å®ç°ï¼Œå…¶æœ€ç»ˆæ¨¡å‹æ˜¯ä»¥è®¸å¤šå¼±å­¦ä¹ å™¨çš„æ€»å’Œå®šä¹‰çš„ï¼ˆä¸é›†æˆæ–¹æ³•ç±»ä¼¼ï¼‰ã€‚åŒ…tgpæä¾›äº†è´å¶æ–¯éå¹³ç¨³ï¼ŒåŠå‚æ•°éçº¿æ€§å›å½’å’Œè®¾è®¡é€šè¿‡é«˜æ–¯è¿‡ç¨‹åŒ…å«è´å¶æ–¯CARTå’Œçº¿æ€§æ¨¡å‹ã€‚åŒ…BDgraphå®ç°äº†é’ˆå¯¹å¤šå˜é‡è¿ç»­ã€ç¦»æ•£å’Œæ··åˆæ•°æ®çš„æ— å‘å›¾å½¢æ¨¡å‹ä¸­çš„è´å¶æ–¯ç»“æ„å­¦ä¹ ï¼›ç›¸åº”çš„ä¾èµ–äºå°–å³°å’Œæ¿çŠ¶å…ˆéªŒçš„æ–¹æ³•å¯ä»¥ä»ssgraphåŒ…ä¸­è·å¾—ã€‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨åœ¨naivebayesåŒ…ä¸­æä¾›ã€‚\nBayesian Methods : Bayesian Additive Regression Trees (BART), where the final model is defined in terms of the sum over many weak learners (not unlike ensemble methods), are implemented in packages BayesTree, BART, and bartMachine. Bayesian nonstationary, semiparametric nonlinear regression and design by treed Gaussian processes including Bayesian CART and treed linear models are made available by package tgp. Bayesian structure learning in undirected graphical models for multivariate continuous, discrete, and mixed data is implemented in package BDgraph; corresponding methods relying on spike-and-slab priors are available from package ssgraph. Naive Bayes classifiers are available in naivebayes.\n\n\n\n4.2.9 æä¾›é—ä¼ ç®—æ³•çš„è½¯ä»¶åŒ…\n\nä½¿ç”¨é—ä¼ ç®—æ³•ä¼˜åŒ–ï¼šrgenoudåŒ…æä¾›äº†åŸºäºé—ä¼ ç®—æ³•çš„ä¼˜åŒ–ç¨‹åºã€‚RmalschainsåŒ…å®ç°äº†å¸¦æœ‰æœ¬åœ°æœç´¢é“¾çš„é—ä¼ ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„è¿›åŒ–ç®—æ³•ï¼Œç»“åˆäº†ç¨³å®šçŠ¶æ€çš„é—ä¼ ç®—æ³•å’Œæœ¬åœ°æœç´¢ç”¨äºå®å€¼å‚æ•°ä¼˜åŒ–ã€‚\nOptimization using Genetic Algorithms : Package rgenoud offers optimization routines based on genetic algorithms. The package Rmalschains implements memetic algorithms with local search chains, which are a special type of evolutionary algorithms, combining a steady state genetic algorithm with local search for real-valued parameter optimization.\n\n\n\n4.2.10 å…³è”è§„åˆ™åˆ†æçš„è½¯ä»¶åŒ…\n\nå…³è”è§„åˆ™ï¼šarulesåŒ…ä¸ºé«˜æ•ˆå¤„ç†ç¨€ç–äºŒè¿›åˆ¶æ•°æ®æä¾›äº†æ•°æ®ç»“æ„ï¼ŒåŒæ—¶ä¸ºAprioriå’ŒEclatçš„å®ç°æä¾›äº†æ¥å£ï¼Œç”¨äºæŒ–æ˜é¢‘ç¹é¡¹é›†ã€æœ€å¤§é¢‘ç¹é¡¹é›†ã€å°é—­é¢‘ç¹é¡¹é›†å’Œå…³è”è§„åˆ™ã€‚opusmineråŒ…æä¾›äº†ä¸€ä¸ªæ¥å£åˆ°OPUS Minerç®—æ³•ï¼ˆåœ¨C++ä¸­å®ç°ï¼‰ï¼Œç”¨äºæœ‰æ•ˆåœ°æ‰¾åˆ°äº¤æ˜“æ•°æ®ä¸­çš„å…³é”®å…³è”ï¼Œä»¥è‡ªç»™è‡ªè¶³çš„é¡¹é›†çš„å½¢å¼ï¼Œä½¿ç”¨æ æ†æˆ–æå‡ã€‚\nAssociation Rules : Package arules provides both data structures for efficient handling of sparse binary data as well as interfaces to implementations of Apriori and Eclat for mining frequent itemsets, maximal frequent itemsets, closed frequent itemsets and association rules. Package opusminer provides an interface to the OPUS Miner algorithm (implemented in C++) for finding the key associations in transaction data efficiently, in the form of self-sufficient itemsets, using either leverage or lift.\n\n\n\n4.2.11 æ¨¡ç³Šè§„åˆ™ç³»ç»Ÿçš„è½¯ä»¶åŒ…\n\næ¨¡ç³Šè§„åˆ™ç³»ç»Ÿï¼šfrbsåŒ…å®ç°äº†ä»æ•°æ®ä¸­å­¦ä¹ æ¨¡ç³Šè§„åˆ™ç³»ç»Ÿçš„æ ‡å‡†æ–¹æ³•ï¼Œç”¨äºå›å½’å’Œåˆ†ç±»ã€‚RoughSetsåŒ…åœ¨ä¸€ä¸ªåŒ…ä¸­æä¾›äº†ç²—ç³™é›†è®ºï¼ˆRSTï¼‰å’Œæ¨¡ç³Šç²—ç³™é›†è®ºï¼ˆFRSTï¼‰çš„å…¨é¢å®ç°ã€‚\nFuzzy Rule-based Systems : Package frbs implements a host of standard methods for learning fuzzy rule-based systems from data for regression and classification. Package RoughSets provides comprehensive implementations of the rough set theory (RST) and the fuzzy rough set theory (FRST) in a single package.\n\n\n\n4.2.12 æ¨¡å‹é€‰æ‹©å’ŒéªŒè¯çš„è½¯ä»¶åŒ…\n\næ¨¡å‹é€‰æ‹©å’ŒéªŒè¯ï¼še1071åŒ…æœ‰ç”¨äºè¶…å‚æ•°è°ƒä¼˜çš„tune()å‡½æ•°ï¼Œå¯ä»¥ä½¿ç”¨å‡½æ•°errorest()ï¼ˆæ¥è‡ªipredï¼‰è¿›è¡Œé”™è¯¯ç‡ä¼°è®¡ã€‚å¯ä»¥åˆ©ç”¨svmpathåŒ…çš„åŠŸèƒ½é€‰æ‹©æ”¯æŒå‘é‡æœºçš„æˆæœ¬å‚æ•°Cã€‚splitToolsåŒ…æä¾›äº†äº¤å‰éªŒè¯å’Œå…¶ä»–é‡é‡‡æ ·æ–¹æ¡ˆçš„æ•°æ®åˆ†å‰²ã€‚nestedcvåŒ…ä¸ºglmnetå’Œcaretæ¨¡å‹æä¾›äº†åµŒå¥—äº¤å‰éªŒè¯ã€‚ç”¨äºROCåˆ†æå’Œæ¯”è¾ƒå€™é€‰åˆ†ç±»å™¨çš„å…¶ä»–å¯è§†åŒ–æŠ€æœ¯çš„å‡½æ•°å¯ä»¥ä»ROCRåŒ…è·å–ã€‚hdi å’Œ stabsåŒ…å®ç°äº†ä¸€ç³»åˆ—æ¨¡å‹çš„ç¨³å®šæ€§é€‰æ‹©ï¼Œhdiè¿˜æä¾›äº†é«˜ç»´æ¨¡å‹ä¸­çš„å…¶ä»–æ¨ç†ç¨‹åºã€‚\nModel selection and validation : Package e1071 has function tune() for hyper parameter tuning and function errorest() (ipred) can be used for error rate estimation. The cost parameter C for support vector machines can be chosen utilizing the functionality of package svmpath. Data splitting for crossvalidation and other resampling schemes is available in the splitTools package. Package nestedcv provides nested cross-validation for glmnet and caret models. Functions for ROC analysis and other visualisation techniques for comparing candidate classifiers are available from package ROCR. Packages hdi and stabs implement stability selection for a range of models, hdialso offers other inference procedures in high-dimensional models.\n\n\n\n4.2.13 å› æœåˆ†æçš„è½¯ä»¶åŒ…\n\nå› æœæœºå™¨å­¦ä¹ ï¼šDoubleMLåŒ…æ˜¯åŒæœºå™¨å­¦ä¹ æ¡†æ¶åœ¨å„ç§å› æœæ¨¡å‹ä¸­çš„é¢å‘å¯¹è±¡å®ç°ã€‚åŸºäºmlr3ç”Ÿæ€ç³»ç»Ÿï¼Œå¯ä»¥åŸºäºå¹¿æ³›çš„æœºå™¨å­¦ä¹ æ–¹æ³•ä¼°è®¡å› æœæ•ˆåº”ã€‚\nCausal Machine Learning : The package DoubleML is an object-oriented implementation of the double machine learning framework in a variety of causal models. Building upon the mlr3 ecosystem, estimation of causal effects can be based on an extensive collection of machine learning methods.\n\n\n\n4.2.14 å…¶å®ƒç¨‹åº\n\nå…¶ä»–ç¨‹åºï¼šè¯æ®åˆ†ç±»å™¨åœ¨evclassåŒ…ä¸­ä½¿ç”¨Dempster-Shaferè´¨é‡å‡½æ•°é‡åŒ–å…³äºæµ‹è¯•æ¨¡å¼ç±»åˆ«çš„ä¸ç¡®å®šæ€§ã€‚OneRï¼ˆOne Ruleï¼‰åŒ…æä¾›äº†ä¸€ä¸ªåˆ†ç±»ç®—æ³•ï¼Œå¢å¼ºäº†å¯¹ç¼ºå¤±å€¼å’Œæ•°å­—æ•°æ®çš„ç²¾ç»†å¤„ç†ï¼Œä»¥åŠå¹¿æ³›çš„è¯Šæ–­åŠŸèƒ½ã€‚\nOther procedures : Evidential classifiers quantify the uncertainty about the class of a test pattern using a Dempster-Shafer mass function in package evclass. The OneR (One Rule) package offers a classification algorithm with enhancements for sophisticated handling of missing values and numeric data together with extensive diagnostic functions.\n\n\n\n4.2.15 ç”¨äºæœºå™¨å­¦ä¹ çš„å®åŒ…\n\nå®åŒ…ï¼štidymodelsåŒ…æä¾›äº†æ„å»ºé¢„æµ‹æ¨¡å‹çš„æ‚é¡¹å‡½æ•°ï¼ŒåŒ…æ‹¬å‚æ•°è°ƒä¼˜å’Œå˜é‡é‡è¦åº¦åº¦é‡ã€‚åŒæ ·ï¼Œmlr3åŒ…ä¸ºå„ç§ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ åŒ…æä¾›é«˜çº§æ¥å£ã€‚SuperLearnerå®ç°äº†ç±»ä¼¼çš„å·¥å…·ç®±ã€‚h2oåŒ…å®ç°äº†ä¸€ä¸ªé€šç”¨çš„æœºå™¨å­¦ä¹ å¹³å°ï¼Œå…¶ä¸­åŒ…å«äº†è®¸å¤šæµè¡Œç®—æ³•çš„å¯æ‰©å±•å®ç°ï¼Œå¦‚éšæœºæ£®æ—ã€GBMã€GLMï¼ˆå¸¦å¼¹æ€§ç½‘æ­£åˆ™åŒ–ï¼‰å’Œæ·±åº¦å­¦ä¹ ï¼ˆå‰é¦ˆå¤šå±‚ç½‘ç»œï¼‰ç­‰ç­‰ã€‚å¯ä»¥ä»mlpackåŒ…è·å–åˆ°mlpack C++åº“çš„æ¥å£ã€‚ CORElearnå®ç°äº†ä¸€ç±»ç›¸å½“å¹¿æ³›çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå¦‚æœ€è¿‘é‚»ï¼Œæ ‘ï¼Œéšæœºæ£®æ—ï¼Œä»¥åŠå‡ ç§ç‰¹å¾é€‰æ‹©æ–¹æ³•ã€‚ç±»ä¼¼åœ°ï¼ŒrmineråŒ…æ¥å£äº†åœ¨å…¶ä»–åŒ…ä¸­å®ç°çš„å‡ ç§å­¦ä¹ ç®—æ³•ï¼Œå¹¶è®¡ç®—äº†å‡ ç§æ€§èƒ½åº¦é‡ã€‚\nMeta packages : Package tidymodels provides miscellaneous functions for building predictive models, including parameter tuning and variable importance measures. In a similar spirit, package mlr3 offers high-level interfaces to various statistical and machine learning packages. Package SuperLearner implements a similar toolbox. The h2o package implements a general purpose machine learning platform that has scalable implementations of many popular algorithms such as random forest, GBM, GLM (with elastic net regularization), and deep learning (feedforward multilayer networks), among others. An interface to the mlpack C++ library is available from package mlpack. CORElearn implements a rather broad class of machine learning algorithms, such as nearest neighbors, trees, random forests, and several feature selection methods. Similar, package rminer interfaces several learning algorithms implemented in other packages and computes several performance measures.\n\n\n\n4.2.16 å¯è§†åŒ–çš„è½¯ä»¶åŒ…\n\nå¯è§†åŒ–ï¼ˆæœ€åˆç”±Brandon Greenwellè´¡çŒ®ï¼‰ï¼šstats::termplot()å‡½æ•°åŒ…å¯ä»¥ç”¨æ¥ç»˜åˆ¶é¢„æµ‹æ–¹æ³•æ”¯æŒ type=\"terms\"çš„æ¨¡å‹ä¸­çš„é¡¹ã€‚effectsåŒ…ä¸ºå¸¦æœ‰çº¿æ€§é¢„æµ‹å™¨çš„æ¨¡å‹ï¼ˆå¦‚ï¼Œçº¿æ€§å’Œå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼‰æä¾›äº†å›¾å½¢å’Œè¡¨æ ¼æ•ˆæœæ˜¾ç¤ºã€‚å¼—é‡Œå¾·æ›¼çš„éƒ¨åˆ†ä¾èµ–å›¾ï¼ˆPDPsï¼‰ï¼Œè¿™æ˜¯é¢„æµ‹å‡½æ•°çš„ä½ç»´åº¦å›¾å½¢æ¸²æŸ“ï¼Œå·²ç»åœ¨ä¸€äº›åŒ…ä¸­å®ç°ã€‚gbmï¼ŒrandomForest å’Œ randomForestSRC æä¾›äº†ä»–ä»¬è‡ªå·±çš„å‡½æ•°æ¥æ˜¾ç¤ºPDPsï¼Œä½†ä»…é™äºä½¿ç”¨é‚£äº›åŒ…æ‹Ÿåˆçš„æ¨¡å‹ï¼ˆæ¥è‡ªrandomForest çš„ partialPlot å‡½æ•°æ›´å—é™ï¼Œå› ä¸ºå®ƒä¸€æ¬¡åªå…è®¸ä¸€ä¸ªé¢„æµ‹å™¨ï¼‰ã€‚pdpï¼Œplotmoï¼Œå’Œ ICEbox åŒ…æ›´ä¸ºé€šç”¨ï¼Œå¹¶å…è®¸åˆ›å»ºå„ç§æœºå™¨å­¦ä¹ æ¨¡å‹çš„PDPsï¼ˆä¾‹å¦‚ï¼Œéšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºç­‰ï¼‰ï¼›pdp å’Œ plotmo éƒ½æ”¯æŒå¤šå˜é‡æ˜¾ç¤ºï¼ˆplotmo é™äºä¸¤ä¸ªé¢„æµ‹å™¨ï¼Œè€Œ pdp ä½¿ç”¨trelliså›¾å½¢æ¥æ˜¾ç¤ºæ¶‰åŠä¸‰ä¸ªé¢„æµ‹å™¨çš„PDPsï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œplotmo å°†èƒŒæ™¯å˜é‡å›ºå®šåœ¨ä»–ä»¬çš„ä¸­ä½æ•°ï¼ˆæˆ–å› ç´ çš„ç¬¬ä¸€çº§ï¼‰ï¼Œè¿™æ¯”æ„é€ PDPsæ›´å¿«ï¼Œä½†åŒ…å«çš„ä¿¡æ¯è¾ƒå°‘ã€‚ ICEboxå…³æ³¨äºæ„å»ºä¸ªä½“æ¡ä»¶æœŸæœ›ï¼ˆICEï¼‰æ›²çº¿ï¼Œè¿™æ˜¯å¯¹Friedmanâ€™s PDPsçš„æ”¹è¿›ã€‚ ICE curvesä»¥åŠå±…ä¸­çš„ ICE curvesä¹Ÿå¯ä»¥ç”¨pdp åŒ…çš„ partial() å‡½æ•°æ„å»ºã€‚\nVisualisation (initially contributed by Brandon Greenwell) The stats::termplot() function package can be used to plot the terms in a model whose predict method supports type=\"terms\". The effects package provides graphical and tabular effect displays for models with a linear predictor (e.g., linear and generalized linear models). Friedmanâ€™s partial dependence plots (PDPs), that are low dimensional graphical renderings of the prediction function, are implemented in a few packages. gbm, randomForest and randomForestSRC provide their own functions for displaying PDPs, but are limited to the models fit with those packages (the function partialPlot from randomForest is more limited since it only allows for one predictor at a time). Packages pdp, plotmo, and ICEbox are more general and allow for the creation of PDPs for a wide variety of machine learning models (e.g., random forests, support vector machines, etc.); both pdp and plotmo support multivariate displays (plotmo is limited to two predictors while pdp uses trellis graphics to display PDPs involving three predictors). By default, plotmo fixes the background variables at their medians (or first level for factors) which is faster than constructing PDPs but incorporates less information. ICEbox focuses on constructing individual conditional expectation (ICE) curves, a refinement over Friedmanâ€™s PDPs. ICE curves, as well as centered ICE curves can also be constructed with the partial() function from the pdp package.\n\n\n\n4.2.17 å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„è½¯ä»¶åŒ…\n\nXAIï¼š å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰é¢†åŸŸçš„å¤§å¤šæ•°è½¯ä»¶åŒ…å’Œå‡½æ•°éƒ½å±äºæœ€åä¸€èŠ‚â€œå¯è§†åŒ–â€ã€‚å…ƒåŒ… DALEX å’Œ iml æä¾›äº†è§£é‡Šä»»ä½•æ¨¡å‹çš„ä¸åŒæ–¹æ³•ï¼ŒåŒ…æ‹¬éƒ¨åˆ†ä¾èµ–æ€§ã€ç´¯ç§¯å±€éƒ¨æ•ˆåº”å’Œæ’åˆ—é‡è¦æ€§ã€‚ ç´¯ç§¯å±€éƒ¨æ•ˆåº”å›¾ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ ALEPlotä¸­è·å–ã€‚ SHAPï¼ˆæ¥è‡ª SHapley Additive exPlanationsï¼‰æ˜¯è§£é‡ŠMLæ¨¡å‹æœ€å¸¸ç”¨çš„æŠ€æœ¯ä¹‹ä¸€ã€‚ å®ƒä»¥å…¬å¹³çš„æ–¹å¼å°†é¢„æµ‹åˆ†è§£ä¸ºé¢„æµ‹å™¨çš„åŠ æ€§è´¡çŒ®ã€‚ å¯¹äºåŸºäºæ ‘çš„æ¨¡å‹ï¼Œå­˜åœ¨éå¸¸å¿«çš„TreeSHAPç®—æ³•ã€‚ å®ƒç›´æ¥ä¸ h2oï¼Œxgboostï¼Œå’Œ lightgbm ä¸€èµ·æä¾›ã€‚ åœ¨é¢å¤–çš„åŒ…ä¸­æä¾›äº†SHAPçš„æ¨¡å‹ä¸å¯çŸ¥å®ç°ï¼šfastshap ä¸»è¦ä½¿ç”¨è’™ç‰¹å¡æ´›é‡‡æ ·æ¥è¿‘ä¼¼SHAPå€¼ï¼Œè€Œ shapr å’Œ kernelshap æä¾›äº†KernelSHAPçš„å®ç°ã€‚ è¿™äº›åŒ…çš„SHAPå€¼å¯ä»¥ç”±shapvizåŒ…ç»˜åˆ¶ã€‚Pythonçš„â€œshapâ€åŒ…çš„ç«¯å£åœ¨ shapperä¸­æä¾›ã€‚ é¢„æµ‹çš„æ›¿ä»£åˆ†è§£åœ¨ lime å’Œ iBreakDown ä¸­å®ç°ã€‚\nXAI : Most packages and functions from the last section â€œVisualizationâ€ belong to the field of explainable artificial intelligence (XAI). The meta packages DALEX and iml offer different methods to interpret any model, including partial dependence, accumulated local effects, and permutation importance. Accumulated local effects plots are also directly available in ALEPlot. SHAP (from SHapley Additive exPlanations) is one of the most frequently used techniques to interpret ML models. It decomposes - in a fair way - predictions into additive contributions of the predictors. For tree-based models, the very fast TreeSHAP algorithm exists. It is shipped directly with h2o, xgboost, and lightgbm. Model-agnostic implementations of SHAP are available in additional packages: fastshap mainly uses Monte-Carlo sampling to approximate SHAP values, while shapr and kernelshap provide implementations of KernelSHAP. SHAP values of any of these packages can be plotted by the package shapviz. A port to Pythonâ€™s â€œshapâ€ package is provided in shapper. Alternative decompositions of predictions are implemented in lime and iBreakDown."
  },
  {
    "objectID": "14.tidymodels-list.html#ä¸€äº›æ–°çš„æœºå™¨å­¦ä¹ é¢†åŸŸæ¦‚å¿µ",
    "href": "14.tidymodels-list.html#ä¸€äº›æ–°çš„æœºå™¨å­¦ä¹ é¢†åŸŸæ¦‚å¿µ",
    "title": "4Â  å¸¸è§æ¨¡å‹å’Œè½¯ä»¶åŒ…",
    "section": "4.3 ä¸€äº›æ–°çš„æœºå™¨å­¦ä¹ é¢†åŸŸæ¦‚å¿µ",
    "text": "4.3 ä¸€äº›æ–°çš„æœºå™¨å­¦ä¹ é¢†åŸŸæ¦‚å¿µ\n\né€’å½’åˆ’åˆ†ï¼šè¿™æ˜¯ä¸€ç§æ„å»ºå†³ç­–æ ‘çš„æ–¹æ³•ï¼Œå®ƒåå¤å°†æ•°æ®é›†åˆ’åˆ†ä¸ºä¸¤ä¸ªæˆ–æ›´å¤šçš„å­é›†ï¼Œè¿™ä¸ªè¿‡ç¨‹ç›´åˆ°æ»¡è¶³æŸç§åœæ­¢æ¡ä»¶ï¼ˆæ¯”å¦‚ï¼Œè¾¾åˆ°é¢„è®¾çš„æœ€å¤§æ·±åº¦ï¼‰æ‰ä¼šåœæ­¢ã€‚æ¯æ¬¡åˆ’åˆ†éƒ½æ˜¯åŸºäºç‰¹å®šç‰¹å¾çš„å€¼ã€‚\næ­£åˆ™åŒ–ï¼šæ­£åˆ™åŒ–æ˜¯ä¸€ç§ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆçš„æŠ€æœ¯ã€‚é€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œå¯ä»¥å‡å°æ¨¡å‹å¤æ‚åº¦å¹¶å¢å¼ºå…¶æ³›åŒ–èƒ½åŠ›ã€‚\nBoostingï¼šBoosting æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æŠ€æœ¯ï¼Œå®ƒç»“åˆäº†å¤šä¸ªâ€œå¼±â€åˆ†ç±»å™¨ä»¥åˆ›å»ºä¸€ä¸ªâ€œå¼ºâ€åˆ†ç±»å™¨ã€‚Boosting çš„å·¥ä½œæ–¹å¼æ˜¯ï¼Œåœ¨æ¯ä¸ªè®­ç»ƒé˜¶æ®µï¼Œéƒ½å¯¹é¢„æµ‹é”™è¯¯çš„æ ·æœ¬è¿›è¡ŒåŠ æƒï¼Œä½¿å¾—åç»­çš„åˆ†ç±»å™¨æ›´å…³æ³¨é‚£äº›è¢«è¯¯åˆ†ç±»çš„æ ·æœ¬ã€‚\næ¢¯åº¦ä¸‹é™ï¼šæ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºå¯»æ‰¾ç›®æ ‡å‡½æ•°ï¼ˆå¦‚æŸå¤±å‡½æ•°æˆ–æˆæœ¬å‡½æ•°ï¼‰çš„æœ€å°å€¼ã€‚å®ƒé€šè¿‡è®¡ç®—å½“å‰ç‚¹çš„è´Ÿæ¢¯åº¦æ¥è¿­ä»£åœ°æ›´æ–°å‚æ•°å€¼ï¼Œå¹¶å‘ç€å‡½æ•°å€¼ä¸‹é™æœ€å¿«çš„æ–¹å‘ç§»åŠ¨ã€‚\næ”¯æŒå‘é‡æœºï¼šæ”¯æŒå‘é‡æœº (SVM) æ˜¯ä¸€ç§åˆ†ç±»å’Œå›å½’æ–¹æ³•ã€‚åœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼ŒSVM è¯•å›¾æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢ï¼Œèƒ½å¤Ÿæœ€å¤§åŒ–ä¸¤ä¸ªç±»åˆ«ä¹‹é—´çš„è¾¹ç•Œã€‚\næ ¸æ–¹æ³•ï¼šæ ¸æ–¹æ³•æ˜¯ä¸€ç§åœ¨æ›´é«˜ç»´çš„ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œè®¡ç®—çš„æŠ€å·§ï¼Œè€Œæ— éœ€æ˜¾å¼åœ°è®¡ç®—æ•°æ®ç‚¹åœ¨è¿™ä¸ªç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚å®ƒå¸¸ç”¨äºæ”¯æŒå‘é‡æœºç­‰ç®—æ³•ã€‚\nè´å¶æ–¯æ–¹æ³•ï¼šè´å¶æ–¯æ–¹æ³•åŸºäºè´å¶æ–¯å®šç†ï¼Œå°†å…ˆéªŒçŸ¥è¯†ä¸è§‚å¯Ÿåˆ°çš„æ•°æ®ç»“åˆèµ·æ¥ï¼Œå¾—å‡ºå¯¹æœªçŸ¥å‚æ•°çš„åéªŒæ¦‚ç‡åˆ†å¸ƒã€‚\né—ä¼ ç®—æ³•ï¼šé—ä¼ ç®—æ³•æ˜¯ä¸€ç§æ¨¡æ‹Ÿè‡ªç„¶é€‰æ‹©è¿‡ç¨‹çš„æœç´¢ä¼˜åŒ–ç®—æ³•ã€‚å®ƒé€šè¿‡åœ¨æ¯ä¸€ä»£ä¸­é‡å¤é€‰æ‹©ã€äº¤å‰å’Œå˜å¼‚æ“ä½œï¼Œä»è€Œåœ¨è§£ç©ºé—´ä¸­æœç´¢æœ€ä¼˜è§£ã€‚\næ¨¡ç³Šè§„åˆ™ï¼šæ¨¡ç³Šè§„åˆ™ç³»ç»Ÿæ˜¯ä¸€ç§åŸºäºæ¨¡ç³Šé€»è¾‘çš„ç³»ç»Ÿï¼Œç”¨äºå¤„ç†æ¨¡ç³Šæˆ–ä¸ç¡®å®šçš„ä¿¡æ¯ã€‚å®ƒç”±ä¸€ç»„å¦‚æœ-é‚£ä¹ˆçš„æ¨¡ç³Šè§„åˆ™ç»„æˆï¼Œå¹¶ä¸”å¯ä»¥å¤„ç†è¿ç»­å€¼è¾“å…¥å’Œè¾“å‡ºã€‚\nå› æœåˆ†æï¼šå› æœåˆ†ææ˜¯ä¸€ç§ç ”ç©¶å› æœå…³ç³»çš„æ–¹æ³•ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå®ƒæ¶‰åŠä½¿ç”¨å¼ºå¤§çš„ç»Ÿè®¡å·¥å…·ï¼ˆå¦‚ Granger å› æœæ€§æµ‹è¯•ï¼‰æ¥è¯†åˆ«å› æœå…³ç³»ï¼Œæˆ–ä½¿ç”¨å»ºç«‹åœ¨æ½œåœ¨å› æœå…³ç³»æ¨¡å‹åŸºç¡€ä¸Šçš„ç®—æ³•ï¼ˆæ¯”å¦‚ Pearlâ€™s do-calculusï¼‰æ¥è¿›è¡Œé¢„æµ‹ã€‚\nXAIï¼ˆå¯è§£é‡Šçš„äººå·¥æ™ºèƒ½ï¼‰ï¼šè¿™æ˜¯ä¸€ä¸ªç ”ç©¶é¢†åŸŸï¼Œæ—¨åœ¨è®©äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å†³ç­–è¿‡ç¨‹å˜å¾—å¯ä»¥ç†è§£å’Œè§£é‡Šã€‚å°½ç®¡è®¸å¤šç°ä»£AIæ¨¡å‹ï¼ˆå¦‚æ·±åº¦å­¦ä¹ ï¼‰åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å¾€å¾€è¢«è§†ä¸ºâ€œé»‘ç®±â€ï¼Œå› ä¸ºæˆ‘ä»¬å¾ˆéš¾ç†è§£å®ƒä»¬æ˜¯å¦‚ä½•åšå‡ºå…·ä½“å†³ç­–çš„ã€‚XAIçš„ç›®æ ‡æ˜¯æ­ç¤ºæ¨¡å‹å†…éƒ¨çš„å¤æ‚æœºåˆ¶ï¼Œå¹¶æä¾›æœ‰å…³æ¨¡å‹å†³ç­–çš„é€æ˜ã€å¯ç†è§£ä¸”å¯ä¿¡èµ–çš„è§£é‡Šã€‚è¿™ä¸ä»…æœ‰åŠ©äºæé«˜ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œä¹Ÿæœ‰åŠ©äºå¼€å‘è€…æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„è¡Œä¸ºï¼Œä»è€Œè¿›è¡Œè°ƒè¯•å’Œæ”¹è¿›ã€‚å®ç°XAIçš„æ–¹æ³•åŒ…æ‹¬ç‰¹å¾é‡è¦æ€§åˆ†æã€æ¨¡å‹å¯è§†åŒ–ã€å¯¹æŠ—æ€§ä¾‹è¯ç”Ÿæˆã€å±€éƒ¨å¯è§£é‡Šæ€§æ¨¡å‹ï¼ˆå¦‚LIMEï¼‰ç­‰ã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#é…ç½®é»˜è®¤ç¯å¢ƒ",
    "href": "15.tidymodels-recipes.html#é…ç½®é»˜è®¤ç¯å¢ƒ",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.1 é…ç½®é»˜è®¤ç¯å¢ƒ",
    "text": "5.1 é…ç½®é»˜è®¤ç¯å¢ƒ\n\n# è®¾ç½® knitr é€‰é¡¹\nknitr::opts_chunk$set(\n    collapse = TRUE,\n    comment = \"#&gt;\",\n    message = FALSE,\n    warning = FALSE\n)\n\n# æ˜¾ç¤ºè‹±æ–‡æŠ¥é”™ä¿¡æ¯\nSys.setenv(LANG = \"en\")\n\n# ä½¿ç”¨ rmodels ç¯å¢ƒ\nreticulate::use_condaenv(\"rmodels\",\n    conda = \"/opt/homebrew/anaconda3/bin/conda\"\n)\n\n# å¯¼å…¥ tidyverse åŒ…\nlibrary(\"tidyverse\")\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.4.4     âœ” tibble    3.2.1\nâœ” lubridate 1.9.3     âœ” tidyr     1.3.0\nâœ” purrr     1.0.2     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# å¯¼å…¥ cailab.utils åŒ…\nif (Sys.getenv(\"USER\") == \"gaoch\") {\n    devtools::load_all(\"~/GitHub/cailab.utils\")\n} else {\n    library(\"cailab.utils\")\n}\n\nâ„¹ Loading cailab.utils\nRegistered S3 methods overwritten by 'treeio':\n  method              from    \n  MRCA.phylo          tidytree\n  MRCA.treedata       tidytree\n  Nnode.treedata      tidytree\n  Ntip.treedata       tidytree\n  ancestor.phylo      tidytree\n  ancestor.treedata   tidytree\n  child.phylo         tidytree\n  child.treedata      tidytree\n  full_join.phylo     tidytree\n  full_join.treedata  tidytree\n  groupClade.phylo    tidytree\n  groupClade.treedata tidytree\n  groupOTU.phylo      tidytree\n  groupOTU.treedata   tidytree\n  inner_join.phylo    tidytree\n  inner_join.treedata tidytree\n  is.rooted.treedata  tidytree\n  nodeid.phylo        tidytree\n  nodeid.treedata     tidytree\n  nodelab.phylo       tidytree\n  nodelab.treedata    tidytree\n  offspring.phylo     tidytree\n  offspring.treedata  tidytree\n  parent.phylo        tidytree\n  parent.treedata     tidytree\n  root.treedata       tidytree\n  rootnode.phylo      tidytree\n  sibling.phylo       tidytree\n\n# å¯¼å…¥ tidymodels åŒ…\nlibrary(tidymodels)\n\nRegistered S3 method overwritten by 'parsnip':\n  method          from \n  print.nullmodel vegan\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\nâœ” broom        1.0.5     âœ” rsample      1.2.0\nâœ” dials        1.2.0     âœ” tune         1.1.2\nâœ” infer        1.0.5     âœ” workflows    1.1.3\nâœ” modeldata    1.2.0     âœ” workflowsets 1.0.1\nâœ” parsnip      1.1.1     âœ” yardstick    1.2.0\nâœ” recipes      1.0.9     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– scales::discard() masks purrr::discard()\nâœ– dplyr::filter()   masks stats::filter()\nâœ– recipes::fixed()  masks stringr::fixed()\nâœ– dplyr::lag()      masks stats::lag()\nâœ– yardstick::spec() masks readr::spec()\nâœ– recipes::step()   masks stats::step()\nâ€¢ Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n# è®¾ç½® ggplot é»˜è®¤ä¸»é¢˜\ntheme_set(theme_bw())"
  },
  {
    "objectID": "15.tidymodels-recipes.html#ä»€ä¹ˆæ˜¯ç‰¹å¾å·¥ç¨‹",
    "href": "15.tidymodels-recipes.html#ä»€ä¹ˆæ˜¯ç‰¹å¾å·¥ç¨‹",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.2 ä»€ä¹ˆæ˜¯ç‰¹å¾å·¥ç¨‹",
    "text": "5.2 ä»€ä¹ˆæ˜¯ç‰¹å¾å·¥ç¨‹\nç‰¹å¾å·¥ç¨‹æ˜¯ä¸€ç§æ•°æ®é¢„å¤„ç†çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥å¸®åŠ©æœºå™¨å­¦ä¹ æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹æ•°æ®ã€‚ç‰¹å¾å·¥ç¨‹çš„ä¸»è¦æ­¥éª¤æœ‰ï¼š\n\nç‰¹å¾ç†è§£ï¼šåˆ†ææ•°æ®çš„æ¥æºã€ç±»å‹ã€åˆ†å¸ƒã€ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ç­‰ï¼Œäº†è§£æ•°æ®çš„ç‰¹ç‚¹å’Œå«ä¹‰ã€‚\nç‰¹å¾é€‰æ‹©ï¼šæ ¹æ®æ•°æ®çš„ç›¸å…³æ€§ã€é‡è¦æ€§ã€å†—ä½™æ€§ç­‰ï¼Œé€‰æ‹©å¯¹æ¨¡å‹æœ‰ç”¨çš„ç‰¹å¾ï¼Œå‡å°‘ç‰¹å¾çš„ç»´åº¦å’Œå™ªå£°ã€‚\nç‰¹å¾æå–ï¼šåˆ©ç”¨æ•°å­¦æˆ–ç»Ÿè®¡æ–¹æ³•ï¼Œä»åŸå§‹æ•°æ®ä¸­æå–å‡ºæ–°çš„ç‰¹å¾ï¼Œä¾‹å¦‚ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã€çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ã€å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ç­‰ã€‚\nç‰¹å¾æ„é€ ï¼šåˆ©ç”¨æ•°æ®é¢†åŸŸçš„çŸ¥è¯†ï¼Œåˆ›é€ å‡ºæ–°çš„ç‰¹å¾ï¼Œä¾‹å¦‚ç»„åˆã€åˆ†è§£ã€å˜æ¢ã€ç¼–ç ç­‰ã€‚\nç‰¹å¾è½¬æ¢ï¼šå°†ç‰¹å¾è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹çš„æ ¼å¼ï¼Œä¾‹å¦‚æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ã€ç¦»æ•£åŒ–ã€ç‹¬çƒ­ç¼–ç ç­‰ã€‚\n\nç‰¹å¾å·¥ç¨‹æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€é—¨è‰ºæœ¯ï¼Œå®ƒéœ€è¦ä¸æ–­åœ°å°è¯•å’Œä¼˜åŒ–ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€åˆé€‚çš„ç‰¹å¾ç»„åˆã€‚ç‰¹å¾å·¥ç¨‹çš„å¥½åï¼Œå¾€å¾€å†³å®šäº†æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆæœã€‚\nåœ¨ tidymodels ä¸­ï¼Œä½¿ç”¨ recipes è½¯ä»¶åŒ…è¿›è¡Œç‰¹å¾å·¥ç¨‹ï¼Œå®ƒå¯ä»¥è®©æ‚¨ç”¨ç±»ä¼¼dplyrçš„ç®¡é“è¯­æ³•æ¥åˆ›å»ºå’Œé¢„å¤„ç†æœºå™¨å­¦ä¹ çš„ç‰¹å¾ã€‚recipesè½¯ä»¶åŒ…çš„ä¸»è¦ä¼˜ç‚¹æœ‰ï¼š\n\nå®ƒå¯ä»¥å¤„ç†å„ç§æ•°æ®ç±»å‹ï¼ŒåŒ…æ‹¬æ•°å€¼ã€åˆ†ç±»ã€æ–‡æœ¬ã€å›¾åƒç­‰ã€‚\nå®ƒå¯ä»¥æ–¹ä¾¿åœ°æ·»åŠ ã€åˆ é™¤ã€ä¿®æ”¹å’Œç»„åˆç‰¹å¾å·¥ç¨‹çš„æ­¥éª¤ï¼Œä»¥åŠè°ƒæ•´å‚æ•°å’Œé€‰é¡¹ã€‚\nå®ƒå¯ä»¥è‡ªåŠ¨ä¼°è®¡ç‰¹å¾å·¥ç¨‹çš„ç»Ÿè®¡å‚æ•°ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°æ–°çš„æ•°æ®é›†ä¸Šï¼Œä¿è¯æ•°æ®çš„ä¸€è‡´æ€§ã€‚\nå®ƒå¯ä»¥ä¸å…¶ä»–tidymodelsåŒ…ï¼Œå¦‚rsampleã€parsnipã€tuneç­‰æ— ç¼åœ°é›†æˆï¼Œæ„å»ºå®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹ã€‚\n\nå¦‚æœæ‚¨æƒ³å­¦ä¹ å¦‚ä½•ä½¿ç”¨ recipes è½¯ä»¶åŒ…ï¼Œæ‚¨å¯ä»¥å‚è€ƒä»¥ä¸‹çš„èµ„æºï¼š\n\nrecipeså®˜æ–¹ç½‘ç«™ï¼šè¿™é‡Œæœ‰recipesè½¯ä»¶åŒ…çš„è¯¦ç»†æ–‡æ¡£ã€æ•™ç¨‹å’Œç¤ºä¾‹ï¼Œä»¥åŠå¸¸è§é—®é¢˜çš„è§£ç­”ã€‚\nFeature Engineering and Selectionï¼šè¿™æ˜¯ä¸€æœ¬åœ¨çº¿ä¹¦ç±ï¼Œä»‹ç»äº†ç‰¹å¾å·¥ç¨‹çš„ç†è®ºå’Œåº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨recipesè½¯ä»¶åŒ…çš„ç¤ºä¾‹ã€‚\nR Recipes: A Problem-Solution Approachï¼šè¿™æ˜¯ä¸€æœ¬å®ç”¨çš„ä¹¦ç±ï¼Œæä¾›äº†ä½¿ç”¨Rè¯­è¨€è¿›è¡Œæ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„å„ç§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­ä¹Ÿæ¶‰åŠäº†recipesè½¯ä»¶åŒ…çš„ç”¨æ³•ã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#recipes-ä¸­çš„æ¦‚å¿µ",
    "href": "15.tidymodels-recipes.html#recipes-ä¸­çš„æ¦‚å¿µ",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.3 recipes ä¸­çš„æ¦‚å¿µ",
    "text": "5.3 recipes ä¸­çš„æ¦‚å¿µ\næ¥æºï¼šhttps://recipes.tidymodels.org/articles/recipes.html\né¦–å…ˆè¯´æ˜å‡ ä¸ªå®šä¹‰å¦‚ä¸‹ï¼š\n\nå˜é‡ï¼ˆVariablesï¼‰ï¼šåŸå§‹æ•°æ®é›†ä¸­çš„åˆ—ï¼Œä¾‹å¦‚åœ¨ä¼ ç»Ÿå…¬å¼ Y ~ A + B + A:B ä¸­ï¼Œå˜é‡åŒ…æ‹¬ Aã€B å’Œ Yã€‚\nè§’è‰²ï¼ˆRolesï¼‰ï¼šå®šä¹‰å˜é‡åœ¨æ¨¡å‹ä¸­å¦‚ä½•ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼špredictorï¼ˆè‡ªå˜é‡ï¼‰ã€responseï¼ˆå› å˜é‡ï¼‰å’Œ case weightã€‚è¿™æ„å‘³ç€è§’è‰²çš„è®¾å®šæ˜¯å¼€æ”¾ä¸”å¯æ‰©å±•çš„ã€‚\né¡¹ï¼ˆTermsï¼‰ï¼šè®¾è®¡çŸ©é˜µä¸­çš„åˆ—ï¼Œå¦‚ Aã€B å’Œ A:Bã€‚è¿™äº›ä¹Ÿå¯ä»¥æ˜¯å…¶ä»–æ´¾ç”Ÿå®ä½“ï¼Œä¾‹å¦‚ä¸€ç»„ä¸»æˆåˆ†æˆ–ä¸€ç»„å®šä¹‰å˜é‡åŸºå‡½æ•°çš„åˆ—ã€‚è¿™äº›ä¸æœºå™¨å­¦ä¹ ä¸­çš„ç‰¹å¾æ˜¯åŒä¹‰è¯ã€‚è¢«èµ‹äºˆ predictor è§’è‰²çš„å˜é‡å°†è‡ªåŠ¨æˆä¸ºä¸»æ•ˆåº”é¡¹ã€‚\n\næ€»çš„æ¥è¯´ï¼Œåœ¨ recipes åŒ…ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡åˆ†é…â€œè§’è‰²â€æ¥æŒ‡å®šæ¯ä¸ªå˜é‡çš„ç”¨é€”ï¼Œå¹¶åˆ›å»ºâ€œé¡¹â€ä»¥æŒ‡å®šæ¨¡å‹ä¸­çš„ç‰¹å¾ã€‚è¿™ç§æ–¹å¼æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œä½¿å¾—æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹å˜å¾—æ›´åŠ ç®€å•å’Œç›´è§‚ã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#æœ€å°å®ä¾‹",
    "href": "15.tidymodels-recipes.html#æœ€å°å®ä¾‹",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.4 æœ€å°å®ä¾‹",
    "text": "5.4 æœ€å°å®ä¾‹\nè¿™æ®µä»£ç é¦–å…ˆä» â€œmodeldataâ€ åŒ…ä¸­åŠ è½½äº†ä¸€ä¸ªåä¸º â€œamesâ€ çš„æ•°æ®é›†ï¼Œç„¶åå¯¹ â€œSale_Priceâ€ åˆ—ï¼ˆæˆ¿ä»·ï¼‰è¿›è¡Œäº†å¯¹æ•°è½¬æ¢ã€‚æ¥ç€ï¼Œå®ƒå®šä¹‰äº†ä¸€ä¸ªé¢„å¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬ä¸€äº›ç‰¹å¾å·¥ç¨‹æ­¥éª¤ï¼Œè¿™ä¸ªæµç¨‹å°†ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚\n\n\n\n\n\n\nNote\n\n\n\nå…³äº ames æ•°æ®é›†\nAmes Housing æ•°æ®é›†æ¥æºäºç¾å›½çˆ±è·åå· Ames å¸‚çš„ä½å®…é”€å”®ä¿¡æ¯ï¼Œç”± Dean De Cock æ•™æˆæ”¶é›†è€Œæˆï¼Œç”¨äºæ•™å­¦ç›®çš„ï¼Œç‰¹åˆ«æ˜¯æ•°æ®æ¸…æ´—å’Œé«˜çº§å›å½’æŠ€æœ¯ã€‚\nè¿™ä¸ªæ•°æ®é›†åŒ…å«äº† 2006 å¹´åˆ° 2010 å¹´é—´ Ames å¸‚è¿‘ 3000 æ‰€æˆ¿å±‹çš„ 79 ç§ç‰¹å¾ï¼Œå¦‚æˆ¿å±‹ç±»å‹ã€å»ºé€ å¹´ä»½ã€æˆ¿é—´æ•°é‡ã€åœ°ä¸‹å®¤æƒ…å†µã€è½¦åº“å¤§å°ã€å»ºç­‘ææ–™ç­‰ï¼Œä»¥åŠæ¯ä¸ªæˆ¿å±‹çš„æœ€ç»ˆé”€å”®ä»·æ ¼ã€‚\nåœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€å¤„æˆ¿äº§ï¼Œæ¯ä¸€åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹æ€§ï¼Œå…¶ä¸­ Sale_Price åˆ—æ˜¯æˆ‘ä»¬é€šå¸¸è¦é¢„æµ‹çš„ç›®æ ‡å˜é‡ã€‚è¿™ä¸ªæ•°æ®é›†é€šå¸¸è¢«ç”¨æ¥è¿›è¡Œå›å½’åˆ†ææˆ–æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚é¢„æµ‹æœªæ¥çš„æˆ¿ä»·ã€‚\nå› ä¸ºè¿™ä¸ªæ•°æ®é›†æœ‰è®¸å¤šç‰¹å¾ï¼Œå¹¶ä¸”æ¶‰åŠåˆ°å„ç§ä¸åŒç±»å‹çš„å˜é‡ï¼ˆå¦‚ç±»åˆ«å˜é‡ã€é¡ºåºå˜é‡å’Œæ•°å€¼å˜é‡ï¼‰ï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªéå¸¸å¥½çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨æ¥ç»ƒä¹ å’Œå±•ç¤ºæ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹è°ƒä¼˜ç­‰æŠ€å·§ã€‚\n\n\n\ndata(ames, package = \"modeldata\")\n\names &lt;- mutate(ames, Sale_Price = log10(Sale_Price))\n\names_rec &lt;-\n  recipe(Sale_Price ~ ., data = ames[-(1:6), ]) %&gt;%\n  step_other(Neighborhood, threshold = 0.05) %&gt;%\n  step_dummy(all_nominal()) %&gt;%\n  step_interact(~ starts_with(\"Central_Air\"):Year_Built) %&gt;%\n  step_ns(Longitude, Latitude, deg_free = 2) %&gt;%\n  step_zv(all_predictors())\n\names_rec = prep(ames_rec)\n\n# return the training set (already embedded in ames_rec)\nbake(ames_rec, new_data = NULL)\n#&gt; # A tibble: 2,924 Ã— 259\n#&gt;    Lot_Frontage Lot_Area Year_Built Year_Remod_Add Mas_Vnr_Area BsmtFin_SF_1\n#&gt;           &lt;dbl&gt;    &lt;int&gt;      &lt;int&gt;          &lt;int&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt;  1           41     4920       2001           2001            0            3\n#&gt;  2           43     5005       1992           1992            0            1\n#&gt;  3           39     5389       1995           1996            0            3\n#&gt;  4           60     7500       1999           1999            0            7\n#&gt;  5           75    10000       1993           1994            0            7\n#&gt;  6            0     7980       1992           2007            0            1\n#&gt;  7           63     8402       1998           1998            0            7\n#&gt;  8           85    10176       1990           1990            0            3\n#&gt;  9            0     6820       1985           1985            0            3\n#&gt; 10           47    53504       2003           2003          603            1\n#&gt; # â„¹ 2,914 more rows\n#&gt; # â„¹ 253 more variables: BsmtFin_SF_2 &lt;dbl&gt;, Bsmt_Unf_SF &lt;dbl&gt;,\n#&gt; #   Total_Bsmt_SF &lt;dbl&gt;, First_Flr_SF &lt;int&gt;, Second_Flr_SF &lt;int&gt;,\n#&gt; #   Gr_Liv_Area &lt;int&gt;, Bsmt_Full_Bath &lt;dbl&gt;, Bsmt_Half_Bath &lt;dbl&gt;,\n#&gt; #   Full_Bath &lt;int&gt;, Half_Bath &lt;int&gt;, Bedroom_AbvGr &lt;int&gt;, Kitchen_AbvGr &lt;int&gt;,\n#&gt; #   TotRms_AbvGrd &lt;int&gt;, Fireplaces &lt;int&gt;, Garage_Cars &lt;dbl&gt;,\n#&gt; #   Garage_Area &lt;dbl&gt;, Wood_Deck_SF &lt;int&gt;, Open_Porch_SF &lt;int&gt;, â€¦\n\n# apply processing to other data:\nbake(ames_rec, new_data = head(ames))\n#&gt; # A tibble: 6 Ã— 259\n#&gt;   Lot_Frontage Lot_Area Year_Built Year_Remod_Add Mas_Vnr_Area BsmtFin_SF_1\n#&gt;          &lt;dbl&gt;    &lt;int&gt;      &lt;int&gt;          &lt;int&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1          141    31770       1960           1960          112            2\n#&gt; 2           80    11622       1961           1961            0            6\n#&gt; 3           81    14267       1958           1958          108            1\n#&gt; 4           93    11160       1968           1968            0            1\n#&gt; 5           74    13830       1997           1998            0            3\n#&gt; 6           78     9978       1998           1998           20            3\n#&gt; # â„¹ 253 more variables: BsmtFin_SF_2 &lt;dbl&gt;, Bsmt_Unf_SF &lt;dbl&gt;,\n#&gt; #   Total_Bsmt_SF &lt;dbl&gt;, First_Flr_SF &lt;int&gt;, Second_Flr_SF &lt;int&gt;,\n#&gt; #   Gr_Liv_Area &lt;int&gt;, Bsmt_Full_Bath &lt;dbl&gt;, Bsmt_Half_Bath &lt;dbl&gt;,\n#&gt; #   Full_Bath &lt;int&gt;, Half_Bath &lt;int&gt;, Bedroom_AbvGr &lt;int&gt;, Kitchen_AbvGr &lt;int&gt;,\n#&gt; #   TotRms_AbvGrd &lt;int&gt;, Fireplaces &lt;int&gt;, Garage_Cars &lt;dbl&gt;,\n#&gt; #   Garage_Area &lt;dbl&gt;, Wood_Deck_SF &lt;int&gt;, Open_Porch_SF &lt;int&gt;,\n#&gt; #   Enclosed_Porch &lt;int&gt;, Three_season_porch &lt;int&gt;, Screen_Porch &lt;int&gt;, â€¦\n\nä»¥ä¸‹æ˜¯æ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†è§£é‡Šï¼š\n\nrecipe(Sale_Price ~ ., data = ames[-(1:6), ])ï¼šè¿™è¡Œåˆ›å»ºäº†ä¸€ä¸ª â€œrecipeâ€ å¯¹è±¡ï¼ŒæŒ‡å®šäº†å› å˜é‡ (Sale_Price) å’Œè‡ªå˜é‡ï¼ˆæ•°æ®æ¡†çš„æ‰€æœ‰å…¶ä»–åˆ—ï¼‰ã€‚ames[-(1:6), ] è¡¨ç¤ºå»æ‰äº†å‰ 6 è¡Œçš„æ•°æ®ã€‚\nstep_other(Neighborhood, threshold = 0.05)ï¼šè¯¥æ­¥éª¤å°† â€œNeighborhoodâ€ å˜é‡ä¸­é‚£äº›å°‘äº 5% çš„ç±»åˆ«åˆå¹¶ä¸ºä¸€ä¸ªæ–°çš„ç±»åˆ« â€œotherâ€ã€‚\nstep_dummy(all_nominal())ï¼šè¿™æ­¥åˆ›å»ºè™šæ‹Ÿï¼ˆå“‘ï¼‰å˜é‡ï¼Œå¯¹æ‰€æœ‰æ ‡ç§°å˜é‡æ‰§è¡Œç‹¬çƒ­ç¼–ç ã€‚\nstep_interact(~ starts_with(\"Central_Air\"):Year_Built)ï¼šè¿™æ­¥åˆ›å»ºäº¤äº’é¡¹ï¼Œå³ â€œCentral_Airâ€ ä¸ â€œYear_Builtâ€ çš„ä¹˜ç§¯ã€‚\nstep_ns(Longitude, Latitude, deg_free = 2)ï¼šè¯¥æ­¥æ‰§è¡Œè‡ªç„¶æ ·æ¡è½¬æ¢ï¼Œé€šå¸¸ç”¨äºå¤„ç†éçº¿æ€§å…³ç³»ã€‚\nstep_zv(all_predictors())ï¼šè¿™æ­¥ä¼šåˆ é™¤æ‰€æœ‰é›¶æ–¹å·®é¢„æµ‹å˜é‡ï¼Œå³é‚£äº›åœ¨æ‰€æœ‰è§‚å¯Ÿå€¼ä¸­éƒ½å…·æœ‰ç›¸åŒå€¼çš„åˆ—ã€‚\n\nprep(ames_rec) å‡½æ•°å¯¹è¿™ä¸ª recipe è¿›è¡Œé¢„å¤„ç†ï¼Œè®¡ç®—å‡ºéœ€è¦çš„ç»Ÿè®¡é‡ï¼ˆå¦‚å‡å€¼ã€æ ‡å‡†å·®ç­‰ï¼‰ã€‚ä¹‹åï¼Œå¯ä»¥ä½¿ç”¨ bake() å‡½æ•°æ¥åº”ç”¨è¿™ä¸ªé¢„å¤„ç†æµç¨‹åˆ°æ–°çš„æ•°æ®ä¸Šã€‚ä¾‹å¦‚ï¼Œbake(ames_rec, new_data = NULL) ä¼šå°†é¢„å¤„ç†æµç¨‹åº”ç”¨åˆ°è®­ç»ƒé›†ï¼ˆå³åˆ›å»º recipe æ—¶ç”¨çš„æ•°æ®ï¼‰ï¼Œè€Œ bake(ames_rec, new_data = head(ames)) åˆ™ä¼šå°†å…¶åº”ç”¨åˆ°æ•°æ®æ¡† â€œamesâ€ çš„å‰å‡ è¡Œã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•",
    "href": "15.tidymodels-recipes.html#ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.5 ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•",
    "text": "5.5 ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•\nrecipes è½¯ä»¶åŒ…ä¸­æœ‰ä¸¤å¤§ç±»å‡½æ•°ï¼Œä¸€ç±»æ˜¯ç”¨æ¥è¿›è¡Œå˜é‡é€‰æ‹©çš„å‡½æ•°ï¼Œä¸ tidyselect ä¸­çš„ç”¨æ³•å¤§æ¦‚ç›¸åŒï¼Œå¦ä¸€ç±»æ˜¯ç”¨æ¥è¿›è¡Œå˜é‡è½¬æ¢çš„å‡½æ•°ï¼Œé€šå¸¸ä»¥ step_* å¼€å¤´ã€‚\nSelectors\n\nuse basic variable names (e.g.Â x1, x2),\ndplyr functions for selecting variables: contains(), ends_with(), everything(), matches(), num_range(), and starts_with(),\nfunctions that subset on the role of the variables that have been specified so far: all_outcomes(), all_predictors(), has_role(),\nsimilar functions for the type of data: all_nominal(), all_numeric(), and has_type(), or compound selectors such as all_nominal_predictors() or all_numeric_predictors().\n\nStep\nrecipes åº“æä¾›äº†è®¸å¤š step_ å‡½æ•°ç”¨äºæ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¸»è¦çš„ç±»åˆ«ï¼š\n\nç¼©æ”¾ä¸ä¸­å¿ƒåŒ–ï¼šä¾‹å¦‚ step_center() å’Œ step_scale()ã€‚è¿™ä¸¤ä¸ªå‡½æ•°å¯ä»¥å°†æ•°å€¼å‹å˜é‡é‡æ–°ç¼©æ”¾åˆ°å‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ã€‚æ¯”å¦‚ï¼š\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_center(all_numeric()) %&gt;%\n  step_scale(all_numeric())\n\nç¦»æ•£åŒ–ï¼šä¾‹å¦‚ step_discretize()ã€‚è¿™ä¸ªå‡½æ•°å¯ä»¥å°†è¿ç»­å˜é‡åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªèŒƒå›´ï¼ˆå³â€œæ¡¶â€ï¼‰ï¼Œç„¶åè½¬æ¢ä¸ºå› å­ç±»å‹ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_discretize(Age, options = list(cuts = 5))\n\nåˆ›å»ºè™šæ‹Ÿå˜é‡ï¼šä¾‹å¦‚ step_dummy()ã€‚è¿™ä¸ªå‡½æ•°å¯ä»¥å¯¹åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸€ä¸ªæ–°çš„äºŒè¿›åˆ¶ç‰¹å¾ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_dummy(Gender)\n\näº¤äº’é¡¹å’Œå¤šé¡¹å¼ï¼šä¾‹å¦‚ step_interact() å’Œ step_poly(). step_interact() å¯ä»¥åˆ›å»ºäº¤äº’é¡¹ï¼ˆå³ä¸¤ä¸ªæˆ–æ›´å¤šå˜é‡çš„ä¹˜ç§¯ï¼‰ï¼Œè€Œ step_poly() å¯ä»¥åˆ›å»ºå¤šé¡¹å¼ç‰¹å¾ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_interact(~ starts_with(\"x1\"):starts_with(\"x2\")) %&gt;%\n  step_poly(Gender, degree = 2)\n\nç¼ºå¤±å€¼å¤„ç†ï¼šä¾‹å¦‚ step_impute_knn() å’Œ step_impute_median(). è¿™äº›å‡½æ•°å¯ä»¥ç”¨ä¸åŒçš„æ–¹æ³•ï¼ˆå¦‚ KNN å¡«å……æˆ–ä¸­ä½æ•°å¡«å……ï¼‰æ¥å¤„ç†ç¼ºå¤±å€¼ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_impute_knn(all_predictors()) %&gt;%\n  step_impute_median(Age)\næ­¤å¤–ï¼Œrecipes åŒ…ä¸­çš„ filter ç±»å‡½æ•°ç”¨äºé€‰æ‹©æˆ–æ’é™¤ç‰¹å®šçš„è§‚å¯Ÿå€¼æˆ–å˜é‡ã€‚ä¾‹å¦‚ï¼š\n\nstep_slice()ï¼šè¿™ä¸ªå‡½æ•°ä¼šæ ¹æ®ç»™å®šçš„è¡Œç´¢å¼•ä¿ç•™æˆ–åˆ é™¤è§‚å¯Ÿå€¼ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_slice(row_index(5:10))\nä¸Šé¢çš„ä»£ç å°†ä¿ç•™ç¬¬5è¡Œè‡³ç¬¬10è¡Œçš„æ•°æ®ã€‚\n\nstep_rm()ï¼šè¿™ä¸ªå‡½æ•°ä¼šä»æ•°æ®é›†ä¸­åˆ é™¤æŒ‡å®šçš„å˜é‡ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_rm(Gender)\nä¸Šé¢çš„ä»£ç å°†ä»æ•°æ®é›†ä¸­ç§»é™¤ Gender è¿™ä¸€åˆ—ã€‚\n\nstep_zv()ï¼šè¯¥å‡½æ•°ä¼šåˆ é™¤æ‰€æœ‰é›¶æ–¹å·®é¢„æµ‹å˜é‡ï¼Œå³é‚£äº›åœ¨æ‰€æœ‰è§‚å¯Ÿå€¼ä¸­éƒ½å…·æœ‰ç›¸åŒå€¼çš„åˆ—ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_zv(all_predictors())\nä¸Šé¢çš„ä»£ç å°†ç§»é™¤æ‰€æœ‰é›¶æ–¹å·®çš„é¢„æµ‹å˜é‡ã€‚\n\nstep_corr()ï¼šå¯¹äºé«˜åº¦ç›¸å…³çš„é¢„æµ‹å˜é‡ï¼ˆå³ä¸¤ä¸ªå˜é‡ç›¸äº’ä¹‹é—´çš„ç›¸å…³æ€§è¶…è¿‡ç»™å®šé˜ˆå€¼ï¼‰ï¼Œæ­¤å‡½æ•°å°†åªä¿ç•™ä¸€ä¸ªã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_corr(all_numeric(), threshold = 0.9)\nä»¥ä¸Šä»£ç å°†ç§»é™¤ä¸ä»»ä½•å…¶ä»–æ•°å€¼å˜é‡ç›¸å…³æ€§è¶…è¿‡ 0.9 çš„å˜é‡ã€‚\nä»¥ä¸Šåªæ˜¯ä¸€éƒ¨åˆ†ä¾‹å­ï¼Œrecipes åŒ…è¿˜æä¾›äº†æ›´å¤šçš„ step_ å‡½æ•°ã€‚å…·ä½“å¯æ ¹æ®æ•°æ®é›†å’Œå»ºæ¨¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„é¢„å¤„ç†æ­¥éª¤ã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#å…¶å®ƒçš„ç‰¹å¾å·¥ç¨‹å·¥å…·",
    "href": "15.tidymodels-recipes.html#å…¶å®ƒçš„ç‰¹å¾å·¥ç¨‹å·¥å…·",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.6 å…¶å®ƒçš„ç‰¹å¾å·¥ç¨‹å·¥å…·",
    "text": "5.6 å…¶å®ƒçš„ç‰¹å¾å·¥ç¨‹å·¥å…·\né™¤äº† recipes åŒ…ï¼Œè¿˜æœ‰å¦å¤–ä¸€äº›åŒ…æä¾›äº†æ›´å¤šçš„ç‰¹å¾å·¥ç¨‹å·¥å…·ã€‚è¿™äº›å·¥å…·å¯ä»¥åœ¨ https://www.tidymodels.org/find/recipes/ æ‰¾åˆ°ã€‚\nä¾‹å¦‚ï¼Œtextrecipes æ˜¯ tidymodels çš„ä¸€ä¸ªæ‰©å±•åŒ…ï¼Œä¸“é—¨å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ä¸­å¸¸è§çš„æ–‡æœ¬é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹æ­¥éª¤ã€‚å®ƒéµå¾ªä¸ recipes åŒ…ç›¸åŒçš„è®¾è®¡åŸç†ï¼Œå¹¶æä¾›äº†ä¸€äº›é’ˆå¯¹æ–‡æœ¬æ•°æ®çš„ step_ å‡½æ•°ã€‚\nä»¥ä¸‹æ˜¯ä¸€äº›ä¸»è¦çš„ step_ å‡½æ•°ï¼š\n\nstep_tokenize()ï¼š è¿™ä¸ªå‡½æ•°å°†æ–‡æœ¬åˆ†å‰²æˆå•è¯æˆ–æ ‡è®°(token)ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_tokenize(text_column)\n\nstep_stopwords()ï¼šè¿™ä¸ªå‡½æ•°å¯ä»¥åˆ é™¤è¢«è®¤ä¸ºå¯¹æ¨¡å‹æ²¡æœ‰ä¿¡æ¯ä»·å€¼çš„å¸¸ç”¨è¯ï¼ˆå¦‚â€œtheâ€ã€â€œandâ€ç­‰ï¼‰ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_tokenize(text_column) %&gt;%\n  step_stopwords(text_column)\n\nstep_tfidf()ï¼šæ­¤å‡½æ•°è®¡ç®—æ¯ä¸ªè¯çš„ TF-IDF ï¼ˆè¯é¢‘-é€†æ–‡æ¡£é¢‘ç‡ï¼‰å¾—åˆ†ï¼Œè¿™æ˜¯ä¸€ç§å¸¸è§çš„è®¡ç®—è¯é‡è¦æ€§çš„æ–¹æ³•ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_tokenize(text_column) %&gt;%\n  step_tfidf(text_column)\n\nstep_sequence_onehot(): å¯¹åºåˆ—æ•°æ®è¿›è¡Œç‹¬çƒ­ç¼–ç ã€‚\n\nrecipe &lt;- recipe(~ ., data = your_data) %&gt;%\n  step_sequence_onehot(text_column)\nä»¥ä¸Šåªæ˜¯ textrecipes åŒ…æä¾›çš„éƒ¨åˆ†å‡½æ•°ï¼Œè¿˜æœ‰æ›´å¤šå…¶ä»–çš„å‡½æ•°ç”¨äºå¤„ç†ç‰¹å®šçš„æ–‡æœ¬é¢„å¤„ç†ä»»åŠ¡ï¼Œæ¯”å¦‚è¯å¹²æå–ï¼ˆstemmingï¼‰ã€è¯å½¢è¿˜åŸï¼ˆlemmatizationï¼‰ç­‰ã€‚è¿™ä¸ªåŒ…æ˜¯å¯¹ recipes åŒ…çš„æœ‰æ•ˆæ‰©å±•ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†æ–‡æœ¬æ•°æ®ã€‚\né™¤æ­¤ä¹‹å¤–ï¼Œç”¨æˆ·è¿˜å¯ä»¥åˆ›å»ºè‡ªå·±çš„ step_* å‡½æ•°ï¼Œå‚è§ï¼šhttps://www.tidymodels.org/learn/develop/recipes/ã€‚"
  },
  {
    "objectID": "15.tidymodels-recipes.html#åˆ›å»ºæ–°å˜é‡",
    "href": "15.tidymodels-recipes.html#åˆ›å»ºæ–°å˜é‡",
    "title": "5Â  ç‰¹å¾å·¥ç¨‹",
    "section": "5.7 åˆ›å»ºæ–°å˜é‡",
    "text": "5.7 åˆ›å»ºæ–°å˜é‡\nè¿™ä¸ªä»£ç ç¤ºä¾‹ä¸»è¦å±•ç¤ºäº† recipes åŒ…åœ¨æ•°æ®é¢„å¤„ç†ä¸­çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬åˆ›å»ºæ–°çš„å˜é‡ä»¥åŠå¦‚ä½•æ­£ç¡®åœ°åµŒå…¥å¯¹è±¡ã€‚è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥çœ‹ã€‚\n\nrec &lt;-\n  recipe(~., data = iris) %&gt;%\n  step_mutate(\n    dbl_width = Sepal.Width * 2,\n    half_length = Sepal.Length / 2\n  )\n\nprepped &lt;- prep(rec, training = iris %&gt;% slice(1:75))\n\nlibrary(dplyr)\n\ndplyr_train &lt;-\n  iris %&gt;%\n  as_tibble() %&gt;%\n  slice(1:75) %&gt;%\n  mutate(\n    dbl_width = Sepal.Width * 2,\n    half_length = Sepal.Length / 2\n  )\n\nrec_train &lt;- bake(prepped, new_data = NULL)\nall.equal(dplyr_train, rec_train)\n#&gt; [1] TRUE\n\ndplyr_test &lt;-\n  iris %&gt;%\n  as_tibble() %&gt;%\n  slice(76:150) %&gt;%\n  mutate(\n    dbl_width = Sepal.Width * 2,\n    half_length = Sepal.Length / 2\n  )\nrec_test &lt;- bake(prepped, iris %&gt;% slice(76:150))\nall.equal(dplyr_test, rec_test)\n#&gt; [1] TRUE\n\n# Embedding objects:\nconst &lt;- 1.414\n\nqq_rec &lt;-\n  recipe(~., data = iris) %&gt;%\n  step_mutate(\n    bad_approach = Sepal.Width * const,\n    best_approach = Sepal.Width * !!const\n  ) %&gt;%\n  prep(training = iris)\n\nbake(qq_rec, new_data = NULL, contains(\"appro\")) %&gt;% slice(1:4)\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   bad_approach best_approach\n#&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1         4.95          4.95\n#&gt; 2         4.24          4.24\n#&gt; 3         4.52          4.52\n#&gt; 4         4.38          4.38\n\n# The difference:\ntidy(qq_rec, number = 1)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;   terms         value               id          \n#&gt;   &lt;chr&gt;         &lt;chr&gt;               &lt;chr&gt;       \n#&gt; 1 bad_approach  Sepal.Width * const mutate_Bv7YY\n#&gt; 2 best_approach Sepal.Width * 1.414 mutate_Bv7YY\n\né¦–å…ˆï¼Œå®šä¹‰äº†ä¸€ä¸ª recipeï¼Œè¯¥ recipe å¯¹ iris æ•°æ®é›†çš„ Sepal.Width å’Œ Sepal.Length åˆ—è¿›è¡Œäº†å˜æ¢ï¼Œåˆ›å»ºäº†ä¸¤ä¸ªæ–°çš„åˆ— dbl_widthï¼ˆç­‰äº Sepal.Width çš„ä¸¤å€ï¼‰å’Œ half_lengthï¼ˆç­‰äº Sepal.Length çš„ä¸€åŠï¼‰ã€‚ç„¶åï¼Œä½¿ç”¨ prep() å‡½æ•°å‡†å¤‡ï¼ˆæˆ–è®­ç»ƒï¼‰è¿™ä¸ª recipeï¼Œå¾—åˆ°äº†é¢„å¤„ç†æ­¥éª¤çš„ç»“æœã€‚\næ¥ç€ï¼Œä½¿ç”¨ dplyr æ‰‹åŠ¨å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œäº†ç›¸åŒçš„é¢„å¤„ç†æ­¥éª¤ï¼Œå¹¶ä½¿ç”¨ all.equal() æ£€æŸ¥æ‰‹åŠ¨å¤„ç†åçš„ç»“æœæ˜¯å¦ä¸ä½¿ç”¨ recipes å¾—åˆ°çš„ç»“æœä¸€è‡´ã€‚ç»“æœè¡¨æ˜ï¼Œä¸¤ç§æ–¹å¼å¾—åˆ°çš„ç»“æœæ˜¯ä¸€è‡´çš„ã€‚\nç„¶åï¼Œä»‹ç»äº†åµŒå…¥å¸¸æ•°å¯¹è±¡çš„æ­£ç¡®æ–¹æ³•ã€‚åœ¨è¿™éƒ¨åˆ†çš„ recipe ä¸­ï¼Œé€šè¿‡å¯¹å˜é‡ Sepal.Width ä¹˜ä»¥ä¸€ä¸ªå¸¸æ•° const æ¥ç”Ÿæˆæ–°çš„å˜é‡ã€‚è¿™é‡Œä½¿ç”¨äº† !! ç¬¦å·æ¥å¼ºåˆ¶è¯„ä¼° constã€‚è¿™ç§åšæ³•è¢«ç§°ä¸ºâ€œéæ ‡å‡†è¯„ä¼°â€ï¼ˆnon-standard evaluation, NSEï¼‰ï¼Œæ˜¯ tidyverse è½¯ä»¶åŒ…ä¸­ç»å¸¸ç”¨åˆ°çš„ä¸€ç§æŠ€å·§ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœä¸ä½¿ç”¨ !!ï¼Œé‚£ä¹ˆ const ä¼šè¢«å½“ä½œä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯å…¶å¯¹åº”çš„å€¼ã€‚\næœ€åï¼Œä½¿ç”¨ tidy() å‡½æ•°æŸ¥çœ‹äº† recipe ä¸­é¢„å¤„ç†æ­¥éª¤çš„è¯¦ç»†æƒ…å†µã€‚ä»è¾“å‡ºä¸­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ best_approach åˆ—çš„é¢„å¤„ç†ä¸­ï¼Œå¸¸æ•° const å·²ç»è¢«æ›¿æ¢ä¸ºå…¶å®é™…å€¼ 1.414ã€‚\næ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ recipes åŒ…è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œä»¥åŠåœ¨å¤„ç†è¿‡ç¨‹ä¸­å¦‚ä½•æ­£ç¡®åœ°å¤„ç†åµŒå…¥çš„å¯¹è±¡ã€‚"
  },
  {
    "objectID": "30.tidymodels-example.html#é¢„æµ‹å…‰è°±æ•°æ®çš„å®ä¾‹",
    "href": "30.tidymodels-example.html#é¢„æµ‹å…‰è°±æ•°æ®çš„å®ä¾‹",
    "title": "6Â  Example of tidymodels",
    "section": "6.1 é¢„æµ‹å…‰è°±æ•°æ®çš„å®ä¾‹",
    "text": "6.1 é¢„æµ‹å…‰è°±æ•°æ®çš„å®ä¾‹\ntidymodelsæ˜¯ä¸€ç»„ç”¨äºå»ºç«‹ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ æ¨¡å‹çš„RåŒ…ï¼Œå®ƒå¯ä»¥å¤„ç†å„ç§ç±»å‹çš„æ•°æ®ï¼ŒåŒ…æ‹¬å…‰è°±æ•°æ®ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å’Œéšæœºæ£®æ—å›å½’åœ¨tidymodelsä¸­å¯¹å…‰è°±æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚\n\n# åŠ è½½å¿…è¦çš„åŒ…\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” recipes      1.0.9\nâœ” dials        1.2.0     âœ” rsample      1.2.0\nâœ” dplyr        1.1.4     âœ” tibble       3.2.1\nâœ” ggplot2      3.4.4     âœ” tidyr        1.3.0\nâœ” infer        1.0.5     âœ” tune         1.1.2\nâœ” modeldata    1.2.0     âœ” workflows    1.1.3\nâœ” parsnip      1.1.1     âœ” workflowsets 1.0.1\nâœ” purrr        1.0.2     âœ” yardstick    1.2.0\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– purrr::discard() masks scales::discard()\nâœ– dplyr::filter()  masks stats::filter()\nâœ– dplyr::lag()     masks stats::lag()\nâœ– recipes::step()  masks stats::step()\nâ€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” forcats   1.0.0     âœ” readr     2.1.4\nâœ” lubridate 1.9.3     âœ” stringr   1.5.1\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– readr::col_factor() masks scales::col_factor()\nâœ– purrr::discard()    masks scales::discard()\nâœ– dplyr::filter()     masks stats::filter()\nâœ– stringr::fixed()    masks recipes::fixed()\nâœ– dplyr::lag()        masks stats::lag()\nâœ– readr::spec()       masks yardstick::spec()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸ºspectraçš„æ•°æ®æ¡†ï¼Œå…¶ä¸­æœ‰100åˆ—è¡¨ç¤ºå…‰è°±ç‰¹å¾ï¼Œæœ€åä¸€åˆ—æ˜¯æˆ‘ä»¬æƒ³è¦é¢„æµ‹çš„å“åº”å˜é‡\nset.seed(123)\nspectra &lt;- as_tibble(matrix(rnorm(10000), ncol = 100))\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nâ„¹ Using compatibility `.name_repair`.\n\nspectra$response &lt;- with(spectra, V1 * 2 + V2 ^ 2 + rnorm(nrow(spectra)))\n\n# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\nsplit &lt;- initial_split(spectra, prop = 3/4)\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)\n\n# å®šä¹‰PCAé¢„å¤„ç†æ­¥éª¤å’Œéšæœºæ£®æ—è§„èŒƒ\npca_recipe &lt;- recipe(response ~ ., data = train_data) %&gt;%\n  step_normalize(all_predictors()) %&gt;%\n  step_pca(all_predictors())\n\nrf_spec &lt;- rand_forest() %&gt;% set_engine(\"randomForest\", importance = TRUE)  |&gt; \n    set_mode(\"regression\")\n\n# å®šä¹‰å·¥ä½œæµ\nrf_workflow &lt;- workflow() %&gt;% add_model(rf_spec) %&gt;% add_recipe(pca_recipe)\n\n# è®­ç»ƒæ¨¡å‹\nrf_fit &lt;- fit(rf_workflow, data = train_data)\n\n# è¿›è¡Œé¢„æµ‹\npredictions &lt;- rf_fit %&gt;% predict(test_data) %&gt;% bind_cols(test_data)\npredictions %&gt;% show()\n\n# A tibble: 25 Ã— 102\n     .pred     V1      V2      V3      V4      V5      V6      V7      V8\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  2.84   -0.560 -0.710   2.20   -0.715  -0.0736 -0.602   1.07   -0.728 \n 2  1.28    1.72  -0.0450 -0.476   0.331  -1.65   -0.0951 -0.211   0.590 \n 3  0.712  -0.446  0.919  -0.0540  2.04    0.227  -0.0792 -0.849   0.748 \n 4 -0.307   0.401 -1.62    1.23   -1.73    0.653   0.882   1.69   -0.0936\n 5  0.0653  0.111 -0.0556 -0.516  -0.602  -0.123   0.206  -0.0160 -0.0867\n 6  0.978  -1.97  -0.641  -0.723  -1.26    0.430   0.310  -0.675  -0.287 \n 7  1.85    0.701 -0.850  -1.24    1.68    0.535  -1.04   -1.22    0.373 \n 8  1.54    0.838  0.235  -0.705  -0.0608  2.40    1.24    0.171   0.564 \n 9  1.47    0.426  1.44    1.96    1.02   -0.191   0.605  -0.679   1.74  \n10 -0.130  -0.295  0.452  -0.0903 -1.19    0.378  -0.506  -1.86    0.881 \n# â„¹ 15 more rows\n# â„¹ 93 more variables: V9 &lt;dbl&gt;, V10 &lt;dbl&gt;, V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;,\n#   V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;,\n#   V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;,\n#   V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;,\n#   V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;, V37 &lt;dbl&gt;,\n#   V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, V42 &lt;dbl&gt;, V43 &lt;dbl&gt;, â€¦\n\n\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆç”Ÿæˆäº†ä¸€ä¸ªæ¨¡æ‹Ÿçš„å…‰è°±æ•°æ®é›†ï¼Œç„¶åæ‰§è¡Œä¸»æˆåˆ†åˆ†æä»¥å‡å°‘æ•°æ®çš„ç»´æ•°ï¼Œæœ€åä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œé¢„æµ‹ã€‚tidymodelsæä¾›äº†è®¸å¤šå…¶ä»–çš„é¢„å¤„ç†æ­¥éª¤å’Œæ¨¡å‹è§„èŒƒï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œé€‰æ‹©å’Œè°ƒæ•´ã€‚\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºå…‰è°±æ•°æ®ï¼Œå› ä¸ºç‰¹å¾æ•°é‡é€šå¸¸å¾ˆå¤§ï¼ˆå¯èƒ½è¾¾åˆ°ä¸Šåƒæˆ–æ›´å¤šï¼‰ï¼Œæ‰€ä»¥ä¸€èˆ¬éœ€è¦è¿›è¡Œé™ç»´æˆ–è€…ç‰¹å¾é€‰æ‹©ï¼Œè€Œä¸”ä¹Ÿéœ€è¦é€‰æ‹©èƒ½å¤Ÿå¤„ç†é«˜ç»´æ•°æ®çš„æ¨¡å‹ã€‚"
  },
  {
    "objectID": "20.data-mining.html#å˜é‡ç±»å‹åŠå¤„ç†æ–¹æ³•",
    "href": "20.data-mining.html#å˜é‡ç±»å‹åŠå¤„ç†æ–¹æ³•",
    "title": "Data mining with R",
    "section": "å˜é‡ç±»å‹åŠå¤„ç†æ–¹æ³•",
    "text": "å˜é‡ç±»å‹åŠå¤„ç†æ–¹æ³•\n\nå˜é‡ç±»å‹\nåœ¨æ•°æ®æŒ–æ˜ä¸­ï¼Œå˜é‡å¯ä»¥æ ¹æ®æµ‹é‡å°ºåº¦ä¸»è¦åˆ†ä¸ºå››ç±»ï¼š\n\nå®šç±»å°ºåº¦ï¼ˆNominal Scaleï¼‰ï¼šè¿™æ˜¯æœ€ä½çº§çš„å°ºåº¦ï¼Œç”¨äºè¡¨ç¤ºå·®å¼‚ã€‚ä¾‹å¦‚ï¼Œæ€§åˆ«ï¼ˆç”·ã€å¥³ï¼‰ï¼Œè¡€å‹ï¼ˆAã€Bã€ABã€Oï¼‰ç­‰ã€‚\nå®šåºå°ºåº¦ï¼ˆOrdinal Scaleï¼‰ï¼šå®šåºå°ºåº¦ä¸ä»…å¯ä»¥åŒºåˆ†é¡¹ç›®ï¼Œè¿˜èƒ½å¤Ÿç¡®å®šé¡¹ç›®ä¹‹é—´çš„é¡ºåºã€‚ä¾‹å¦‚ï¼Œäº§å“è´¨é‡è¯„ä»·ï¼ˆä¼˜ã€è‰¯ã€ä¸­ã€å·®ï¼‰ï¼Œæ•™è‚²ç¨‹åº¦ï¼ˆå°å­¦ã€åˆä¸­ã€é«˜ä¸­ã€å¤§å­¦ï¼‰ç­‰ã€‚\nå®šè·å°ºåº¦ï¼ˆInterval Scaleï¼‰ï¼šå®šè·å°ºåº¦é™¤äº†å…·æœ‰å®šåºå°ºåº¦çš„ç‰¹æ€§å¤–ï¼Œè¿˜å¯ä»¥æµ‹é‡é¡¹ç›®ä¹‹é—´çš„è·ç¦»ã€‚ä¾‹å¦‚ï¼Œæ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰ï¼Œå¹´ä»½ç­‰ã€‚\nå®šæ¯”å°ºåº¦ï¼ˆRatio Scaleï¼‰ï¼šå®šæ¯”å°ºåº¦æ˜¯æœ€é«˜çº§çš„å°ºåº¦ï¼Œå®ƒå…·æœ‰å›ºå®šçš„é›¶ç‚¹å’Œå•ä½å°ºåº¦ï¼Œå¹¶ä¸”å¯ä»¥è¿›è¡ŒåŠ ã€å‡ã€ä¹˜ã€é™¤ç­‰è¿ç®—ã€‚ä¾‹å¦‚ï¼Œé•¿åº¦ï¼ˆç±³ï¼‰ã€é‡é‡ï¼ˆåƒå…‹ï¼‰ã€æ”¶å…¥ç­‰ã€‚\n\nå¯¹å˜é‡çš„ç†è§£å’Œå¤„ç†ç›´æ¥å½±å“åˆ°æ•°æ®æŒ–æ˜çš„ç»“æœï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ ¹æ®ä¸åŒçš„å˜é‡ç±»å‹é€‰æ‹©åˆé€‚çš„æ•°æ®æŒ–æ˜æ–¹æ³•ã€‚\n\n\nå¦‚ä½•å¤„ç†ç¦»æ•£å˜é‡\nå¤„ç†ç¦»æ•£ï¼ˆåˆ†ç±»ï¼‰å˜é‡ä¸€èˆ¬æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•ï¼š\n\nç‹¬çƒ­ç¼–ç ï¼ˆOne-hot Encodingï¼‰ï¼šå¯¹äºæ¯ä¸€ä¸ªç±»åˆ«ç”Ÿæˆä¸€ä¸ªå¸ƒå°”åˆ—ï¼Œè¿™ä¸ªç±»åˆ«è¡¨ç¤ºä¸º1ï¼Œå…¶å®ƒç±»åˆ«è¡¨ç¤ºä¸º0ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„æ•°æ®é›†ä¸­æœ‰ä¸€ä¸ªåä¸ºâ€œé¢œè‰²â€çš„åˆ†ç±»å˜é‡ï¼Œå…¶ä¸­åŒ…å«ä¸‰ä¸ªå€¼ï¼šâ€œçº¢è‰²â€ï¼Œâ€œè“è‰²â€å’Œâ€œç»¿è‰²â€ã€‚é€šè¿‡ç‹¬çƒ­ç¼–ç ï¼Œå¯ä»¥å°†è¿™ä¸€åˆ†ç±»å˜é‡è½¬åŒ–ä¸º3ä¸ªå¸ƒå°”å˜é‡ï¼šâ€œæ˜¯çº¢è‰²â€ï¼Œâ€œæ˜¯è“è‰²â€å’Œâ€œæ˜¯ç»¿è‰²â€ã€‚\næ ‡ç­¾ç¼–ç ï¼ˆLabel Encodingï¼‰ï¼šæ¯ä¸€ä¸ªå”¯ä¸€çš„åˆ†ç±»å€¼è¢«èµ‹äºˆä¸€ä¸ªæ•´æ•°ã€‚ä¾‹å¦‚ï¼Œâ€œçº¢è‰²â€ä¸º1ï¼Œâ€œè“è‰²â€ä¸º2ï¼Œâ€œç»¿è‰²â€ä¸º3ã€‚è¿™ç§æ–¹å¼é€‚ç”¨äºæœ‰åºçš„åˆ†ç±»å˜é‡ï¼Œå¦‚è¯„çº§ï¼ˆå¥½ã€ä¸­ã€å·®ç­‰ï¼‰ã€‚ä½†å¯¹äºæ— åºçš„åˆ†ç±»å˜é‡ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹è¯¯è§£å…¶ä¸­å­˜åœ¨é¡ºåºå…³ç³»ã€‚\näºŒè¿›åˆ¶ç¼–ç ï¼ˆBinary Encodingï¼‰ï¼šé¦–å…ˆï¼Œå°†æ‰€æœ‰çš„åˆ†ç±»å€¼æŒ‰ç…§å‡ºç°çš„é¢‘ç‡ä»é«˜åˆ°ä½æ’åºï¼Œå¹¶åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°å€¼ã€‚ç„¶åï¼Œå°†è¿™äº›æ•´æ•°å€¼è½¬æ¢ä¸ºäºŒè¿›åˆ¶å½¢å¼ã€‚\nå“‘å˜é‡ï¼ˆDummy Variableï¼‰ï¼šå“‘å˜é‡æ˜¯ç‹¬çƒ­ç¼–ç çš„ä¸€ç§ç‰¹ä¾‹ï¼Œå¸¸ç”¨äºç»Ÿè®¡å­¦ä¸­ã€‚åœ¨å“‘å˜é‡ç¼–ç ä¸­ï¼Œä¼šä¸ºåˆ†ç±»å˜é‡çš„æ¯ä¸€ä¸ªç±»åˆ«åˆ›å»ºä¸€ä¸ªæ–°çš„å˜é‡ï¼Œç„¶åä½¿ç”¨0æˆ–1æ¥è¡¨ç¤ºç±»åˆ«æ˜¯å¦å­˜åœ¨ã€‚ä¸ç‹¬çƒ­ç¼–ç ä¸åŒçš„æ˜¯ï¼Œä¸ºäº†é¿å…å…±çº¿æ€§é—®é¢˜ï¼Œå“‘å˜é‡ä¼šå°‘åˆ›å»ºä¸€ä¸ªå˜é‡ã€‚\næ•ˆåº”ç¼–ç ï¼ˆEffect Encodingï¼‰ï¼šæ•ˆåº”ç¼–ç æ˜¯å“‘å˜é‡ç¼–ç çš„ä¸€ç§æ‰©å±•ï¼Œé€šå¸¸ç”¨äºçº¿æ€§æ¨¡å‹ï¼ˆå¦‚çº¿æ€§å›å½’ï¼‰ã€‚å¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œå¦‚æœè¯¥ç±»åˆ«å¯¹åº”çš„è§‚å¯Ÿå€¼æ˜¯1ï¼Œåˆ™ç¼–ç ä¸º1ï¼Œå¦‚æœæ˜¯0ï¼Œåˆ™ç¼–ç ä¸º-1ï¼Œå¦åˆ™ç¼–ç ä¸º0ã€‚\nå“ˆå¸Œç¼–ç ï¼ˆHashing Encodingï¼‰ï¼šå“ˆå¸Œç¼–ç é€šè¿‡å“ˆå¸Œå‡½æ•°å°†åˆ†ç±»å˜é‡æ˜ å°„åˆ°æ¯”åŸå…ˆåˆ†ç±»æ•°ç›®æ›´å°çš„ç©ºé—´ã€‚å®ƒå¯ä»¥å¤„ç†å¤§è§„æ¨¡åˆ†ç±»ç‰¹å¾ï¼Œå¹¶ä¸”åœ¨å†…å­˜å’Œè®¡ç®—ä¸Šæ›´é«˜æ•ˆã€‚ä½†æ˜¯ç”±äºå“ˆå¸Œç¢°æ’çš„å­˜åœ¨ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚\n\né€‰æ‹©å“ªç§æ–¹æ³•å–å†³äºä½ çš„æ•°æ®å’Œæ¨¡å‹ã€‚æœ‰äº›ç®—æ³•ï¼ˆå¦‚å†³ç­–æ ‘å’Œéšæœºæ£®æ—ï¼‰å¯ä»¥ç›´æ¥å¤„ç†åˆ†ç±»å˜é‡ï¼Œè€Œå…¶ä»–ç®—æ³•ï¼ˆå¦‚çº¿æ€§å›å½’å’Œæ”¯æŒå‘é‡æœºï¼‰åˆ™éœ€è¦è¿›è¡Œä»¥ä¸Šç¼–ç ã€‚\n\n\nå¦‚ä½•å¤„ç†æ—¶é—´å˜é‡\næ—¶é—´è‡ªå˜é‡æ— æ³•ç›´æ¥è¿›å…¥å»ºæ¨¡æ•°æ®é›†ã€‚å› ä¸ºæ—¶é—´æ˜¯æ— é™å¢é•¿çš„ï¼Œåœ¨å»ºæ¨¡æ•°æ®é›†ä¸­å‡ºç°çš„æ—¶é—´è‚¯å®šæ—©äºé¢„æµ‹æ•°æ®é›†ä¸­å‡ºç°çš„æ—¶é—´ï¼Œæ‰€ä»¥å¦‚æœéœ€è¦å†å»ºæ¨¡è¿‡ç¨‹ä¸­è€ƒè™‘æ—¶é—´è‡ªå˜é‡ï¼Œå°±å¿…é¡»å¯¹å…¶è¿›è¡Œå˜æ¢ã€‚\nå¤„ç†æ—¶é—´ä¿¡æ¯çš„æ–¹å¼ä¸»è¦å–å†³äºå…¶åœ¨æ•°æ®åˆ†æä¸­çš„ä½œç”¨å’Œå«ä¹‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å¤„ç†æ–¹å¼ï¼š\n\næ—¥æœŸ/æ—¶é—´åˆ†è§£ï¼šå°†æ—¥æœŸæˆ–æ—¶é—´å­—æ®µåˆ†è§£ä¸ºå¹´ã€æœˆã€æ—¥ã€å°æ—¶ã€åˆ†é’Ÿå’Œç§’ç­‰è¾ƒå°çš„éƒ¨åˆ†ã€‚è¿™æ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ä»ä¸­æ‰¾å‡ºæ½œåœ¨çš„è¶‹åŠ¿ã€å‘¨æœŸæ€§å’Œæ¨¡å¼ã€‚\nè®¡ç®—æ—¶é—´é—´éš”ï¼šåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå¯èƒ½éœ€è¦çŸ¥é“ä¸¤ä¸ªæ—¥æœŸæˆ–æ—¶é—´ä¹‹é—´çš„é—´éš”ï¼Œä¾‹å¦‚è®¡ç®—ç”¨æˆ·çš„ç•™å­˜æ—¶é—´ã€äº§å“çš„ç”Ÿå‘½å‘¨æœŸç­‰ã€‚\næ—¥æœŸ/æ—¶é—´ç¼–ç ï¼šå°†æ—¥æœŸè½¬æ¢ä¸ºå­£åº¦ã€æ˜ŸæœŸå‡ ã€å·¥ä½œæ—¥æˆ–èŠ‚å‡æ—¥ç­‰åˆ†ç±»å˜é‡ï¼Œè¿™å¯¹äºè€ƒå¯Ÿç‰¹å®šäº‹ä»¶å¯¹ç»“æœçš„å½±å“éå¸¸æœ‰ç”¨ã€‚\næ—¶é—´åºåˆ—åˆ†æï¼šå¦‚æœæ•°æ®å…·æœ‰æ—¶é—´é¡ºåºï¼Œé‚£ä¹ˆå°±å¯èƒ½æ¶‰åŠåˆ°æ—¶é—´åºåˆ—åˆ†æã€‚ä¾‹å¦‚é€šè¿‡è‡ªç›¸å…³å’Œåè‡ªç›¸å…³å›¾æ¥æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨å­£èŠ‚æ€§å’Œè¶‹åŠ¿ã€‚\nè®¾ç«‹æ—¶é—´çª—å£ï¼šåœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½åªå…³æ³¨æ•°æ®çš„ä¸€éƒ¨åˆ†æ—¶é—´æ®µï¼Œæ¯”å¦‚ç”¨æˆ·è¿‘7å¤©ã€30å¤©çš„è¡Œä¸ºæ•°æ®ç­‰ï¼Œæ­¤æ—¶å°±éœ€è¦è®¾ç«‹åˆé€‚çš„æ—¶é—´çª—å£è¿›è¡Œåˆ†æã€‚\nç¦»æ•£åŒ–/åˆ†ç®±ï¼šæŠŠè¿ç»­çš„æ—¶é—´ä¿¡æ¯è½¬æ¢æˆç±»åˆ«ï¼Œä¾‹å¦‚å°†24å°æ—¶åˆ¶çš„æ—¶é—´åˆ’åˆ†ä¸ºâ€œæ—©ä¸Šâ€ã€â€œä¸­åˆâ€ã€â€œä¸‹åˆâ€å’Œâ€œæ™šä¸Šâ€ã€‚\n\nä»¥ä¸Šéƒ½æ˜¯å¤„ç†æ—¶é—´ä¿¡æ¯çš„ä¸€äº›å¸¸è§ç­–ç•¥ï¼Œå…·ä½“é‡‡å–å“ªç§æ–¹å¼éœ€è¦æ ¹æ®ä½ çš„æ•°æ®å’Œéœ€æ±‚æ¥å®šã€‚\n\n\nå¦‚ä½•å¤„ç†æ•°æ®ä¸­çš„å¼‚å¸¸å€¼\nå¤„ç†å»ºæ¨¡æ•°æ®é›†ä¸­çš„æå€¼ï¼ˆå³å¼‚å¸¸å¤§æˆ–å¼‚å¸¸å°çš„å€¼ï¼‰æ˜¯å¾ˆé‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½å¯¹æ¨¡å‹çš„å­¦ä¹ äº§ç”Ÿä¸åˆ©å½±å“ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å¤„ç†æ–¹æ³•ï¼š\n\nåˆ é™¤ï¼šå¦‚æœä½ ç¡®å®šè¿™äº›æå€¼æ˜¯ç”±äºé”™è¯¯æˆ–å…¶ä»–æˆ‘ä»¬ä¸å…³å¿ƒçš„åŸå› å¯¼è‡´çš„ï¼Œå¯ä»¥é€‰æ‹©ç›´æ¥åˆ é™¤ã€‚\næˆªæ–­ï¼šå°†æ‰€æœ‰è¶…å‡ºæŸä¸ªèŒƒå›´çš„å€¼è®¾å®šä¸ºèŒƒå›´çš„ä¸Šé™æˆ–ä¸‹é™ã€‚è¿™ç§æ–¹æ³•å¯ä»¥å‡å°‘æå€¼çš„å½±å“ï¼Œä½†ä¿ç•™äº†å®ƒä»¬çš„å­˜åœ¨ã€‚\nå˜æ¢ï¼šå¦‚å¯¹æ•°å˜æ¢ã€Box-Coxå˜æ¢ç­‰ï¼Œå¯ä»¥å‡å°æå€¼é€ æˆçš„å½±å“ï¼Œå¹¶ä½¿æ•°æ®æ›´æ¥è¿‘æ­£æ€åˆ†å¸ƒï¼Œä¾¿äºåç»­å»ºæ¨¡å¤„ç†ã€‚\næ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼šé€šè¿‡å°ºåº¦å˜æ¢å°†æ‰€æœ‰æ•°æ®è½¬æ¢åˆ°åŒä¸€å°ºåº¦ï¼Œå¯ä»¥é™ä½æå€¼å¯¹æ¨¡å‹çš„å½±å“ã€‚\nä½¿ç”¨é²æ£’æ€§æ¨¡å‹ï¼šæŸäº›æ¨¡å‹ï¼ˆå¦‚åŸºäºæ ‘çš„æ¨¡å‹ï¼‰å¯¹æå€¼å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œä¸éœ€è¦é¢å¤–å¤„ç†ã€‚\nåˆ†ä½æ•°ç¦»æ•£åŒ–ï¼šå°†è¿ç»­å˜é‡æ ¹æ®å…¶å€¼çš„å¤§å°è¿›è¡Œæ’åºï¼ŒæŒ‰ç…§åˆ†ä½æ•°ï¼ˆå¦‚å››åˆ†ä½æ•°ï¼‰åˆ’åˆ†ä¸ºå¤šä¸ªç­‰çº§ï¼Œè¾ƒå¤§æˆ–è¾ƒå°çš„æå€¼ä¼šè¢«å½’å…¥æœ€é«˜æˆ–æœ€ä½çš„åˆ†ä½æ•°ä¸­ã€‚\n\nå¯¹å¾…æå€¼æ²¡æœ‰é€šç”¨çš„æœ€ä½³åšæ³•ï¼Œå…·ä½“å¤„ç†æ–¹å¼éœ€è¦åŸºäºä½ çš„æ•°æ®ç‰¹æ€§ã€æ¨¡å‹é€‰æ‹©ä»¥åŠä¸šåŠ¡éœ€æ±‚æ¥å†³å®šã€‚\n\n\nBox-Cox å˜æ¢\nBox-Coxå˜æ¢æ˜¯ä¸€ç§æ•°å€¼ç¨³å®šåŒ–ï¼ˆç¨³å®šæ–¹å·®ï¼‰å’Œæ­£æ€åŒ–çš„æŠ€æœ¯ï¼Œé€‚ç”¨äºè¿ç»­å“åº”å˜é‡ã€‚å®ƒçš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„æŒ‡æ•°ï¼ˆÎ»ï¼‰æ¥è½¬æ¢æ•°æ®ï¼Œä½¿å¾—è½¬æ¢åçš„æ•°æ®æ¥è¿‘æ­£æ€åˆ†å¸ƒã€‚\nBox-Cox å˜æ¢å…¬å¼å¦‚ä¸‹ï¼š\n\ny^{(\\lambda)} =\n\\begin{cases}\n\\frac{y^{\\lambda}-1}{\\lambda} & \\text{å¦‚æœ}\\ \\lambda \\neq 0, \\\\\nln(y) & \\text{å¦‚æœ}\\ \\lambda = 0,\n\\end{cases}\n\nå…¶ä¸­ï¼Œy æ˜¯éœ€è¦è¢«è½¬æ¢çš„åŸå§‹æ•°æ®ï¼ŒÎ» æ˜¯è½¬æ¢å‚æ•°ã€‚åœ¨å®é™…æ“ä½œä¸­ï¼Œé€šå¸¸ä¼šé€‰æ‹©ä½¿å¾—æ•°æ®æ›´æ¥è¿‘æ­£æ€åˆ†å¸ƒçš„ Î» å€¼ã€‚\nè¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†åæ€åˆ†å¸ƒçš„æ•°æ®ï¼Œå¹¶ä¸”å¯¹å¼‚å¸¸å€¼å…·æœ‰è‰¯å¥½çš„ç¨³å¥æ€§ã€‚ç„¶è€Œï¼ŒBox-Cox å˜æ¢è¦æ±‚è¾“å…¥æ•°æ®å¿…é¡»æ˜¯æ­£çš„ã€‚å¯¹äºåŒ…å«é›¶æˆ–è´Ÿæ•°çš„æ•°æ®ï¼Œå¯èƒ½éœ€è¦è¿›è¡Œå¹³ç§»æˆ–å…¶ä»–é¢„å¤„ç†æ­¥éª¤ï¼Œä»¥ä¾¿åº”ç”¨ Box-Cox å˜æ¢ã€‚\n\n\nå¦‚ä½•å¤„ç†ç¼ºå¤±å€¼\nå¤„ç†ç¼ºå¤±å€¼çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œå…·ä½“ä½¿ç”¨å“ªç§å–å†³äºæ•°æ®ä¸¢å¤±çš„æ€§è´¨ä»¥åŠåº”ç”¨é¢†åŸŸã€‚\nå¦‚æœç¼ºå¤±å€¼å®é™…å­˜åœ¨ä½†æ˜¯æ²¡æœ‰è¢«è§‚æµ‹åˆ°ï¼Œé‚£å¯ä»¥è¿›è¡Œå¡«å……ã€æ’å€¼ç­‰ã€‚å¦‚æœç¼ºå¤±å€¼æœ¬èº«å°±æ²¡æœ‰ï¼Œæ¯”å¦‚æ–°ç”¨æˆ·æ²¡æœ‰è´­ä¹°æ‰€ä»¥å°±æ²¡æœ‰è´­ä¹°è®°å½•ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨ç¼ºå¤±æŒ‡ç¤ºå˜é‡ã€‚\nä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å¤„ç†æ–¹æ³•ï¼š\n\nåˆ é™¤ï¼šç›´æ¥åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è®°å½•ã€‚è¿™æ˜¯å¤„ç†ç¼ºå¤±å€¼æœ€ç®€å•çš„æ–¹æ³•ï¼Œä½†å¦‚æœæ•°æ®ä¸¢å¤±æ˜¯éšæœºçš„ï¼Œæˆ–è€…ç¼ºå¤±å€¼è¾ƒå¤šæ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚\nå¡«å……ï¼šå°†ç¼ºå¤±å€¼æ›¿æ¢ä¸ºæŸä¸ªå€¼ã€‚å¸¸è§çš„å¡«å……æ–¹å¼åŒ…æ‹¬ä½¿ç”¨å›ºå®šå€¼ã€å¹³å‡å€¼ã€ä¸­ä½æ•°æˆ–ä¼—æ•°ç­‰ã€‚å¯¹äºåˆ†ç±»å˜é‡ï¼Œé€šå¸¸ä½¿ç”¨ä¼—æ•°æ¥å¡«å……ï¼›å¯¹äºè¿ç»­å˜é‡ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å¹³å‡å€¼æˆ–ä¸­ä½æ•°ã€‚\næ’å€¼ï¼šåœ¨æ—¶é—´åºåˆ—æ•°æ®ä¸­ï¼Œå¦‚æœä¸€ä¸ªè§‚æµ‹ç‚¹çš„å‰åæ•°æ®éƒ½æ˜¯å­˜åœ¨çš„ï¼Œé‚£ä¹ˆå¯ä»¥æ ¹æ®å‰åæ•°æ®å¯¹å…¶è¿›è¡Œæ’å€¼ã€‚æ’å€¼æ–¹æ³•æœ‰çº¿æ€§æ’å€¼ã€å¤šé¡¹å¼æ’å€¼ã€æ ·æ¡æ’å€¼ç­‰ã€‚\né¢„æµ‹æ¨¡å‹ï¼šåˆ©ç”¨å­˜åœ¨çš„æ•°æ®å»ºç«‹æ¨¡å‹ï¼Œé¢„æµ‹ç¼ºå¤±å€¼ã€‚ä¾‹å¦‚ä½¿ç”¨å›å½’æ¨¡å‹ã€å†³ç­–æ ‘ã€K-æœ€è¿‘é‚»ï¼ˆKNNï¼‰ç­‰ç®—æ³•ã€‚\nä½¿ç”¨ç¼ºå¤±å€¼æŒ‡ç¤ºå˜é‡ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å˜é‡æ¥æŒ‡ç¤ºæ•°æ®æ˜¯å¦ä¸¢å¤±ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤„ç†è°ƒæŸ¥é—®å·æ—¶ï¼ŒæŸä¸ªé—®é¢˜çš„éå›ç­”ï¼ˆNAï¼‰å¯èƒ½å°±æ„å‘³ç€è¢«è°ƒæŸ¥è€…å¯¹è¿™ä¸ªé—®é¢˜é€‰æ‹©äº†ä¸å›ç­”ï¼Œè€Œè¿™æœ¬èº«å¯èƒ½å°±æ˜¯ä¸€ä¸ªé‡è¦çš„ä¿¡æ¯ã€‚\nå¤šé‡æ’è¡¥ï¼šå¤šé‡æ’è¡¥ï¼ˆMultiple Imputationï¼‰æ˜¯ä¸€ç§ç»Ÿè®¡æŠ€å·§ï¼Œé€šè¿‡è‡ªç›¸å…³å…³ç³»ç”Ÿæˆå¤šä»½æ›¿ä»£ç¼ºå¤±å€¼çš„å®Œæ•´æ•°æ®é›†ï¼Œåœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œåˆ†æï¼Œç„¶åå°†ç»“æœåˆå¹¶ã€‚å®ƒå¯ä»¥æœ‰æ•ˆå¤„ç†æ•°æ®ä¸¢å¤±ä¸ç¡®å®šæ€§çš„é—®é¢˜ã€‚\n\nåœ¨å¤„ç†ç¼ºå¤±å€¼æ—¶ï¼Œé¦–å…ˆéœ€è¦ç†è§£æ•°æ®ä¸¢å¤±çš„æœºåˆ¶ï¼Œä¾‹å¦‚æ˜¯å®Œå…¨éšæœºä¸¢å¤±ã€éšæœºä¸¢å¤±è¿˜æ˜¯ééšæœºä¸¢å¤±ï¼Œç„¶åå†é€‰æ‹©é€‚å½“çš„æ–¹æ³•ã€‚å¯¹äºä¸åŒçš„é—®é¢˜ï¼Œå¯èƒ½éœ€è¦å°è¯•ä¸åŒçš„æ–¹æ³•ï¼Œä»¥æ‰¾åˆ°æœ€é€‚åˆçš„å¤„ç†æ–¹å¼ã€‚\n\n\nç±»åˆ«ä¸å¹³è¡¡é—®é¢˜\nç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆClass Imbalance Problemï¼‰æ˜¯åœ¨ç›‘ç£å­¦ä¹ ä¸­å¸¸è§çš„é—®é¢˜ï¼Œå…¶ç‰¹ç‚¹æ˜¯ç›®æ ‡å˜é‡çš„ç±»åˆ«åˆ†å¸ƒä¸å‡åŒ€ã€‚ä¾‹å¦‚ï¼Œåœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œå¤§éƒ¨åˆ†æ ·æœ¬å¯èƒ½å±äºä¸€ä¸ªç±»åˆ«ï¼Œè€Œå¦ä¸€ç±»åˆ«çš„æ ·æœ¬æ•°é‡ç›¸å¯¹éå¸¸å°‘ã€‚\nè¿™ç§é—®é¢˜åœ¨ç°å®ä¸–ç•Œä¸­å¾ˆå¸¸è§ï¼Œæ¯”å¦‚ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ã€ç–¾ç—…è¯Šæ–­ã€ç”µå­é‚®ä»¶åƒåœ¾è¿‡æ»¤ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè´Ÿé¢ç±»ï¼ˆå¦‚æ¬ºè¯ˆã€ç–¾ç—…æˆ–åƒåœ¾é‚®ä»¶ï¼‰é€šå¸¸ä¼šè¿œå°‘äºæ­£é¢ç±»ã€‚\nç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ç»™æœºå™¨å­¦ä¹ ä»»åŠ¡å¸¦æ¥æŒ‘æˆ˜ï¼Œå› ä¸ºå¤§å¤šæ•°ç®—æ³•ä¼šåå‘äºå¤šæ•°ç±»ï¼Œä»è€Œå¿½ç•¥äº†æ•°é‡è¾ƒå°‘ä½†å¯èƒ½æ›´é‡è¦çš„å°‘æ•°ç±»ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½é™ä½ã€‚\nå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æœ‰å„ç§æ–¹æ³•ï¼Œä¾‹å¦‚ï¼š\n\né‡æ–°é‡‡æ ·ï¼šåŒ…æ‹¬è¿‡æŠ½æ ·ï¼ˆå¢åŠ å°‘æ•°ç±»çš„æ ·æœ¬ï¼‰å’Œæ¬ æŠ½æ ·ï¼ˆå‡å°‘å¤šæ•°ç±»çš„æ ·æœ¬ï¼‰ã€‚\näº§ç”Ÿåˆæˆæ ·æœ¬ï¼šä¾‹å¦‚SMOTEï¼ˆSynthetic Minority Over-Sampling Techniqueï¼‰ç®—æ³•ï¼Œé€šè¿‡æ’å€¼çš„æ–¹å¼ç”Ÿæˆæ–°çš„å°‘æ•°ç±»æ ·æœ¬ã€‚\nè°ƒæ•´åˆ†ç±»é˜ˆå€¼ï¼šé’ˆå¯¹ä¸åŒçš„ç±»åˆ«è®¾å®šä¸åŒçš„åˆ†ç±»é˜ˆå€¼ã€‚\nä»£ä»·æ•æ„Ÿå­¦ä¹ ï¼šç»™äºˆå°‘æ•°ç±»æ ·æœ¬æ›´é«˜çš„æƒé‡ã€‚\nä½¿ç”¨é›†æˆæ–¹æ³•ï¼šå¦‚éšæœºæ£®æ—ã€Adaboostç­‰ï¼Œè¿™äº›ç®—æ³•å¯¹ä¸å¹³è¡¡æ•°æ®å…·æœ‰è¾ƒå¥½çš„é²æ£’æ€§ã€‚\n\nè¿‡æŠ½æ ·ï¼ˆOversamplingï¼‰å’Œæ¬ æŠ½æ ·ï¼ˆUndersamplingï¼‰é€šå¸¸ç”¨äºå¤„ç†ä¸å¹³è¡¡åˆ†ç±»é—®é¢˜ã€‚\n\nè¿‡æŠ½æ ·ï¼šå½“æˆ‘ä»¬çš„æ•°æ®é›†ä¸­å°‘æ•°ç±»çš„æ ·æœ¬æ•°é‡è¿œå°‘äºå¤šæ•°ç±»æ—¶ï¼Œè¿‡æŠ½æ ·æ–¹æ³•ä¼šé€šè¿‡å¢åŠ å°‘æ•°ç±»çš„æ ·æœ¬æ•°é‡æ¥è¾¾åˆ°ç±»åˆ«å¹³è¡¡ã€‚è¿™å¯ä»¥é€šè¿‡å¤åˆ¶å°‘æ•°ç±»æ ·æœ¬æˆ–ç”Ÿæˆæ–°çš„å°‘æ•°ç±»æ ·æœ¬ï¼ˆä¾‹å¦‚ä½¿ç”¨SMOTEç®—æ³•ï¼‰æ¥å®ç°ã€‚ä½†æ˜¯ï¼Œè¿‡åº¦æŠ½æ ·å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå› ä¸ºå®ƒä¼šå¤åˆ¶å°‘æ•°ç±»æ ·æœ¬ï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥å™ªå£°ã€‚\næ¬ æŠ½æ ·ï¼šä¸è¿‡æŠ½æ ·ç›¸åï¼Œå½“æˆ‘ä»¬çš„æ•°æ®é›†ä¸­å¤šæ•°ç±»çš„æ ·æœ¬æ•°é‡è¿œå¤§äºå°‘æ•°ç±»æ—¶ï¼Œæ¬ æŠ½æ ·æ–¹æ³•ä¼šé€šè¿‡å‡å°‘å¤šæ•°ç±»æ ·æœ¬çš„æ•°é‡æ¥è¾¾åˆ°ç±»åˆ«å‡è¡¡ã€‚è¿™å¯ä»¥é€šè¿‡éšæœºåˆ é™¤å¤šæ•°ç±»æ ·æœ¬æˆ–ä½¿ç”¨èšç±»æŠ€æœ¯å°†å¤šæ•°ç±»æ ·æœ¬è¿›è¡Œåˆå¹¶ç­‰æ–¹å¼å®ç°ã€‚ç„¶è€Œï¼Œæ¬ æŠ½æ ·å¯èƒ½ä¼šä¸¢å¤±å¤šæ•°ç±»çš„ä¸€äº›é‡è¦ä¿¡æ¯ã€‚\n\nä»¥ä¸Šä¸¤ç§æ–¹æ³•éƒ½æœ‰å…¶ä¼˜åŠ¿å’Œç¼ºç‚¹ï¼Œå…·ä½“ä½¿ç”¨å“ªç§æ–¹æ³•éœ€è¦åŸºäºä½ çš„æ•°æ®ç‰¹æ€§ä»¥åŠä¸šåŠ¡éœ€æ±‚æ¥å†³å®šã€‚å¦å¤–ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨ç»„åˆé‡‡æ ·ï¼ˆCombination Samplingï¼‰ï¼ŒåŒæ—¶åº”ç”¨è¿‡æŠ½æ ·å’Œæ¬ æŠ½æ ·ï¼Œæˆ–è€…ä½¿ç”¨æ›´å¤æ‚çš„æ–¹æ³•å¦‚ä»£ä»·æ•æ„Ÿå­¦ä¹ ï¼ˆCost-Sensitive Learningï¼‰ç­‰ã€‚\n\n\né™ç»´æ“ä½œ\næ•°æ®çš„é™ç»´æ˜¯æŒ‡é€šè¿‡æŸç§æ•°å­¦æ–¹æ³•ï¼Œå°†æœ‰å¾ˆå¤šç‰¹å¾ï¼ˆç»´åº¦ï¼‰çš„æ•°æ®é›†è½¬åŒ–ä¸ºå…·æœ‰è¾ƒå°‘ç‰¹å¾çš„æ•°æ®é›†ï¼ŒåŒæ—¶è¿˜èƒ½ä¿ç•™åŸå§‹æ•°æ®ä¸­çš„å¤§éƒ¨åˆ†é‡è¦ä¿¡æ¯ã€‚\nä»¥ä¸‹æ˜¯è¿›è¡Œæ•°æ®é™ç»´çš„ä¸»è¦ç†ç”±ï¼š\n\nå‡å°‘è®¡ç®—é‡ï¼šå¤§é‡çš„ç‰¹å¾å¯èƒ½ä¼šå¯¼è‡´è®¡ç®—é‡å·¨å¤§ï¼Œå¢åŠ å¤„ç†æ•°æ®å’Œè®­ç»ƒæ¨¡å‹çš„æ—¶é—´ã€‚\né™ä½æ¨¡å‹å¤æ‚æ€§ï¼šå»é™¤ä¸ç›¸å…³æˆ–å†—ä½™çš„ç‰¹å¾å¯ä»¥é™ä½æ¨¡å‹çš„å¤æ‚æ€§ï¼Œæé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚\né¿å…ç»´åº¦ç¾éš¾ï¼šåœ¨é«˜ç»´åº¦ç©ºé—´ä¸­ï¼Œæ•°æ®å¯èƒ½ä¼šéå¸¸ç¨€ç–ï¼Œè¿™ä½¿å¾—è®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•éš¾ä»¥æœ‰æ•ˆåœ°å·¥ä½œï¼Œè¿™è¢«ç§°ä¸ºâ€œç»´åº¦ç¾éš¾â€ã€‚\nå¯è§†åŒ–ï¼šå¯¹äºäºŒç»´æˆ–ä¸‰ç»´çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å›¾å½¢ç›´è§‚åœ°å±•ç¤ºå…¶ç»“æ„æˆ–è€…æ¨¡å¼ã€‚è€Œæ›´é«˜ç»´åº¦çš„æ•°æ®æ— æ³•ç›´æ¥å¯è§†åŒ–ï¼Œéœ€è¦é€šè¿‡é™ç»´æŠ€æœ¯è½¬æ¢åˆ°äºŒç»´æˆ–ä¸‰ç»´ã€‚\n\næœ€å¸¸è§çš„é™ç»´æŠ€æœ¯åŒ…æ‹¬ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã€çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ã€t-åˆ†å¸ƒé‚»åŸŸåµŒå…¥ç®—æ³•ï¼ˆt-SNEï¼‰ç­‰ã€‚é€‰æ‹©å“ªç§æŠ€æœ¯å–å†³äºä½ çš„æ•°æ®ç‰¹æ€§å’Œéœ€æ±‚ã€‚"
  },
  {
    "objectID": "20.data-mining.html#æ•°æ®æŒ–æ˜æ–¹æ³•",
    "href": "20.data-mining.html#æ•°æ®æŒ–æ˜æ–¹æ³•",
    "title": "Data mining with R",
    "section": "æ•°æ®æŒ–æ˜æ–¹æ³•",
    "text": "æ•°æ®æŒ–æ˜æ–¹æ³•\n\nå…³è”è§„åˆ™æŒ–æ˜\nå…³è”è§„åˆ™æŒ–æ˜æ˜¯ä¸€ç§åœ¨å¤§å‹æ•°æ®é›†ä¸­å‘ç°å˜é‡é—´æœ‰è¶£å…³ç³»çš„æ–¹æ³•ï¼Œå¸¸è¢«ç”¨äºå¸‚åœºç¯®åˆ†æï¼Œå®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬ç†è§£å“ªäº›å•†å“ç»å¸¸åŒæ—¶è¢«è´­ä¹°ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼š\nå‡è®¾ä½ æ˜¯ä¸€ä¸ªé›¶å”®å•†ï¼Œå‡ºå”®å„ç§ä¸åŒçš„å•†å“ï¼Œä½ å¸Œæœ›çŸ¥é“å®¢æˆ·çš„è´­ä¹°è¡Œä¸ºæ¨¡å¼æ¥æ”¹å–„äº§å“å¸ƒå±€æˆ–ä¼˜åŒ–é”€å”®ç­–ç•¥ã€‚ä½ å¯èƒ½æœ‰ä¸€ä¸ªå¤§å‹çš„äº¤æ˜“æ•°æ®åº“ï¼Œæ¯æ¡è®°å½•åŒ…å«ä¸€æ¬¡è´­ä¹°è¡Œä¸ºä»¥åŠè¯¥æ¬¡è´­ä¹°ä¸­åŒ…å«çš„å•†å“ã€‚\né€šè¿‡å…³è”è§„åˆ™æŒ–æ˜ï¼Œä½ å¯èƒ½ä¼šå‘ç°åƒâ€œå¦‚æœè´­ä¹°äº†é¢åŒ…å’Œé»„æ²¹ï¼Œé‚£ä¹ˆå¾ˆå¯èƒ½ä¹Ÿä¼šè´­ä¹°ç‰›å¥¶â€è¿™æ ·çš„è§„åˆ™ã€‚è¿™ç§è§„åˆ™è¡¨æ˜é¢åŒ…ã€é»„æ²¹å’Œç‰›å¥¶ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„å…³è”æ€§ã€‚åˆ©ç”¨è¿™ä¸ªä¿¡æ¯ï¼Œä½ å¯èƒ½ä¼šæŠŠç‰›å¥¶æ”¾åœ¨é¢åŒ…å’Œé»„æ²¹é™„è¿‘ï¼Œä»è€Œå¢åŠ é”€å”®é‡ã€‚\nåœ¨å®é™…æ“ä½œä¸­ï¼ŒæŒ–æ˜å…³è”è§„åˆ™é€šå¸¸ä½¿ç”¨ Apriori ç®—æ³•æˆ– FP-Growth ç®—æ³•ç­‰ã€‚\nAprioriç®—æ³•æ˜¯ä¸€ç§ç”¨äºé¢‘ç¹é¡¹é›†æŒ–æ˜å’Œå…³è”è§„åˆ™å­¦ä¹ çš„å¸¸è§æ–¹æ³•ï¼Œä¸»è¦åº”ç”¨åœ¨äº‹åŠ¡æ•°æ®ä¸Šã€‚å®ƒæœ€åˆè¢«æå‡ºæ˜¯ä¸ºäº†è§£å†³å¸‚åœºç¯®å­åˆ†æçš„é—®é¢˜ï¼Œå³æ‰¾å‡ºå“ªäº›å•†å“ä¼šè¢«åŒæ—¶è´­ä¹°ã€‚\nAprioriç®—æ³•åŸºäºä¸€ä¸ªå…³é”®çš„æ¦‚å¿µï¼Œç§°ä¸ºâ€œå…ˆéªŒåŸç†â€ã€‚è¿™ä¸ªåŸç†æŒ‡å‡ºï¼Œå¦‚æœä¸€ä¸ªé¡¹é›†æ˜¯é¢‘ç¹çš„ï¼Œé‚£ä¹ˆå®ƒçš„æ‰€æœ‰å­é›†ä¹Ÿä¸€å®šæ˜¯é¢‘ç¹çš„ã€‚åè¿‡æ¥ï¼Œå¦‚æœä¸€ä¸ªé¡¹é›†æ˜¯ç¨€ç–çš„ï¼ˆéé¢‘ç¹çš„ï¼‰ï¼Œé‚£ä¹ˆå®ƒçš„æ‰€æœ‰è¶…é›†ä¹Ÿä¸€å®šæ˜¯ç¨€ç–çš„ã€‚\nAprioriç®—æ³•çš„å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\n\nç¬¬ä¸€æ­¥ï¼šé¦–å…ˆæ‰«ææ•°æ®åº“ï¼Œè®¡ç®—æ¯ä¸ªé¡¹ç›®çš„æ”¯æŒåº¦ï¼ˆä¹Ÿå°±æ˜¯åœ¨æ‰€æœ‰äº¤æ˜“ä¸­çš„å‡ºç°é¢‘ç‡ï¼‰ã€‚ç„¶åæ ¹æ®ç»™å®šçš„æœ€å°æ”¯æŒåº¦é˜ˆå€¼ï¼Œåˆ é™¤é‚£äº›æ”¯æŒåº¦ä½äºé˜ˆå€¼çš„é¡¹ç›®ï¼Œå¾—åˆ°ä¸€ç»„é¢‘ç¹çš„1-é¡¹é›†ã€‚\nç¬¬äºŒæ­¥ï¼šç„¶åï¼Œç®—æ³•ä½¿ç”¨é¢‘ç¹çš„k-é¡¹é›†ç”Ÿæˆå€™é€‰çš„(k+1)-é¡¹é›†ï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„æ”¯æŒåº¦ã€‚åˆ é™¤æ”¯æŒåº¦ä½äºé˜ˆå€¼çš„é¡¹é›†ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸æ–­é‡å¤ï¼Œç›´åˆ°ä¸èƒ½ç”Ÿæˆæ›´å¤§çš„é¡¹é›†ã€‚\nç¬¬ä¸‰æ­¥ï¼šå½“æˆ‘ä»¬æœ‰äº†é¢‘ç¹é¡¹é›†åï¼Œå°±å¯ä»¥ç”¨å®ƒä»¬æ¥ç”Ÿæˆå…³è”è§„åˆ™ã€‚å¯¹äºæ¯ä¸ªé¢‘ç¹é¡¹é›†ï¼Œæˆ‘ä»¬ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è§„åˆ™ï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„ç½®ä¿¡åº¦ï¼ˆä¹Ÿå°±æ˜¯è§„åˆ™çš„æ¡ä»¶æ¦‚ç‡ï¼‰ã€‚åˆ é™¤é‚£äº›ç½®ä¿¡åº¦ä½äºæœ€å°ç½®ä¿¡åº¦é˜ˆå€¼çš„è§„åˆ™ã€‚å‰©ä¸‹çš„è§„åˆ™å°±æ˜¯æˆ‘ä»¬æŒ–æ˜å‡ºæ¥çš„å…³è”è§„åˆ™ã€‚\n\nAprioriç®—æ³•çš„ä¼˜ç‚¹æ˜¯åŸç†ç®€å•ã€æ˜“äºå®ç°ã€‚ä½†æ˜¯ï¼Œå½“æ•°æ®åº“å¾ˆå¤§æˆ–è€…é¡¹é›†æ•°é‡å¾ˆå¤šæ—¶ï¼ŒAprioriç®—æ³•çš„è®¡ç®—å’Œå­˜å‚¨éœ€æ±‚å¯èƒ½ä¼šéå¸¸å¤§ã€‚å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨æ›´é«˜æ•ˆçš„ç®—æ³•ï¼Œå¦‚FP-Growthç­‰ã€‚\nå…³è”è§„åˆ™åˆ†æçš„ä¸€ç§å…¸å‹åº”ç”¨æ˜¯è´­ç‰©ç¯®åˆ†æï¼Œæˆ‘ä»¬æ¥ä¸¾ä¸€ä¸ªå‡è®¾çš„è´­ç‰©ç¯®æ•°æ®åˆ†æä¾‹å­ã€‚\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªäº¤æ˜“æ•°æ®é›†ã€‚æ¯ä¸ªäº¤æ˜“ä»£è¡¨ä¸€ä¸ªè´­ç‰©ç¯®ï¼ŒåŒ…å«è‹¥å¹²å•†å“ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä»¥ä¸‹æ•°æ®ï¼š\n\n# å®‰è£…å¹¶åŠ è½½arulesåŒ…\n# install.packages(\"arules\")\nlibrary(arules)\n\nè½½å…¥éœ€è¦çš„ç¨‹è¾‘åŒ…ï¼šMatrix\n\n\n\nè½½å…¥ç¨‹è¾‘åŒ…ï¼š'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n\nè½½å…¥ç¨‹è¾‘åŒ…ï¼š'arules'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following objects are masked from 'package:base':\n\n    abbreviate, write\n\n# åˆ›å»ºäº¤æ˜“æ•°æ®\ntransactions &lt;- list(\n  c(\"é¢åŒ…\", \"é»„æ²¹\"),\n  c(\"ç‰›å¥¶\", \"é¢åŒ…\", \"é»„æ²¹\"),\n  c(\"èŒ¶\", \"ç³–\"),\n  c(\"é¢åŒ…\", \"é»„æ²¹\", \"æœé…±\"),\n  c(\"ç‰›å¥¶\", \"é¢åŒ…\", \"é»„æ²¹\", \"èŒ¶\"),\n  c(\"é¢åŒ…\"),\n  c(\"èŒ¶\"),\n  c(\"èŒ¶\", \"ç³–\"),\n  c(\"é¢åŒ…\", \"ç‰›å¥¶\"),\n  c(\"é¢åŒ…\", \"é»„æ²¹\", \"èŒ¶\")\n)\ntransactions &lt;- as(transactions, \"transactions\")\n\nç„¶åï¼Œä½¿ç”¨Aprioriç®—æ³•æ¥æ‰¾å‡ºé¢‘ç¹é¡¹é›†å’Œå…³è”è§„åˆ™ï¼š\n\n# æŸ¥æ‰¾é¢‘ç¹é¡¹é›†\nfrequent_itemsets &lt;- apriori(transactions, parameter = list(support = 0.2, target = \"frequent itemsets\"))\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n         NA    0.1    1 none FALSE            TRUE       5     0.2      1\n maxlen            target  ext\n     10 frequent itemsets TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 2 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[6 item(s), 10 transaction(s)] done [0.00s].\nsorting and recoding items ... [5 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.00s].\nsorting transactions ... done [0.00s].\nwriting ... [13 set(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\ninspect(head(frequent_itemsets))\n\n    items    support count\n[1] {ç³–}     0.2     2    \n[2] {ç‰›å¥¶}   0.3     3    \n[3] {èŒ¶}     0.5     5    \n[4] {é»„æ²¹}   0.5     5    \n[5] {é¢åŒ…}   0.7     7    \n[6] {èŒ¶, ç³–} 0.2     2    \n\n# æŸ¥æ‰¾å…³è”è§„åˆ™\nrules &lt;- apriori(transactions, parameter = list(support = 0.2, confidence = 0.6))\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n        0.6    0.1    1 none FALSE            TRUE       5     0.2      1\n maxlen target  ext\n     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 2 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[6 item(s), 10 transaction(s)] done [0.00s].\nsorting and recoding items ... [5 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.00s].\nwriting ... [10 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\ninspect(head(rules))\n\n    lhs       rhs    support confidence coverage lift     count\n[1] {}     =&gt; {é¢åŒ…} 0.7     0.7000000  1.0      1.000000 7    \n[2] {ç³–}   =&gt; {èŒ¶}   0.2     1.0000000  0.2      2.000000 2    \n[3] {ç‰›å¥¶} =&gt; {é»„æ²¹} 0.2     0.6666667  0.3      1.333333 2    \n[4] {ç‰›å¥¶} =&gt; {é¢åŒ…} 0.3     1.0000000  0.3      1.428571 3    \n[5] {é»„æ²¹} =&gt; {é¢åŒ…} 0.5     1.0000000  0.5      1.428571 5    \n[6] {é¢åŒ…} =&gt; {é»„æ²¹} 0.5     0.7142857  0.7      1.428571 5    \n\n\nä¸Šè¿°ä»£ç ä¼šè¿”å›æ”¯æŒåº¦å¤§äº0.2çš„é¢‘ç¹é¡¹é›†ï¼Œä»¥åŠæ”¯æŒåº¦å¤§äº0.2ä¸”ç½®ä¿¡åº¦å¤§äº0.6çš„å…³è”è§„åˆ™ã€‚\nç„¶åå¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚æ¥è§£è¯»è¿™äº›ç»“æœï¼Œä¾‹å¦‚æŠŠç»å¸¸ä¸€èµ·è´­ä¹°çš„å•†å“æ”¾åœ¨ä¸€èµ·ï¼Œæˆ–è€…é’ˆå¯¹æŸä¸ªå•†å“çš„è´­ä¹°è€…è¿›è¡Œæ¨èç­‰ã€‚\nè¯·æ³¨æ„ï¼Œè¿™åªæ˜¯ä¸€ä¸ªåŸºç¡€ç¤ºä¾‹ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼Œä»¥åŠè°ƒæ•´Aprioriç®—æ³•çš„å‚æ•°ä»¥æ‰¾åˆ°æœ€æœ‰ä»·å€¼çš„é¡¹é›†å’Œè§„åˆ™ã€‚\n\n\nèšç±»åˆ†æ\nä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨Rè¯­è¨€è¿›è¡Œk-meansèšç±»åˆ†æçš„ä¾‹å­ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å†…ç½®çš„irisæ•°æ®é›†ã€‚\né¦–å…ˆï¼ŒåŠ è½½æ‰€éœ€çš„åº“å¹¶è¯»å–æ•°æ®ï¼š\n\n# è¯»å–æ•°æ®\ndata(iris)\n\nç„¶åè¿›è¡Œkå‡å€¼èšç±»ï¼Œè¿™é‡Œæˆ‘ä»¬è®¾å®šclusterçš„æ•°é‡ä¸º3ï¼ˆå®é™…æƒ…å†µä¸‹å¯èƒ½ä¼šéœ€è¦ç”¨åˆ°ä¸€äº›æ–¹æ³•æ¯”å¦‚elbow methodæ¥ç¡®å®škçš„å€¼ï¼‰ï¼š\n\nset.seed(123) # è®¾ç½®éšæœºæ•°ç§å­ä»¥ä¿è¯ç»“æœå¯å¤åˆ¶\n\n# æ‰§è¡Œk-meansèšç±»\nclusters &lt;- kmeans(iris[, 1:4], centers = 3)\n\n# æŸ¥çœ‹èšç±»ç»“æœ\nprint(clusters)\n\nK-means clustering with 3 clusters of sizes 50, 62, 38\n\nCluster means:\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1     5.006000    3.428000     1.462000    0.246000\n2     5.901613    2.748387     4.393548    1.433871\n3     6.850000    3.073684     5.742105    2.071053\n\nClustering vector:\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3\n[112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3\n[149] 3 2\n\nWithin cluster sum of squares by cluster:\n[1] 15.15100 39.82097 23.87947\n (between_SS / total_SS =  88.4 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nç°åœ¨ï¼Œclusterså¯¹è±¡åŒ…å«äº†èšç±»çš„ç»“æœã€‚æˆ‘ä»¬å¯ä»¥å°†å…¶æ·»åŠ å›åŸå§‹æ•°æ®ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œå¯è§†åŒ–ï¼š\n\n# å°†èšç±»ç»“æœæ·»åŠ åˆ°åŸå§‹æ•°æ®\niris$Cluster &lt;- as.factor(clusters$cluster)\n\n# å¯è§†åŒ–èšç±»ç»“æœ\nggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster)) + \n  geom_point() +\n  theme_minimal()\n\n\n\n\nä»¥ä¸Šå°±æ˜¯ä¸€ä¸ªåŸºæœ¬çš„k-meansèšç±»åˆ†æçš„ä¾‹å­ã€‚æ³¨æ„ï¼Œk-meansèšç±»å‡è®¾ç°‡æ˜¯å‡¸å½¢å’Œåœ†å½¢çš„ï¼Œå¦‚æœä½ çš„æ•°æ®ä¸æ»¡è¶³è¿™äº›å‡è®¾ï¼Œå¯èƒ½éœ€è¦é€‰æ‹©å…¶ä»–çš„èšç±»ç®—æ³•ã€‚\n\n\nå¹¿ä¹‰çº¿æ€§æ¨¡å‹\nå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGeneralized Linear Modelï¼Œç®€ç§°GLMï¼‰æ˜¯ä¸€ç±»çµæ´»çš„ç»Ÿè®¡æ¨¡å‹ã€‚å®ƒæ‰©å±•äº†ä¼ ç»Ÿçš„çº¿æ€§å›å½’æ¨¡å‹ï¼Œå…è®¸å› å˜é‡ï¼ˆå“åº”å˜é‡ï¼‰æœä»å¹¿ä¹‰çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè€Œä¸ä»…ä»…æ˜¯æ­£æ€åˆ†å¸ƒã€‚\nGLMä¸»è¦åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼š\n\néšæœºåˆ†å¸ƒæˆåˆ†ï¼šè¿™æŒ‡å®šäº†å› å˜é‡æˆ–å“åº”å˜é‡æœä»çš„æ¦‚ç‡åˆ†å¸ƒã€‚åœ¨GLMä¸­ï¼Œå“åº”å˜é‡å¯ä»¥æœä»åŒ…æ‹¬äºŒé¡¹åˆ†å¸ƒã€æ³Šæ¾åˆ†å¸ƒã€è´ŸäºŒé¡¹åˆ†å¸ƒã€ä¼½é©¬åˆ†å¸ƒç­‰åœ¨å†…çš„æŒ‡æ•°æ—åˆ†å¸ƒã€‚\nç³»ç»Ÿéƒ¨åˆ†ï¼šè¿™å’Œä¼ ç»Ÿçš„çº¿æ€§å›å½’æ¨¡å‹ç±»ä¼¼ï¼Œå‡è®¾é¢„æµ‹å€¼æ˜¯è‡ªå˜é‡ï¼ˆè§£é‡Šå˜é‡ï¼‰çš„çº¿æ€§ç»„åˆã€‚\nè¿ç»“å‡½æ•°ï¼šè¿ç»“å‡½æ•°å®šä¹‰äº†å“åº”å˜é‡çš„æœŸæœ›å€¼å’Œçº¿æ€§é¢„æµ‹å­ä¹‹é—´çš„å…³ç³»ã€‚æœ€å¸¸è§çš„ä¾‹å­åŒ…æ‹¬æ’ç­‰é“¾æ¥å‡½æ•°ï¼ˆç”¨äºæ­£æ€åˆ†å¸ƒï¼‰ã€å¯¹æ•°é“¾æ¥å‡½æ•°ï¼ˆç”¨äºæ³Šæ¾åˆ†å¸ƒæˆ–ä¼½é©¬åˆ†å¸ƒï¼‰å’Œlogité“¾æ¥å‡½æ•°ï¼ˆç”¨äºäºŒé¡¹åˆ†å¸ƒï¼‰ã€‚\n\nGLMçš„ä¸€ä¸ªé‡è¦ä¼˜ç‚¹æ˜¯å®ƒèƒ½å¤Ÿå¤„ç†å„ç§ç±»å‹çš„å“åº”å˜é‡ï¼ŒåŒ…æ‹¬è¿ç»­çš„ã€äºŒå…ƒçš„ã€è®¡æ•°çš„ç­‰ç­‰ã€‚å› æ­¤ï¼ŒGLMè¢«å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸï¼ŒåŒ…æ‹¬ç¤¾ä¼šç§‘å­¦ã€ç”Ÿç‰©ç§‘å­¦ã€åŒ»å­¦å’Œå·¥ç¨‹ç­‰ã€‚\nåœ¨Rè¯­è¨€ä¸­ï¼Œå¯ä»¥ä½¿ç”¨glmå‡½æ•°æ¥æ‹ŸåˆGLMæ¨¡å‹ï¼Œä¾‹å¦‚ï¼š\n# ä½¿ç”¨æ³Šæ¾å›å½’ï¼ˆå¯¹æ•°é“¾æ¥å‡½æ•°ï¼‰é¢„æµ‹è®¡æ•°æ•°æ®\nmodel &lt;- glm(y ~ x1 + x2, data = mydata, family = poisson(link = \"log\"))\n\nè¿æ¥å‡½æ•°\nåœ¨å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMï¼‰ä¸­ï¼Œè¿æ¥å‡½æ•°ç”¨äºæè¿°å› å˜é‡ï¼ˆå“åº”å˜é‡ï¼‰çš„æœŸæœ›å€¼å’Œçº¿æ€§é¢„æµ‹å­ä¹‹é—´çš„å…³ç³»ã€‚æ ¹æ®å“åº”å˜é‡çš„ç±»å‹å’Œåˆ†å¸ƒï¼Œå¯èƒ½ä¼šé€‰æ‹©ä¸åŒçš„è¿æ¥å‡½æ•°ã€‚\nä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„è¿æ¥å‡½æ•°åŠå…¶é€‚ç”¨åœºæ™¯ï¼š\n\næ’ç­‰é“¾æ¥å‡½æ•°ï¼ˆIdentity linkï¼‰ï¼šè¿™ç§è¿æ¥å‡½æ•°æŒ‡çš„æ˜¯çº¿æ€§é¢„æµ‹å­ç›´æ¥ç­‰äºå“åº”å˜é‡çš„æœŸæœ›å€¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œg(Î¼) = Î¼ã€‚é€‚ç”¨äºå› å˜é‡æœä»æ­£æ€åˆ†å¸ƒçš„çº¿æ€§å›å½’ã€‚\n\nmodel &lt;- glm(y ~ x1 + x2, data = mydata, family = gaussian(link = \"identity\"))\n\nå¯¹æ•°é“¾æ¥å‡½æ•°ï¼ˆLog linkï¼‰ï¼šå…¶ä¸­ g(Î¼) = log(Î¼)ã€‚è¿™ç§è¿æ¥å‡½æ•°é€šå¸¸ç”¨äºå› å˜é‡æ˜¯è®¡æ•°æ•°æ®ä¸”æœä»æ³Šæ¾åˆ†å¸ƒçš„æ³Šæ¾å›å½’æˆ–è€…ä¼½é©¬å›å½’ã€‚\n\nmodel &lt;- glm(y ~ x1 + x2, data = mydata, family = poisson(link = \"log\"))\n\nLogité“¾æ¥å‡½æ•°ï¼šå…¶ä¸­ g(Î¼) = log[Î¼ / (1 - Î¼)]ã€‚è¿™ç§è¿æ¥å‡½æ•°ç”¨äºäºŒå…ƒå“åº”å˜é‡ï¼Œæ¯”å¦‚é€»è¾‘å›å½’ä¸­çš„äºŒé¡¹åˆ†å¸ƒã€‚\n\nmodel &lt;- glm(y ~ x1 + x2, data = mydata, family = binomial(link = \"logit\"))\n\nProbité“¾æ¥å‡½æ•°ï¼šå…¶ä¸­ g(Î¼) = Î¦^(-1)(Î¼)ï¼ŒÎ¦ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ã€‚ä¹Ÿç”¨äºäºŒå…ƒå“åº”å˜é‡ï¼Œå®ƒæä¾›äº†ä¸€ç§ä¸logité“¾æ¥ç¨æœ‰ä¸åŒçš„å¯¹äºæ¦‚ç‡çš„å»ºæ¨¡æ–¹å¼ã€‚\n\nmodel &lt;- glm(y ~ x1 + x2, data = mydata, family = binomial(link = \"probit\"))\nä»¥ä¸Šåªæ˜¯éƒ¨åˆ†å¸¸è§é“¾æ¥å‡½æ•°çš„ç¤ºä¾‹ï¼Œå®é™…ä¸Šè¿˜æœ‰è®¸å¤šå…¶ä»–ç±»å‹çš„è¿æ¥å‡½æ•°ï¼Œå¯ä»¥æ ¹æ®å…·ä½“çš„æ•°æ®å’Œå»ºæ¨¡éœ€æ±‚è¿›è¡Œé€‰æ‹©ã€‚\n\n\næ³°å¦å°¼å…‹å­˜æ´»æ•°æ®\nåœ¨Rè¯­è¨€çš„titanicåŒ…ä¸­å°±åŒ…å«äº†æ³°å¦å°¼å…‹å·æ•°æ®é›†ï¼Œä½¿ç”¨è¯¥æ•°æ®åˆ†æä¹˜å®¢çš„å­˜æ´»æƒ…å†µä¸å…¶ä»–å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚\nä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼š\n\n# å®‰è£…å’ŒåŠ è½½æ‰€éœ€çš„RåŒ…\n# pak::pak(\"titanic\")\nlibrary(titanic)\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” rsample      1.2.0\nâœ” dials        1.2.0     âœ” tune         1.1.2\nâœ” infer        1.0.5     âœ” workflows    1.1.3\nâœ” modeldata    1.2.0     âœ” workflowsets 1.0.1\nâœ” parsnip      1.1.1     âœ” yardstick    1.2.0\nâœ” recipes      1.0.9     \n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– scales::discard()     masks purrr::discard()\nâœ– recipes::discretize() masks arules::discretize()\nâœ– Matrix::expand()      masks tidyr::expand()\nâœ– dplyr::filter()       masks stats::filter()\nâœ– recipes::fixed()      masks stringr::fixed()\nâœ– dplyr::lag()          masks stats::lag()\nâœ– Matrix::pack()        masks tidyr::pack()\nâœ– arules::recode()      masks dplyr::recode()\nâœ– yardstick::spec()     masks readr::spec()\nâœ– recipes::step()       masks stats::step()\nâœ– Matrix::unpack()      masks tidyr::unpack()\nâœ– recipes::update()     masks Matrix::update(), stats::update()\nâ€¢ Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n# åŠ è½½æ•°æ®\ndata(\"titanic_train\")\n\n# ä½¿ç”¨ tidymodels å¤„ç†æ•°æ®ï¼Œå¹¶è¿›è¡Œæ¨¡å‹è®­ç»ƒ\ndata &lt;- titanic_train %&gt;% \n select(Survived, Pclass, Sex, Age, Fare) %&gt;% \n mutate(Survived = factor(Survived))  |&gt; \n drop_na()\n\n# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\nset.seed(123)\ndata_split &lt;- initial_split(data, prop = 0.75, strata = Survived)\ndata_train &lt;- training(data_split)\ndata_test &lt;- testing(data_split)\n\n# å®šä¹‰é¢„å¤„ç†æ­¥éª¤\nrec &lt;- recipe(Survived ~ ., data = data_train) %&gt;%\n step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n step_zv(all_predictors()) %&gt;%\n prep()\n\n# åº”ç”¨é¢„å¤„ç†æ­¥éª¤åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›†\ndata_train_preprocessed &lt;- bake(rec, new_data = data_train)\ndata_test_preprocessed &lt;- bake(rec, new_data = data_test)\n\n# å®šä¹‰æ¨¡å‹\nmodel &lt;- logistic_reg() %&gt;%\n set_engine(\"glm\") %&gt;%\n fit(Survived ~ ., data = data_train_preprocessed)\n\n# é¢„æµ‹æµ‹è¯•é›†çš„ç»“æœ\nresults &lt;- predict(model, data_test_preprocessed) %&gt;%\n bind_cols(data_test)\n\nmodel\n\nparsnip model object\n\n\nCall:  stats::glm(formula = Survived ~ ., family = stats::binomial, \n    data = data)\n\nCoefficients:\n(Intercept)       Pclass          Age         Fare     Sex_male  \n   4.603776    -1.245534    -0.029056     0.001864    -2.377828  \n\nDegrees of Freedom: 534 Total (i.e. Null);  530 Residual\nNull Deviance:      722.5 \nResidual Deviance: 491.8    AIC: 501.8\n\n\nåœ¨æ³°å¦å°¼å…‹å·ç”Ÿå­˜é¢„æµ‹çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é€»è¾‘å›å½’æ¨¡å‹ã€‚é€»è¾‘å›å½’æ¨¡å‹çš„ç»“æœå¯ä»¥é€šè¿‡å…¶ç³»æ•°è¿›è¡Œè§£é‡Šã€‚\né€»è¾‘å›å½’æ¨¡å‹çš„åŸºæœ¬å½¢å¼æ˜¯ï¼ˆEquationÂ 1ï¼‰ï¼š\n\nlogit(p) = Î²0 + Î²1*X1 + Î²2*X2 + ... + Î²n*Xn\n\\tag{1}\nå…¶ä¸­ï¼Œp æ˜¯æ­£ä¾‹ï¼ˆè¿™é‡Œæ˜¯â€Survivedâ€ï¼‰çš„æ¦‚ç‡ï¼ŒÎ²iæ˜¯ç¬¬iä¸ªç‰¹å¾çš„ç³»æ•°ï¼ŒXiæ˜¯ç¬¬iä¸ªç‰¹å¾çš„å€¼ã€‚logit(p)æ˜¯pçš„å¯¹æ•°å‡ ç‡ã€‚\næ¯ä¸ªç³»æ•°Î²iè¡¨ç¤ºå½“å…¶ä»–æ‰€æœ‰ç‰¹å¾ä¿æŒä¸å˜æ—¶ï¼ŒX_iå¢åŠ ä¸€å•ä½æ—¶å…¶å¯¹åº”çš„å¯¹æ•°å‡ ç‡çš„æ”¹å˜é‡ã€‚å¦‚æœÎ²i &gt; 0ï¼Œé‚£ä¹ˆè¯¥ç‰¹å¾ä¸æ­£ä¾‹çš„æ¦‚ç‡æ­£ç›¸å…³ï¼›å¦‚æœÎ²i &lt; 0ï¼Œé‚£ä¹ˆè¯¥ç‰¹å¾ä¸æ­£ä¾‹çš„æ¦‚ç‡è´Ÿç›¸å…³ã€‚\nä¾‹å¦‚ï¼Œå¦‚æœå¾—åˆ°çš„æ¨¡å‹ç³»æ•°ä¸ºï¼š\n(Intercept)      4.60\nSexmale         -2.37\nAge             -0.03\nFare             0.002\nPclass          -1.24\né‚£ä¹ˆï¼Œå¯ä»¥è§£é‡Šä¸ºæ€§åˆ«ä¸ºç”·æ€§ã€ä¹˜å®¢ç­‰çº§ä¸º2å’Œ3ç­‰çº§ç›¸æ¯”äº1ç­‰çº§ã€å¹´é¾„å¢åŠ ï¼Œéƒ½ä¼šé™ä½ç”Ÿå­˜çš„å¯¹æ•°å‡ ç‡ï¼Œè€Œç¥¨ä»·å¢åŠ åˆ™ä¼šå¢åŠ ç”Ÿå­˜çš„å¯¹æ•°å‡ ç‡ã€‚\nä¸Šé¢é‡‡ç”¨äº† tidymodels çš„æµç¨‹ï¼Œå¦‚æœé‡‡ç”¨åŸºç¡€ R æ–¹æ³•ï¼Œåˆ™æœ‰å¦‚ä¸‹ç»“æœã€‚\n\nmodel &lt;- glm(Survived ~ ., data = data_train, family = binomial(link = \"logit\"))\nmodel\n\n\nCall:  glm(formula = Survived ~ ., family = binomial(link = \"logit\"), \n    data = data_train)\n\nCoefficients:\n(Intercept)       Pclass      Sexmale          Age         Fare  \n   4.603776    -1.245534    -2.377828    -0.029056     0.001864  \n\nDegrees of Freedom: 534 Total (i.e. Null);  530 Residual\nNull Deviance:      722.5 \nResidual Deviance: 491.8    AIC: 501.8\n\n\nä¸¤ä¸ªç»“æœæ˜¯ä¸€è‡´çš„ã€‚\n\n\n\nç¥ç»ç½‘ç»œæ¨¡å‹\næˆ‘ä»¬ä½¿ç”¨Kerasåº“å’Œtensorflowåç«¯åœ¨Rç¯å¢ƒä¸­è¿›è¡Œç¥ç»ç½‘ç»œçš„å»ºç«‹å’Œè®­ç»ƒã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨UCIæœºå™¨å­¦ä¹ å­˜å‚¨åº“ä¸­çš„çº¢é…’è´¨é‡æ•°æ®é›†ã€‚\n\n# åŠ è½½æ‰€éœ€åº“\nlibrary(keras)\nreticulate::use_condaenv(\"tf\")\n\n# è¯»å–å¹¶é¢„å¤„ç†æ•°æ®\n# å®‰è£…å’ŒåŠ è½½rattleåŒ…\nif (!require(rattle)) {\n  pak::pak(\"rattle\")\n}\n# åŠ è½½wineæ•°æ®é›†\ndata(wine, package = \"rattle\")\n\n# å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†\nset.seed(123)  \nindices &lt;- sample(1:nrow(wine), nrow(wine)*0.7)\ntrain_data &lt;- wine[indices, ] |&gt; as.numeric()\ntest_data &lt;- wine[-indices, ]  |&gt; as.numeric()\n\n# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾\ntrain_X &lt;- as.matrix(train_data[, -1]) \ntrain_Y &lt;- train_data$type\n\ntest_X &lt;- as.matrix(test_data[, -1])\ntest_Y &lt;- test_data$type\n\n# æ•°æ®æ ‡å‡†åŒ–\nmean &lt;- apply(train_X, 2, mean, na.rm = TRUE)\nstd &lt;- apply(train_X, 2, sd, na.rm = TRUE)\ntrain_X &lt;- scale(train_X, center = mean, scale = std)\ntest_X &lt;- scale(test_X, center = mean, scale = std)\n\n# æ„å»ºç¥ç»ç½‘ç»œæ¨¡å‹\nmodel &lt;- keras_model_sequential() \nmodel %&gt;% \n  layer_dense(units = 64, activation = 'relu', input_shape = ncol(train_X)) %&gt;% \n  layer_dense(units = 32, activation = 'relu') %&gt;%\n  layer_dense(units = 1)\n\n# ç¼–è¯‘æ¨¡å‹\nmodel %&gt;% compile(\n  loss = 'mse',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('mae')\n)\n\n# è®­ç»ƒæ¨¡å‹\nhistory &lt;- model %&gt;% fit(\n  train_X, train_Y,\n  epochs = 300, batch_size = 16, \n  validation_split = 0.2\n)\n\nä»¥ä¸Šå°±æ˜¯ä½¿ç”¨kerasåœ¨Rä¸­æ„å»ºç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œçº¢é…’è´¨é‡é¢„æµ‹çš„ç¤ºä¾‹ã€‚æ³¨æ„ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤šçš„æ­¥éª¤æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½å’Œè§£é‡Šæ¨¡å‹ç»“æœã€‚"
  },
  {
    "objectID": "21.house-price-pred-lm.html#å¯¹æ•°æ®é›†çš„è¯´æ˜",
    "href": "21.house-price-pred-lm.html#å¯¹æ•°æ®é›†çš„è¯´æ˜",
    "title": "7Â  Linear Model For House Price Predication",
    "section": "7.1 å¯¹æ•°æ®é›†çš„è¯´æ˜",
    "text": "7.1 å¯¹æ•°æ®é›†çš„è¯´æ˜\nè¿™ä¸ªæ•°æ®é›†åŒ…å«äº†ç¾å›½åç››é¡¿å·é‡‘å¿ï¼ˆå…¶ä¸­åŒ…æ‹¬è¥¿é›…å›¾ï¼‰çš„æˆ¿å±‹é”€å”®ä»·æ ¼ä»¥åŠç›¸å…³æˆ¿å±‹ç‰¹æ€§ã€‚\nä»¥ä¸‹æ˜¯ä¸€äº›åˆ—çš„æè¿°ï¼š\n\nprice: æˆ¿å±‹é”€å”®ä»·æ ¼ï¼Œè¿™é€šå¸¸æ˜¯æˆ‘ä»¬è¦é¢„æµ‹çš„ç›®æ ‡å˜é‡ã€‚\nbedrooms: å§å®¤æ•°é‡ã€‚\nbathrooms: æµ´å®¤æ•°é‡ã€‚\nsqft_living: å±…ä½é¢ç§¯ï¼ˆå¹³æ–¹è‹±å°ºï¼‰ã€‚\nsqft_lot: åœ°å—å¤§å°ï¼ˆå¹³æ–¹è‹±å°ºï¼‰ã€‚\nfloors: æ¥¼å±‚æ•°ã€‚\ncondition: æˆ¿å±‹çŠ¶å†µï¼Œä¸€èˆ¬æ˜¯æŒ‰ç…§æŸç§ç­‰çº§åˆ’åˆ†çš„ã€‚\ngrade: æ ¹æ® King County åˆ†çº§ç³»ç»Ÿè¯„å‡ºçš„æˆ¿å±‹ç­‰çº§ã€‚\n\nè¿™ä¸ªæ•°æ®é›†ç»å¸¸è¢«ç”¨æ¥è¿›è¡Œå›å½’åˆ†ææˆ–æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚é¢„æµ‹æˆ¿ä»·ã€‚"
  },
  {
    "objectID": "21.house-price-pred-lm.html#ä¼ ç»Ÿæ–¹æ³•",
    "href": "21.house-price-pred-lm.html#ä¼ ç»Ÿæ–¹æ³•",
    "title": "7Â  Linear Model For House Price Predication",
    "section": "7.2 ä¼ ç»Ÿæ–¹æ³•",
    "text": "7.2 ä¼ ç»Ÿæ–¹æ³•\nä¸‹é¢æ˜¯ç”± â€œJia-Qi Heâ€ åœ¨ â€œ2022/9/11â€ åˆ›ä½œçš„ä¼ ç»Ÿæ–¹æ³•ã€‚\n\n7.2.1 Load Library\n\n## åŠ è½½ç¨‹åºåŒ…,ä½¿ç”¨é‡Œé¢çš„ç®¡é“å‡½æ•°\nlibrary(dplyr)\n\n\nè½½å…¥ç¨‹è¾‘åŒ…ï¼š'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n## è®¾ç½®éšæœºæ•°ç§å­\nset.seed(202209)\n\n\n\n7.2.2 Data Processing\nè¯»å…¥æ•°æ®ï¼Œç”ŸæˆRæ•°æ®æ¡†ã€‚å°† priceã€sqft_livingã€sqft_lotã€sqft_above è¿™å››ä¸ªå˜é‡å–å¯¹æ•°ï¼›å¹¶è®¡ç®—åˆ° 2015 å¹´æ—¶æˆ¿å±‹çš„å¹´é¾„ã€‚\n\nhouse &lt;- house_raw %&gt;%\n  mutate(log_price = log(price)) %&gt;%\n  mutate(log_sqft_living = log(sqft_living)) %&gt;%\n  mutate(log_sqft_lot = log(sqft_lot)) %&gt;%\n  mutate(log_sqft_above = log(sqft_above)) %&gt;%\n  mutate(age = 2015-yr_built)\n\nä½¿ç”¨ sample() å‡½æ•°å°†æ•°æ®é›†éšæœºåˆ’åˆ†ä¸ºå­¦ä¹ æ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ã€‚å…ˆæŠ½å–å­¦ä¹ æ•°æ®é›†çš„è§‚æµ‹åºå·ï¼Œå­¦ä¹ æ•°æ®é›†æ˜¯æŠ½å–çš„è§‚æµ‹åºå·å¯¹åº”çš„è§‚æµ‹ã€‚æµ‹è¯•æ•°æ®é›†æ˜¯æœªè¢«æŠ½å–åˆ°å­¦ä¹ æ•°æ®é›†çš„è§‚æµ‹ã€‚\n\nid_learning &lt;- sample(1:nrow(house), round(0.7*nrow(house)))\nhouse_learning &lt;- house[id_learning,]\nhouse_testing &lt;- house[-id_learning,]\n\n\n\n7.2.3 Fitting\nå¯¹å­¦ä¹ æ•°æ®é›†æ‹Ÿåˆçº¿æ€§æ¨¡å‹ã€‚å› å˜é‡æ˜¯ log_priceï¼Œlog_sqft_living ç­‰å˜é‡å‡ä¸ºè‡ªå˜é‡ã€‚\n\nfit.lm &lt;- lm(log_price ~ log_sqft_living + log_sqft_lot + log_sqft_above + age + bedrooms + bathrooms + floors + condition + grade, data = house_learning)\n\næŸ¥çœ‹å»ºæ¨¡ç»“æœã€‚\n\nsummary(fit.lm)\n\n\nCall:\nlm(formula = log_price ~ log_sqft_living + log_sqft_lot + log_sqft_above + \n    age + bedrooms + bathrooms + floors + condition + grade, \n    data = house_learning)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.29041 -0.21109  0.01026  0.20526  1.67461 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      7.7428942  0.0735920 105.214  &lt; 2e-16 ***\nlog_sqft_living  0.5174014  0.0161666  32.004  &lt; 2e-16 ***\nlog_sqft_lot    -0.0336378  0.0035713  -9.419  &lt; 2e-16 ***\nlog_sqft_above  -0.0871745  0.0152195  -5.728 1.04e-08 ***\nage              0.0060742  0.0001142  53.181  &lt; 2e-16 ***\nbedrooms        -0.0438852  0.0035787 -12.263  &lt; 2e-16 ***\nbathrooms        0.0773968  0.0059612  12.983  &lt; 2e-16 ***\nfloors           0.0680483  0.0072774   9.351  &lt; 2e-16 ***\ncondition        0.0343253  0.0043309   7.926 2.43e-15 ***\ngrade            0.2409012  0.0036670  65.694  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3165 on 15119 degrees of freedom\nMultiple R-squared:  0.638, Adjusted R-squared:  0.6377 \nF-statistic:  2960 on 9 and 15119 DF,  p-value: &lt; 2.2e-16\n\n\næ¨¡å‹ä¸­å„ä¸ªè‡ªå˜é‡çš„ç³»æ•°å‡æ˜¾è‘—ä¸ä¸º 0ï¼›æ¨¡å‹çš„ R æ–¹ä¸º 0.6406ã€‚\næå–æ¨¡å‹çš„ç³»æ•°ä¼°è®¡å€¼\n\ncoefficients(fit.lm)\n\n    (Intercept) log_sqft_living    log_sqft_lot  log_sqft_above             age \n    7.742894171     0.517401364    -0.033637793    -0.087174490     0.006074193 \n       bedrooms       bathrooms          floors       condition           grade \n   -0.043885175     0.077396849     0.068048324     0.034325337     0.240901189 \n\n\næå–æ¨¡å‹çš„å› å˜é‡æ‹Ÿåˆå€¼ã€‚\n\nyhat &lt;- fitted(fit.lm)\nstr(yhat)\n\n Named num [1:15129] 13.1 13.2 13.4 13 13.4 ...\n - attr(*, \"names\")= chr [1:15129] \"1\" \"2\" \"3\" \"4\" ...\n\n\næå–æ¨¡å‹çš„æ®‹å·®ã€‚\n\nresid &lt;- residuals(fit.lm)\nstr(resid)\n\n Named num [1:15129] -0.0141 -0.308 0.1671 -0.2173 0.443 ...\n - attr(*, \"names\")= chr [1:15129] \"1\" \"2\" \"3\" \"4\" ...\n\n\n\n\n7.2.4 æ¨¡å‹è¯Šæ–­\nå°†ç»˜å›¾çª—å£åˆ†ä¸º 2*2 çš„çŸ©é˜µã€‚æŒ‡å®šç»˜å›¾åŒºåŸŸç¦»ä¸‹è¾¹ç•Œã€å·¦è¾¹ç•Œã€ä¸Šè¾¹ç•Œå’Œå³è¾¹ç•Œçš„è·ç¦»ï¼ˆå•ä½ä¸ºæ–‡æœ¬è¡Œæ•°ï¼‰ï¼Œæ–¹ä¾¿ç”»ä¸‹æ‰€æœ‰è¯Šæ–­å›¾ã€‚\nç”»æ¨¡å‹è¯Šæ–­å›¾ã€‚\n\npar(mfrow=c(2, 2))\npar(mar=c(2.5, 2.5, 1.5, 1.5))\n\nlibrary(ggplot2)\nplot(fit.lm, which=c(1:4))\n\n\n\n\n\n\n7.2.5 Model Optimization\nä» Cook è·ç¦»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œåºå·ä¸ºâ€15871â€çš„è§‚æµ‹æ˜¯å¼‚å¸¸ç‚¹ã€‚\nå»é™¤åºå·ä¸ºâ€15871â€çš„è§‚æµ‹ï¼Œé‡æ–°æ‹Ÿåˆçº¿æ€§æ¨¡å‹\n\nfit2.lm &lt;- lm(log_price ~ log_sqft_living + log_sqft_lot + log_sqft_above + age + bedrooms + bathrooms + floors + condition + grade,data = house_learning[rownames(house_learning)!=\"15871\",])\n\npar(mfrow=c(2, 2))\npar(mar=c(2.5, 2.5, 1.5, 1.5))\nplot(fit2.lm, which=c(1:4))\n\n\n\n\nä½¿ç”¨æ‰€å¾—çš„çº¿æ€§æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚\n\nprediction.lm &lt;- predict(fit2.lm, house_testing)\n\npredition.lm ä¸­å«æœ‰é¢„æµ‹çš„å¯¹æ•°ä»·æ ¼ï¼Œexp(pred.lm) å°†å¯¹æ•°ä»·æ ¼è½¬æ¢ä¸ºé¢„æµ‹çš„ä»·æ ¼ã€‚å°†é¢„æµ‹ä»·æ ¼ä¸çœŸå®ä»·æ ¼å–å·®å€¼ï¼Œå¹³æ–¹ä¹‹åå¹³å‡ï¼Œå†å¼€æ ¹å·ã€‚è®¡ç®—å‡ºæµ‹è¯•æ•°æ®é›†çš„æˆ¿å±‹ä»·æ ¼é¢„æµ‹çš„å‡æ–¹æ ¹è¯¯å·®ã€‚\n\nrmse.lm &lt;- sqrt(mean((exp(prediction.lm) - house_testing$price)^2))\n\nstr(rmse.lm)\n\n num 209627"
  },
  {
    "objectID": "21.house-price-pred-lm.html#tidymodels-æ–¹æ³•",
    "href": "21.house-price-pred-lm.html#tidymodels-æ–¹æ³•",
    "title": "7Â  Linear Model For House Price Predication",
    "section": "7.3 tidymodels æ–¹æ³•",
    "text": "7.3 tidymodels æ–¹æ³•\ntidymodels æ–¹æ³•é‡ç°äº†ä¸Šé¢çš„å»ºæ¨¡è¿‡ç¨‹ï¼Œåªæ˜¯é€»è¾‘æ€§å’Œæ‰©å±•æ€§æ›´å¥½ã€‚\n\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.1.1 â”€â”€\n\n\nâœ” broom        1.0.5     âœ” rsample      1.2.0\nâœ” dials        1.2.0     âœ” tibble       3.2.1\nâœ” infer        1.0.5     âœ” tidyr        1.3.0\nâœ” modeldata    1.2.0     âœ” tune         1.1.2\nâœ” parsnip      1.1.1     âœ” workflows    1.1.3\nâœ” purrr        1.0.2     âœ” workflowsets 1.0.1\nâœ” recipes      1.0.9     âœ” yardstick    1.2.0\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– purrr::discard() masks scales::discard()\nâœ– dplyr::filter()  masks stats::filter()\nâœ– dplyr::lag()     masks stats::lag()\nâœ– recipes::step()  masks stats::step()\nâ€¢ Learn how to get started at https://www.tidymodels.org/start/\n\n# åˆ’åˆ†æ•°æ®é›†\nset.seed(20240206)\n(house_split = initial_split(house_raw, strata = price))\n\n&lt;Training/Testing/Total&gt;\n&lt;16209/5404/21613&gt;\n\n# è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n(house_train = training(house_split))\n\n# A tibble: 16,209 Ã— 10\n    price bedrooms bathrooms sqft_living sqft_lot floors condition grade\n    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 180000        2       1           770    10000    1           3     6\n 2 291850        3       1.5        1060     9711    1           3     7\n 3 229500        3       1          1780     7470    1           3     7\n 4 310000        3       1          1430    19901    1.5         4     7\n 5 230000        3       1          1250     9774    1           4     7\n 6 233000        3       2          1710     4697    1.5         5     6\n 7 280000        2       1.5        1190     1265    3           3     7\n 8 240000        4       1          1220     8075    1           2     7\n 9 309000        3       1          1280     9656    1           4     6\n10 210490        3       1           990     8528    1           3     6\n# â„¹ 16,199 more rows\n# â„¹ 2 more variables: sqft_above &lt;dbl&gt;, yr_built &lt;dbl&gt;\n\n(house_test = testing(house_split))\n\n# A tibble: 5,404 Ã— 10\n    price bedrooms bathrooms sqft_living sqft_lot floors condition grade\n    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 221900        3      1           1180     5650      1         3     7\n 2 510000        3      2           1680     8080      1         3     8\n 3 257500        3      2.25        1715     6819      2         3     7\n 4 468000        2      1           1160     6000      1         4     7\n 5 400000        3      1.75        1370     9680      1         4     7\n 6 189000        2      1           1200     9850      1         4     7\n 7 285000        5      2.5         2270     6300      2         3     8\n 8 252700        2      1.5         1070     9643      1         3     7\n 9 329000        3      2.25        2450     6500      2         4     8\n10 719000        4      2.5         2570     7173      2         3     8\n# â„¹ 5,394 more rows\n# â„¹ 2 more variables: sqft_above &lt;dbl&gt;, yr_built &lt;dbl&gt;\n\n# åˆ›å»º recipe\nhouse_rec = recipe(price ~ ., data = house_train) |&gt; \n  step_log(price, starts_with(\"sqft_\")) |&gt; \n  step_mutate(age = 2015 - yr_built) |&gt; \n  step_rm(yr_built)\nsummary(house_rec)\n\n# A tibble: 10 Ã— 4\n   variable    type      role      source  \n   &lt;chr&gt;       &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 bedrooms    &lt;chr [2]&gt; predictor original\n 2 bathrooms   &lt;chr [2]&gt; predictor original\n 3 sqft_living &lt;chr [2]&gt; predictor original\n 4 sqft_lot    &lt;chr [2]&gt; predictor original\n 5 floors      &lt;chr [2]&gt; predictor original\n 6 condition   &lt;chr [2]&gt; predictor original\n 7 grade       &lt;chr [2]&gt; predictor original\n 8 sqft_above  &lt;chr [2]&gt; predictor original\n 9 yr_built    &lt;chr [2]&gt; predictor original\n10 price       &lt;chr [2]&gt; outcome   original\n\n# å®šä¹‰è®­ç»ƒå‚æ•°\nreg_metrics = metric_set(mae, rsq)\n\n# åˆå§‹åŒ– workflow\nhouse_wflow = workflow() |&gt; \n  add_recipe(house_rec) |&gt; \n  add_model(linear_reg())\n\n# äº¤å‰éªŒè¯é›†\n(house_rs = vfold_cv(house_train, strata = price))\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 Ã— 2\n   splits               id    \n   &lt;list&gt;               &lt;chr&gt; \n 1 &lt;split [14586/1623]&gt; Fold01\n 2 &lt;split [14586/1623]&gt; Fold02\n 3 &lt;split [14587/1622]&gt; Fold03\n 4 &lt;split [14588/1621]&gt; Fold04\n 5 &lt;split [14588/1621]&gt; Fold05\n 6 &lt;split [14589/1620]&gt; Fold06\n 7 &lt;split [14589/1620]&gt; Fold07\n 8 &lt;split [14589/1620]&gt; Fold08\n 9 &lt;split [14589/1620]&gt; Fold09\n10 &lt;split [14590/1619]&gt; Fold10\n\n# æ‹Ÿåˆå¹¶è¯„ä¼°æ¨¡å‹\nctrl &lt;- control_resamples(save_pred = TRUE)\nhouse_res &lt;-\n  house_wflow %&gt;%\n  fit_resamples(house_rs, control = ctrl, metrics = reg_metrics)\n\n# åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹å¹¶æ”¶é›†ç»“æœ\nhouse_test_preds &lt;- house_wflow %&gt;%\n  last_fit(house_split) %&gt;%\n  collect_predictions(new_data = house_test)\n\n# è¾“å‡ºæ¨¡å‹æŒ‡æ ‡\nhouse_test_results &lt;- house_test_preds %&gt;%\n  metrics(truth = price, estimate = .pred)\n\nhouse_test_results\n\n# A tibble: 3 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.316\n2 rsq     standard       0.631\n3 mae     standard       0.250\n\n\nä¸Šè¿°ä»£ç ä¸»è¦å®Œæˆäº†ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n\nä½¿ç”¨ initial_split() å‡½æ•°å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚strata = price å‚æ•°è¡¨ç¤ºåœ¨åˆ’åˆ†æ•°æ®æ—¶ï¼Œä¼šæ ¹æ® price åˆ—çš„å€¼è¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼Œä»¥ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„ price åˆ†å¸ƒç›¸ä¼¼ã€‚\nåˆ›å»ºäº†ä¸€ä¸ªé¢„å¤„ç† recipeï¼Œå…¶ä¸­åŒ…æ‹¬å¯¹ price å’Œæ‰€æœ‰ä»¥ â€œsqft_â€ å¼€å¤´çš„åˆ—è¿›è¡Œå¯¹æ•°è½¬æ¢ï¼Œä»¥åŠè®¡ç®—æˆ¿é¾„ï¼ˆ2015å¹´å‡å»å»ºé€ å¹´ä»½ï¼‰ã€‚\nå®šä¹‰äº†å›å½’ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡ï¼šå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰å’Œå†³å®šç³»æ•°ï¼ˆRÂ²ï¼‰ã€‚\nåˆå§‹åŒ–äº†ä¸€ä¸ªå·¥ä½œæµï¼Œå…¶ä¸­åŒ…å«ä¸Šè¿°çš„é¢„å¤„ç† recipe ä»¥åŠçº¿æ€§å›å½’æ¨¡å‹ã€‚\nå¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ†å±‚äº¤å‰éªŒè¯ï¼Œåˆ›å»ºäº†ä¸€ç³»åˆ—çš„è®­ç»ƒ/éªŒè¯é›†ã€‚\næœ€åä¸€æ­¥æ˜¯åˆ©ç”¨äº¤å‰éªŒè¯çš„ç»“æœæ¥æ‹Ÿåˆå·¥ä½œæµï¼Œå¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚\nlast_fit() å°†å·¥ä½œæµæ‹Ÿåˆåˆ°å®Œæ•´çš„è®­ç»ƒæ•°æ®ä¸Šï¼Œç„¶åç”¨æ‹Ÿåˆå¥½çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šåšé¢„æµ‹ã€‚æœ€åï¼Œè®¡ç®—äº†æµ‹è¯•é›†ä¸Šçš„ MAE å’Œ RÂ² æŒ‡æ ‡å¹¶æ‰“å°å‡ºæ¥ã€‚\n\næœ€åï¼Œæ•°æ®å¯è§†åŒ–æ˜¯æ•°æ®ç§‘å­¦å·¥ä½œä¸­çš„é‡è¦ä¸€ç¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯è§†åŒ–æ¥æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„æ€§èƒ½ä»¥åŠæ•°æ®çš„ç‰¹ç‚¹ã€‚ä»¥ä¸‹æ˜¯ä¸¤ä¸ªå¸¸è§çš„å¯è§†åŒ–ä»»åŠ¡ï¼š\n\nè§‚å¯Ÿé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å…³ç³»ï¼šæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ä¸€ä¸ªæ•£ç‚¹å›¾ï¼Œæ¨ªåæ ‡ä¸ºé¢„æµ‹å€¼ï¼Œçºµåæ ‡ä¸ºçœŸå®å€¼ã€‚\n\n\nggplot(house_test_preds, aes(x = .pred, y = price)) +\n  geom_point(alpha = 0.4) +\n  geom_abline(color = \"blue\") +\n  xlab(\"Predicted Price\") +\n  ylab(\"True Price\")\n\n\n\n\nåœ¨è¿™ä¸ªå›¾ä¸­ï¼Œè“è‰²çš„çº¿è¡¨ç¤ºé¢„æµ‹å€¼å’ŒçœŸå®å€¼å®Œå…¨ç›¸ç­‰çš„æƒ…å†µã€‚å¦‚æœæ¨¡å‹çš„é¢„æµ‹æ•ˆæœè‰¯å¥½ï¼Œé‚£ä¹ˆç‚¹åº”è¯¥ç´§å¯†åœ°å›´ç»•åœ¨è¿™æ¡çº¿å‘¨å›´ã€‚\n\næŸ¥çœ‹æ¯æ¬¡äº¤å‰éªŒè¯çš„ç»“æœï¼šæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ä¸€ä¸ªç®±å‹å›¾ï¼Œå±•ç¤ºæ¯æ¬¡äº¤å‰éªŒè¯ç»“æœçš„åˆ†å¸ƒã€‚\n\n\nhouse_res |&gt; \n  select(id, .metrics)  |&gt; \n  unnest(.metrics) %&gt;%\n  ggplot(aes(x = id, y = .estimate)) +\n  geom_col() +\n  facet_wrap(~.metric, ncol = 1)\n\n\n\n\nåœ¨è¿™ä¸ªå›¾ä¸­ï¼Œæ¯ä¸ªç®±å‹å›¾ä»£è¡¨ä¸€æ¬¡äº¤å‰éªŒè¯çš„ç»“æœï¼ˆå³æ¨¡å‹åœ¨ä¸åŒè®­ç»ƒ/éªŒè¯é›†ä¸Šçš„è¡¨ç°ï¼‰ã€‚é€šè¿‡æŸ¥çœ‹ç®±å‹å›¾ï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£æ¨¡å‹æ€§èƒ½çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚\nä»¥ä¸Šåªæ˜¯ä¸€äº›åŸºæœ¬çš„å¯è§†åŒ–ç¤ºä¾‹ï¼Œå…·ä½“å¯è§†åŒ–çš„å†…å®¹å’Œæ–¹å¼ä¼šä¾æ®ä½ å¯¹æ•°æ®å’Œä»»åŠ¡çš„ç†è§£è¿›è¡Œè°ƒæ•´ã€‚\n\n7.3.1 æœ€ä½³æ‹Ÿåˆç»“æœ\nåœ¨ tidymodels ä¸­ï¼Œå¦‚æœä½ ä½¿ç”¨äº†è°ƒå‚ï¼ˆtuneï¼‰åŠŸèƒ½å¯»æ‰¾æœ€ä½³çš„æ¨¡å‹è¶…å‚æ•°ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ¥è·å–æœ€ä½³çš„æ‹Ÿåˆç»“æœï¼š\n\n# è·å–æœ€ä½³å‚æ•°ç»„åˆ\nbest_params &lt;- house_res %&gt;%\n  select_best(metric = \"mae\")\n\n# ä½¿ç”¨æœ€ä½³å‚æ•°é‡æ–°æ‹Ÿåˆæ¨¡å‹\nbest_fit &lt;- house_wflow %&gt;%\n  finalize_workflow(best_params) %&gt;%\n  last_fit(house_split)\n\n# æå–æ‹Ÿåˆç»“æœ\nfit_result &lt;- best_fit %&gt;% \n  extract_fit_parsnip()\n\n# æ‹Ÿåˆå¾—åˆ°çš„å‚æ•°\nfit_result %&gt;% tidy()\n\n# A tibble: 10 Ã— 5\n   term        estimate std.error statistic   p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)  7.78     0.0717      108.   0        \n 2 bedrooms    -0.0510   0.00370     -13.8  6.19e- 43\n 3 bathrooms    0.0839   0.00576      14.6  1.01e- 47\n 4 sqft_living  0.495    0.0157       31.5  1.25e-211\n 5 sqft_lot    -0.0332   0.00341      -9.74 2.27e- 22\n 6 floors       0.0633   0.00703       9.00 2.51e- 19\n 7 condition    0.0364   0.00419       8.70 3.53e- 18\n 8 grade        0.243    0.00353      68.9  0        \n 9 sqft_above  -0.0699   0.0147       -4.77 1.90e-  6\n10 age          0.00609  0.000111     55.0  0        \n\n# è‡ªå˜é‡çš„é‡è¦æ€§\nfit_result |&gt; vip::vip()\n\n\n\n\nåœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼š - house_res æ˜¯ä½ åœ¨è°ƒå‚è¿‡ç¨‹ä¸­å¾—åˆ°çš„ç»“æœï¼ŒåŒ…å«äº†æ‰€æœ‰å°è¯•è¿‡çš„å‚æ•°ç»„åˆä»¥åŠå¯¹åº”çš„è¯„ä»·æŒ‡æ ‡ã€‚ - select_best() å‡½æ•°ç”¨äºé€‰æ‹©ä½¿æŒ‡å®šæŒ‡æ ‡è¾¾åˆ°æœ€ä¼˜çš„å‚æ•°ç»„åˆã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©ä½¿ RMSE æœ€å°çš„å‚æ•°ç»„åˆã€‚ - finalize_workflow() å‡½æ•°å°†æœ€ä½³å‚æ•°è®¾ç½®åˆ°å·¥ä½œæµä¸­ã€‚ - last_fit() å‡½æ•°åˆ™ä½¿ç”¨è¿™ä¸ªå‚æ•°å†æ¬¡æ‹Ÿåˆæ¨¡å‹ã€‚\nç„¶åï¼Œæˆ‘ä»¬åƒä¹‹å‰ä¸€æ ·ä½¿ç”¨ extract_fit_parsnip() å’Œ tidy() å‡½æ•°æ¥æå–æ¨¡å‹æ‹Ÿåˆç»“æœã€‚æ­¤æ—¶ï¼Œfit_result å°±æ˜¯ä¸€ä¸ªåŒ…å«äº†æœ€ä½³æ¨¡å‹å‚æ•°çš„æ•°æ®æ¡†ã€‚"
  },
  {
    "objectID": "90.conclusion.html",
    "href": "90.conclusion.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "95.references.html",
    "href": "95.references.html",
    "title": "References",
    "section": "",
    "text": "McConville, Chester Ismay and Albert Y. Kim Foreword by Kelly S. 2022.\nStatistical Inference via Data\nScience.\n\n\nRobinson, Julia Silge and David. 2023. Welcome to Text\nMining with R  Text Mining\nwith R.\n\n\nSilge, Emil Hvitfeldt and Julia. 2023. Supervised Machine\nLearning for Text Analysis in R.\n\n\nSilge, Max Kuhn and Julia. 2022. Tidy Modeling with\nR.\n\n\nå¼ ä¿Šå¦®. 2021. æ•°æ®æŒ–æ˜ï¼šåŸºäºRè¯­è¨€çš„å®æˆ˜.\näººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾."
  }
]